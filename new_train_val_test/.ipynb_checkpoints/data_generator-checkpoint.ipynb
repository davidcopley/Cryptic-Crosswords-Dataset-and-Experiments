{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.layers import Bidirectional,LSTM,Dense,Embedding\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./pure_cc_clues.pickle\",'rb') as f:\n",
    "    dfs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dfs(dfs,shuffle=False):\n",
    "    train_test = [train_test_split(df,shuffle=shuffle,test_size=0.2) for df in dfs ]\n",
    "    train = [el[0] for el in train_test]\n",
    "    test = [el[1] for el in train_test]\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt,test = split_dfs(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,val = split_dfs(inpt,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat(train)\n",
    "val = pd.concat(val)\n",
    "test = pd.concat(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['is_charade','is_lit'],axis=1)\n",
    "val = val.drop(['is_charade','is_lit'],axis=1)\n",
    "test = test.drop(['is_charade','is_lit'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.clue\n",
    "val_x = val.clue\n",
    "test_x = test.clue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train[train.columns[4:]]\n",
    "val_y = val[train.columns[4:]]\n",
    "test_y = test[test.columns[4:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = np.argmax(train_y.values*1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_train['category'] = categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = upsampled_train.groupby('category').count().max()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [upsampled_train]\n",
    "for class_index, group in upsampled_train.groupby('category'):\n",
    "    sample = group.sample(max_size-len(group), replace=True, )\n",
    "    lst.append(sample)\n",
    "upsampled_train = pd.concat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=\"#$%&()*+/:;<=>@[\\]^_`{|}~\")\n",
    "tokenizer.fit_on_texts(pd.concat([train,val,test]).clue.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pad_sequences(tokenizer.texts_to_sequences(train_x),15)\n",
    "val_x = pad_sequences(tokenizer.texts_to_sequences(val_x),15)\n",
    "test_x = pad_sequences(tokenizer.texts_to_sequences(test_x),15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1,output_dim=100,input_length=15))\n",
    "model.add(Bidirectional(LSTM(100,dropout=0.5)))\n",
    "model.add(Dense(12,activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30063 samples, validate on 7524 samples\n",
      "Epoch 1/10\n",
      "30063/30063 [==============================] - 9s 302us/step - loss: 0.2457 - categorical_accuracy: 0.7237 - val_loss: 1.4324 - val_categorical_accuracy: 0.4381\n",
      "Epoch 2/10\n",
      "30063/30063 [==============================] - 9s 305us/step - loss: 0.1899 - categorical_accuracy: 0.7391 - val_loss: 1.4707 - val_categorical_accuracy: 0.4337\n",
      "Epoch 3/10\n",
      "30063/30063 [==============================] - 9s 309us/step - loss: 0.1565 - categorical_accuracy: 0.7491 - val_loss: 1.5529 - val_categorical_accuracy: 0.4215\n",
      "Epoch 4/10\n",
      "30063/30063 [==============================] - 9s 307us/step - loss: 0.1332 - categorical_accuracy: 0.7564 - val_loss: 1.5849 - val_categorical_accuracy: 0.4365\n",
      "Epoch 5/10\n",
      "30063/30063 [==============================] - 9s 308us/step - loss: 0.1109 - categorical_accuracy: 0.7624 - val_loss: 1.7225 - val_categorical_accuracy: 0.4329\n",
      "Epoch 6/10\n",
      "30063/30063 [==============================] - 9s 308us/step - loss: 0.0955 - categorical_accuracy: 0.7672 - val_loss: 1.7345 - val_categorical_accuracy: 0.4071\n",
      "Epoch 7/10\n",
      "30063/30063 [==============================] - 9s 309us/step - loss: 0.0786 - categorical_accuracy: 0.7704 - val_loss: 1.8507 - val_categorical_accuracy: 0.4110\n",
      "Epoch 8/10\n",
      "30063/30063 [==============================] - 9s 315us/step - loss: 0.0656 - categorical_accuracy: 0.7755 - val_loss: 1.9283 - val_categorical_accuracy: 0.3989\n",
      "Epoch 9/10\n",
      "30063/30063 [==============================] - 9s 312us/step - loss: 0.0560 - categorical_accuracy: 0.7772 - val_loss: 1.9408 - val_categorical_accuracy: 0.4207\n",
      "Epoch 10/10\n",
      "30063/30063 [==============================] - 9s 311us/step - loss: 0.0495 - categorical_accuracy: 0.7788 - val_loss: 2.0514 - val_categorical_accuracy: 0.4079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a6f2908>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x,train_y,validation_data=(val_x,val_y),epochs=10,batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2001234278904471"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)/(len(train)+len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
