{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import keras\n",
    "from keras.layers import Dense,Embedding, Flatten, Conv1D, GlobalMaxPooling1D, LSTM, Bidirectional, Dropout\n",
    "from keras.preprocessing.text import text_to_word_sequence,Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./cryptic_dataset/combined_fifteen_times_final_filtered.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "anagram_df = df[\n",
    "    df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "anagram_df.sample(1000,random_state=1).to_csv('pure_anagrams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophone_df = df[\n",
    "    ~df.is_anagram &\n",
    "    df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cryptic_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "contain_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternate_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "charade_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spoonerism_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "palindrome_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    df.is_palindrome\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_types_dfs = [anagram_df,homophone_df,double_df,cryptic_df,contain_df,reverse_df,alternate_df,init_df,delete_df,charade_df,lit_df,hidden_df,spoonerism_df,palindrome_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_types = 'is_anagram\tis_homophone\tis_double\tis_cryptic\tis_contain\tis_reverse\tis_alternate\tis_init\tis_delete\tis_charade\tis_&lit\tis_hidden\tis_spoonerism\tis_palindrome'.split('\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df,cc_type in zip(cc_types_dfs,cc_types):\n",
    "    df['category'] = cc_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_val_test(df):\n",
    "    length = len(df)\n",
    "    input_len = math.floor(length*0.7)\n",
    "    val_len  = math.floor(length*0.2)\n",
    "    test_len = math.floor(length*0.1)\n",
    "    input_df = df[:input_len]\n",
    "    val_df = df[input_len:input_len+val_len]\n",
    "    test_df = df[input_len+val_len:]\n",
    "    return input_df,val_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cc_types_df = pd.concat([get_input_val_test(df)[0] for df in cc_types_dfs]).sample(frac=1)\n",
    "val_cc_types_df = pd.concat([get_input_val_test(df)[1] for df in cc_types_dfs]).sample(frac=1)\n",
    "test_cc_types_df = pd.concat([get_input_val_test(df)[2] for df in cc_types_dfs]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = input_cc_types_df.groupby('category').count().max()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [input_cc_types_df]\n",
    "for class_index, group in input_cc_types_df.groupby('category'):\n",
    "    sample = group.sample(max_size-len(group), replace=True, )\n",
    "    lst.append(sample)\n",
    "upsampled_input_cc_types_df = pd.concat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_input_df = upsampled_input_cc_types_df.drop('category',axis=1)\n",
    "cc_val_df = val_cc_types_df.drop('category',axis=1).drop_duplicates()\n",
    "cc_test_df = test_cc_types_df.drop('category',axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df.clue.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_input_data = pad_sequences(tokenizer.texts_to_sequences(cc_input_df.clue.tolist()),maxlen=15)\n",
    "cc_val_data = pad_sequences(tokenizer.texts_to_sequences(cc_val_df.clue.tolist()),maxlen=15)\n",
    "cc_test_data = pad_sequences(tokenizer.texts_to_sequences(cc_test_df.clue.tolist()),maxlen=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_input_data_out = cc_input_df[cc_input_df.columns[2:]] * 1\n",
    "cc_val_data_out = cc_val_df[cc_val_df.columns[2:]] * 1\n",
    "cc_test_data_out = cc_test_df[cc_test_df.columns[2:]] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(len(tokenizer.index_word)+1, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(14, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 149842 samples, validate on 3833 samples\n",
      "Epoch 1/10\n",
      "149842/149842 [==============================] - 153s 1ms/step - loss: 0.2206 - categorical_accuracy: 0.2642 - val_loss: 0.2578 - val_categorical_accuracy: 0.0785\n",
      "Epoch 2/10\n",
      "149842/149842 [==============================] - 142s 947us/step - loss: 0.2023 - categorical_accuracy: 0.3364 - val_loss: 0.2461 - val_categorical_accuracy: 0.1226\n",
      "Epoch 3/10\n",
      "149842/149842 [==============================] - 145s 968us/step - loss: 0.1930 - categorical_accuracy: 0.3689 - val_loss: 0.2473 - val_categorical_accuracy: 0.1017\n",
      "Epoch 4/10\n",
      "149842/149842 [==============================] - 130s 870us/step - loss: 0.1876 - categorical_accuracy: 0.3884 - val_loss: 0.2534 - val_categorical_accuracy: 0.0871\n",
      "Epoch 5/10\n",
      "149842/149842 [==============================] - 119s 793us/step - loss: 0.1842 - categorical_accuracy: 0.4007 - val_loss: 0.2540 - val_categorical_accuracy: 0.1161\n",
      "Epoch 6/10\n",
      "149842/149842 [==============================] - 125s 836us/step - loss: 0.1819 - categorical_accuracy: 0.4072 - val_loss: 0.2535 - val_categorical_accuracy: 0.1064\n",
      "Epoch 7/10\n",
      "149842/149842 [==============================] - 123s 818us/step - loss: 0.1802 - categorical_accuracy: 0.4144 - val_loss: 0.2550 - val_categorical_accuracy: 0.1046\n",
      "Epoch 8/10\n",
      "149842/149842 [==============================] - 122s 815us/step - loss: 0.1789 - categorical_accuracy: 0.4189 - val_loss: 0.2579 - val_categorical_accuracy: 0.0947\n",
      "Epoch 9/10\n",
      "149842/149842 [==============================] - 133s 889us/step - loss: 0.1779 - categorical_accuracy: 0.4229 - val_loss: 0.2545 - val_categorical_accuracy: 0.1072\n",
      "Epoch 10/10\n",
      "149842/149842 [==============================] - 133s 885us/step - loss: 0.1771 - categorical_accuracy: 0.4253 - val_loss: 0.2571 - val_categorical_accuracy: 0.1033\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/510 [==============================] - 0s 255us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2566366582524543, 0.1333333335378591]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(len(tokenizer.index_word)+1,50,input_length=15))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(64, 10,padding='valid', activation='relu', strides=1))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(250,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(14, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 149842 samples, validate on 3833 samples\n",
      "Epoch 1/6\n",
      "149842/149842 [==============================] - 7s 44us/step - loss: 0.2313 - categorical_accuracy: 0.2141 - val_loss: 0.2445 - val_categorical_accuracy: 0.0744\n",
      "Epoch 2/6\n",
      "149842/149842 [==============================] - 6s 43us/step - loss: 0.2087 - categorical_accuracy: 0.3124 - val_loss: 0.2481 - val_categorical_accuracy: 0.0741\n",
      "Epoch 3/6\n",
      "149842/149842 [==============================] - 6s 42us/step - loss: 0.2002 - categorical_accuracy: 0.3410 - val_loss: 0.2483 - val_categorical_accuracy: 0.0918\n",
      "Epoch 4/6\n",
      "149842/149842 [==============================] - 6s 39us/step - loss: 0.1955 - categorical_accuracy: 0.3582 - val_loss: 0.2490 - val_categorical_accuracy: 0.0822\n",
      "Epoch 5/6\n",
      "149842/149842 [==============================] - 6s 40us/step - loss: 0.1923 - categorical_accuracy: 0.3679 - val_loss: 0.2520 - val_categorical_accuracy: 0.0843\n",
      "Epoch 6/6\n",
      "149842/149842 [==============================] - 6s 40us/step - loss: 0.1901 - categorical_accuracy: 0.3744 - val_loss: 0.2510 - val_categorical_accuracy: 0.0916\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(len(tokenizer.index_word)+1, 128))\n",
    "model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"1xBilstm-{epoch:02d}-{val_loss:.2f}-{val_categorical_accuracy:.2f}-singlelabel.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 149842 samples, validate on 3833 samples\n",
      "Epoch 1/16\n",
      "149842/149842 [==============================] - 69s 458us/step - loss: 0.2278 - categorical_accuracy: 0.2305 - val_loss: 0.2482 - val_categorical_accuracy: 0.0764\n",
      "\n",
      "Epoch 00001: saving model to 1xBilstm-01-0.25-0.08-singlelabel.hdf5\n",
      "Epoch 2/16\n",
      "149842/149842 [==============================] - 66s 443us/step - loss: 0.2131 - categorical_accuracy: 0.2964 - val_loss: 0.2412 - val_categorical_accuracy: 0.1135\n",
      "\n",
      "Epoch 00002: saving model to 1xBilstm-02-0.24-0.11-singlelabel.hdf5\n",
      "Epoch 3/16\n",
      "149842/149842 [==============================] - 68s 456us/step - loss: 0.2044 - categorical_accuracy: 0.3277 - val_loss: 0.2520 - val_categorical_accuracy: 0.0897\n",
      "\n",
      "Epoch 00003: saving model to 1xBilstm-03-0.25-0.09-singlelabel.hdf5\n",
      "Epoch 4/16\n",
      "149842/149842 [==============================] - 68s 457us/step - loss: 0.1982 - categorical_accuracy: 0.3500 - val_loss: 0.2533 - val_categorical_accuracy: 0.0871\n",
      "\n",
      "Epoch 00004: saving model to 1xBilstm-04-0.25-0.09-singlelabel.hdf5\n",
      "Epoch 5/16\n",
      "149842/149842 [==============================] - 81s 538us/step - loss: 0.1931 - categorical_accuracy: 0.3689 - val_loss: 0.2478 - val_categorical_accuracy: 0.1036\n",
      "\n",
      "Epoch 00005: saving model to 1xBilstm-05-0.25-0.10-singlelabel.hdf5\n",
      "Epoch 6/16\n",
      "149842/149842 [==============================] - 64s 430us/step - loss: 0.1890 - categorical_accuracy: 0.3819 - val_loss: 0.2486 - val_categorical_accuracy: 0.1070\n",
      "\n",
      "Epoch 00006: saving model to 1xBilstm-06-0.25-0.11-singlelabel.hdf5\n",
      "Epoch 7/16\n",
      "149842/149842 [==============================] - 59s 396us/step - loss: 0.1856 - categorical_accuracy: 0.3941 - val_loss: 0.2499 - val_categorical_accuracy: 0.1145\n",
      "\n",
      "Epoch 00007: saving model to 1xBilstm-07-0.25-0.11-singlelabel.hdf5\n",
      "Epoch 8/16\n",
      "149842/149842 [==============================] - 59s 395us/step - loss: 0.1828 - categorical_accuracy: 0.4036 - val_loss: 0.2517 - val_categorical_accuracy: 0.1064\n",
      "\n",
      "Epoch 00008: saving model to 1xBilstm-08-0.25-0.11-singlelabel.hdf5\n",
      "Epoch 9/16\n",
      "149842/149842 [==============================] - 59s 394us/step - loss: 0.1806 - categorical_accuracy: 0.4106 - val_loss: 0.2516 - val_categorical_accuracy: 0.1098\n",
      "\n",
      "Epoch 00009: saving model to 1xBilstm-09-0.25-0.11-singlelabel.hdf5\n",
      "Epoch 10/16\n",
      "149842/149842 [==============================] - 59s 396us/step - loss: 0.1789 - categorical_accuracy: 0.4160 - val_loss: 0.2524 - val_categorical_accuracy: 0.1054\n",
      "\n",
      "Epoch 00010: saving model to 1xBilstm-10-0.25-0.11-singlelabel.hdf5\n",
      "Epoch 11/16\n",
      "149842/149842 [==============================] - 66s 443us/step - loss: 0.1773 - categorical_accuracy: 0.4221 - val_loss: 0.2569 - val_categorical_accuracy: 0.0999\n",
      "\n",
      "Epoch 00011: saving model to 1xBilstm-11-0.26-0.10-singlelabel.hdf5\n",
      "Epoch 12/16\n",
      "149842/149842 [==============================] - 72s 481us/step - loss: 0.1761 - categorical_accuracy: 0.4245 - val_loss: 0.2514 - val_categorical_accuracy: 0.1117\n",
      "\n",
      "Epoch 00012: saving model to 1xBilstm-12-0.25-0.11-singlelabel.hdf5\n",
      "Epoch 13/16\n",
      "149842/149842 [==============================] - 76s 508us/step - loss: 0.1750 - categorical_accuracy: 0.4290 - val_loss: 0.2580 - val_categorical_accuracy: 0.1015\n",
      "\n",
      "Epoch 00013: saving model to 1xBilstm-13-0.26-0.10-singlelabel.hdf5\n",
      "Epoch 14/16\n",
      "149842/149842 [==============================] - 72s 480us/step - loss: 0.1741 - categorical_accuracy: 0.4316 - val_loss: 0.2549 - val_categorical_accuracy: 0.1096\n",
      "\n",
      "Epoch 00014: saving model to 1xBilstm-14-0.25-0.11-singlelabel.hdf5\n",
      "Epoch 15/16\n",
      "149842/149842 [==============================] - 60s 403us/step - loss: 0.1731 - categorical_accuracy: 0.4346 - val_loss: 0.2558 - val_categorical_accuracy: 0.1104\n",
      "\n",
      "Epoch 00015: saving model to 1xBilstm-15-0.26-0.11-singlelabel.hdf5\n",
      "Epoch 16/16\n",
      "149842/149842 [==============================] - 65s 431us/step - loss: 0.1722 - categorical_accuracy: 0.4373 - val_loss: 0.2639 - val_categorical_accuracy: 0.1114\n",
      "\n",
      "Epoch 00016: saving model to 1xBilstm-16-0.26-0.11-singlelabel.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=16, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
