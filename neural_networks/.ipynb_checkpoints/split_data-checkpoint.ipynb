{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import keras\n",
    "from keras.layers import Dense,Embedding, Flatten, Conv1D, GlobalMaxPooling1D, LSTM, Bidirectional, Dropout\n",
    "from keras.preprocessing.text import text_to_word_sequence,Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../cryptic_dataset/combined_fifteen_times_final_filtered.pickle\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "anagram_df = df[\n",
    "    df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]\n",
    "homophone_df = df[\n",
    "    ~df.is_anagram &\n",
    "    df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]\n",
    "double_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]\n",
    "cryptic_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]\n",
    "contain_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]\n",
    "reverse_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]\n",
    "alternate_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]\n",
    "init_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]\n",
    "delete_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]\n",
    "\n",
    "charade_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]\n",
    "lit_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]\n",
    "hidden_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]\n",
    "spoonerism_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    df.is_spoonerism & \n",
    "    ~df.is_palindrome\n",
    "]\n",
    "palindrome_df = df[\n",
    "    ~df.is_anagram &\n",
    "    ~df.is_homophone &\n",
    "    ~df.is_double &\n",
    "    ~df.is_cryptic & \n",
    "    ~df.is_contain & \n",
    "    ~df.is_reverse & \n",
    "    ~df.is_alternate &\n",
    "    ~df.is_init & \n",
    "    ~df.is_delete & \n",
    "    ~df.is_charade & \n",
    "    ~df['is_&lit'] & \n",
    "    ~df.is_hidden & \n",
    "    ~df.is_spoonerism & \n",
    "    df.is_palindrome\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_types_dfs = [anagram_df,homophone_df,double_df,cryptic_df,contain_df,reverse_df,alternate_df,init_df,delete_df,lit_df,hidden_df,spoonerism_df,palindrome_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_types = 'is_anagram\tis_homophone\tis_double\tis_cryptic\tis_contain\tis_reverse\tis_alternate\tis_init\tis_delete\tis_&lit\tis_hidden\tis_spoonerism\tis_palindrome'.split('\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df,cc_type in zip(cc_types_dfs,cc_types):\n",
    "    df['category'] = cc_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_val_test(df):\n",
    "    length = len(df)\n",
    "    input_len = math.floor(length*0.9)\n",
    "    test_len = math.floor(length*0.1)\n",
    "    input_df = df[:input_len]\n",
    "    test_df = df[input_len:]\n",
    "    return input_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cc_types_df = pd.concat([get_input_val_test(df)[0] for df in cc_types_dfs]).sample(frac=1)\n",
    "test_cc_types_df = pd.concat([get_input_val_test(df)[1] for df in cc_types_dfs]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = input_cc_types_df.groupby('category').count().max()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [input_cc_types_df]\n",
    "for class_index, group in input_cc_types_df.groupby('category'):\n",
    "    sample = group.sample(max_size-len(group), replace=True, )\n",
    "    lst.append(sample)\n",
    "upsampled_input_cc_types_df = pd.concat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28187"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(upsampled_input_cc_types_df.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3138"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_cc_types_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1001755786113328"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_cc_types_df)/(len(upsampled_input_cc_types_df.drop_duplicates())+len(test_cc_types_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.concat([upsampled_input_cc_types_df.drop_duplicates(),test_cc_types_df]).drop_duplicates()) == len(upsampled_input_cc_types_df.drop_duplicates()) + len(test_cc_types_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsampled_input_cc_types_df.to_csv(\"../upsampled_train_test/upsampled_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_cc_types_df.to_csv(\"../upsampled_train_test/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
