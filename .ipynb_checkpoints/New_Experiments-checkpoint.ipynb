{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import keras\n",
    "from keras.layers import Dense,Embedding, Flatten, Conv1D, GlobalMaxPooling1D, LSTM, Bidirectional\n",
    "from keras.preprocessing.text import text_to_word_sequence,Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./cryptic_dataset/combined_fifteen_times_final.pickle\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_types = \"is_anagram\tis_homophone\tis_double\tis_cryptic\tis_contain\tis_reverse\tis_alternate\tis_init\tis_delete\tis_charade\tis_&lit\tis_hidden\tis_spoonerism\tis_palindrome\".split('\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.clue = df.clue.apply(text_to_word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_types_dfs = [df[df[cc_type]==True] for cc_type in cc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for cc_type,cc_type_df in zip(cc_types,cc_types_dfs):\n",
    "    cc_type_df['category'] = cc_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc_types_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_val_test(df):\n",
    "    length = len(df)\n",
    "    input_len = math.floor(length*0.7)\n",
    "    val_len  = math.floor(length*0.2)\n",
    "    test_len = math.floor(length*0.1)\n",
    "    input_df = df[:input_len]\n",
    "    val_df = df[input_len:input_len+val_len]\n",
    "    test_df = df[input_len+val_len:]\n",
    "    return input_df,val_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cc_types_df = pd.concat([get_input_val_test(df)[0] for df in cc_types_dfs])\n",
    "val_cc_types_df = pd.concat([get_input_val_test(df)[1] for df in cc_types_dfs])\n",
    "test_cc_types_df = pd.concat([get_input_val_test(df)[2] for df in cc_types_dfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = input_cc_types_df.groupby('category').count().max()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [input_cc_types_df]\n",
    "for class_index, group in input_cc_types_df.groupby('category'):\n",
    "    sample = group.sample(max_size-len(group), replace=True, )\n",
    "    lst.append(sample)\n",
    "upsampled_input_cc_types_df = pd.concat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_input_df = upsampled_input_cc_types_df.drop('category',axis=1)\n",
    "cc_val_df = val_cc_types_df.drop('category',axis=1).drop_duplicates()\n",
    "cc_test_df = test_cc_types_df.drop('category',axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df.clue.tolist())\n",
    "cc_input_data = pad_sequences(tokenizer.texts_to_sequences(cc_input_df.clue.tolist()),maxlen=15)\n",
    "cc_val_data = pad_sequences(tokenizer.texts_to_sequences(cc_val_df.clue.tolist()),maxlen=15)\n",
    "cc_test_data = pad_sequences(tokenizer.texts_to_sequences(cc_test_df.clue.tolist()),maxlen=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_input_data_out = cc_input_df[cc_input_df.columns[2:]] * 1\n",
    "cc_val_data_out = cc_val_df[cc_val_df.columns[2:]] * 1\n",
    "cc_test_data_out = cc_test_df[cc_test_df.columns[2:]] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300))\n",
    "model.add(Dense(14, activation='relu', input_dim=15))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358484 samples, validate on 16926 samples\n",
      "Epoch 1/6\n",
      "358484/358484 [==============================] - 10s 29us/step - loss: 2.7302 - categorical_accuracy: 0.1644 - val_loss: 1.9284 - val_categorical_accuracy: 0.2269\n",
      "Epoch 2/6\n",
      "358484/358484 [==============================] - 9s 25us/step - loss: 2.3165 - categorical_accuracy: 0.1818 - val_loss: 1.9150 - val_categorical_accuracy: 0.2309\n",
      "Epoch 3/6\n",
      "358484/358484 [==============================] - 9s 25us/step - loss: 2.3106 - categorical_accuracy: 0.1839 - val_loss: 1.9104 - val_categorical_accuracy: 0.2311\n",
      "Epoch 4/6\n",
      "358484/358484 [==============================] - 9s 25us/step - loss: 2.3088 - categorical_accuracy: 0.1843 - val_loss: 1.9127 - val_categorical_accuracy: 0.2330\n",
      "Epoch 5/6\n",
      "358484/358484 [==============================] - 9s 25us/step - loss: 2.3096 - categorical_accuracy: 0.1859 - val_loss: 1.9100 - val_categorical_accuracy: 0.2333\n",
      "Epoch 6/6\n",
      "358484/358484 [==============================] - 9s 25us/step - loss: 2.3093 - categorical_accuracy: 0.1857 - val_loss: 1.9096 - val_categorical_accuracy: 0.2340\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8475/8475 [==============================] - 0s 46us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8900460505415204, 0.22938053097345132]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300,input_length=15))\n",
    "model.add(Dense(300, activation='relu', input_dim=15))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 711924 samples, validate on 42542 samples\n",
      "Epoch 1/4\n",
      "711924/711924 [==============================] - 11s 16us/step - loss: 2.7505 - categorical_accuracy: 0.3063 - val_loss: 2.6746 - val_categorical_accuracy: 0.2312\n",
      "Epoch 2/4\n",
      "711924/711924 [==============================] - 10s 15us/step - loss: 2.7355 - categorical_accuracy: 0.3131 - val_loss: 2.6953 - val_categorical_accuracy: 0.2227\n",
      "Epoch 3/4\n",
      "711924/711924 [==============================] - 10s 15us/step - loss: 2.7349 - categorical_accuracy: 0.3134 - val_loss: 2.6953 - val_categorical_accuracy: 0.2227\n",
      "Epoch 4/4\n",
      "711924/711924 [==============================] - 10s 15us/step - loss: 2.7349 - categorical_accuracy: 0.3134 - val_loss: 2.6953 - val_categorical_accuracy: 0.2227\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16968/16968 [==============================] - 0s 17us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.777652508467225, 0.31347241867043846]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300,input_length=15))\n",
    "model.add(Dense(300, activation='sigmoid', input_dim=15))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 12s 26us/step - loss: 0.3623 - categorical_accuracy: 0.2733 - val_loss: 0.3074 - val_categorical_accuracy: 0.2127\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 12s 25us/step - loss: 0.3528 - categorical_accuracy: 0.2822 - val_loss: 0.3024 - val_categorical_accuracy: 0.3311\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 12s 25us/step - loss: 0.3464 - categorical_accuracy: 0.2847 - val_loss: 0.3041 - val_categorical_accuracy: 0.3002\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 12s 25us/step - loss: 0.3408 - categorical_accuracy: 0.2881 - val_loss: 0.3029 - val_categorical_accuracy: 0.2917\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300,input_length=15))\n",
    "model.add(Dense(300, activation='sigmoid', input_dim=15))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 17s 35us/step - loss: 0.3612 - categorical_accuracy: 0.2776 - val_loss: 0.3047 - val_categorical_accuracy: 0.3257\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 16s 33us/step - loss: 0.3472 - categorical_accuracy: 0.2888 - val_loss: 0.3023 - val_categorical_accuracy: 0.2896\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 16s 33us/step - loss: 0.3392 - categorical_accuracy: 0.2916 - val_loss: 0.3045 - val_categorical_accuracy: 0.3026\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 16s 33us/step - loss: 0.3315 - categorical_accuracy: 0.2933 - val_loss: 0.3047 - val_categorical_accuracy: 0.3212\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 9s 18us/step - loss: 0.3121 - categorical_accuracy: 0.3606 - val_loss: 0.2770 - val_categorical_accuracy: 0.3414\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 8s 16us/step - loss: 0.1623 - categorical_accuracy: 0.5833 - val_loss: 0.3133 - val_categorical_accuracy: 0.3344\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 8s 16us/step - loss: 0.1039 - categorical_accuracy: 0.6364 - val_loss: 0.3685 - val_categorical_accuracy: 0.3245\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 8s 16us/step - loss: 0.0760 - categorical_accuracy: 0.6496 - val_loss: 0.4256 - val_categorical_accuracy: 0.3246\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(Conv1D(filters=15,kernel_size=2))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 13s 28us/step - loss: 0.3132 - categorical_accuracy: 0.3622 - val_loss: 0.2806 - val_categorical_accuracy: 0.3209\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 12s 25us/step - loss: 0.1933 - categorical_accuracy: 0.4961 - val_loss: 0.3093 - val_categorical_accuracy: 0.3052\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 12s 24us/step - loss: 0.1522 - categorical_accuracy: 0.5294 - val_loss: 0.3411 - val_categorical_accuracy: 0.3040\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 12s 24us/step - loss: 0.1292 - categorical_accuracy: 0.5360 - val_loss: 0.3725 - val_categorical_accuracy: 0.2919\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=15))\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/10\n",
      "480706/480706 [==============================] - 22s 45us/step - loss: 0.3965 - categorical_accuracy: 0.2432 - val_loss: 0.3013 - val_categorical_accuracy: 0.3406\n",
      "Epoch 2/10\n",
      "480706/480706 [==============================] - 20s 41us/step - loss: 0.3287 - categorical_accuracy: 0.3195 - val_loss: 0.2875 - val_categorical_accuracy: 0.3196\n",
      "Epoch 3/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.2611 - categorical_accuracy: 0.4215 - val_loss: 0.2971 - val_categorical_accuracy: 0.3073\n",
      "Epoch 4/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.2048 - categorical_accuracy: 0.5103 - val_loss: 0.3144 - val_categorical_accuracy: 0.3185\n",
      "Epoch 5/10\n",
      "480706/480706 [==============================] - 20s 41us/step - loss: 0.1678 - categorical_accuracy: 0.5882 - val_loss: 0.3387 - val_categorical_accuracy: 0.3311\n",
      "Epoch 6/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.1401 - categorical_accuracy: 0.6242 - val_loss: 0.3645 - val_categorical_accuracy: 0.3281\n",
      "Epoch 7/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.1198 - categorical_accuracy: 0.6423 - val_loss: 0.3948 - val_categorical_accuracy: 0.3228\n",
      "Epoch 8/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.1046 - categorical_accuracy: 0.6477 - val_loss: 0.4164 - val_categorical_accuracy: 0.3355\n",
      "Epoch 9/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.0925 - categorical_accuracy: 0.6491 - val_loss: 0.4457 - val_categorical_accuracy: 0.3339\n",
      "Epoch 10/10\n",
      "480706/480706 [==============================] - 21s 43us/step - loss: 0.0828 - categorical_accuracy: 0.6541 - val_loss: 0.4727 - val_categorical_accuracy: 0.3281\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=15,dropout=0.5))\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/10\n",
      "480706/480706 [==============================] - 24s 51us/step - loss: 0.3896 - categorical_accuracy: 0.2492 - val_loss: 0.2951 - val_categorical_accuracy: 0.2055\n",
      "Epoch 2/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.3106 - categorical_accuracy: 0.2419 - val_loss: 0.2923 - val_categorical_accuracy: 0.2200\n",
      "Epoch 3/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2638 - categorical_accuracy: 0.3352 - val_loss: 0.2947 - val_categorical_accuracy: 0.2900\n",
      "Epoch 4/10\n",
      "480706/480706 [==============================] - 22s 45us/step - loss: 0.2280 - categorical_accuracy: 0.4346 - val_loss: 0.2994 - val_categorical_accuracy: 0.2927\n",
      "Epoch 5/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1998 - categorical_accuracy: 0.4691 - val_loss: 0.3095 - val_categorical_accuracy: 0.2929\n",
      "Epoch 6/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1833 - categorical_accuracy: 0.4925 - val_loss: 0.3201 - val_categorical_accuracy: 0.2955\n",
      "Epoch 7/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1719 - categorical_accuracy: 0.5095 - val_loss: 0.3377 - val_categorical_accuracy: 0.2941\n",
      "Epoch 8/10\n",
      "480706/480706 [==============================] - 23s 47us/step - loss: 0.1629 - categorical_accuracy: 0.5205 - val_loss: 0.3440 - val_categorical_accuracy: 0.3012\n",
      "Epoch 9/10\n",
      "480706/480706 [==============================] - 22s 47us/step - loss: 0.1558 - categorical_accuracy: 0.5286 - val_loss: 0.3580 - val_categorical_accuracy: 0.2966\n",
      "Epoch 10/10\n",
      "480706/480706 [==============================] - 23s 47us/step - loss: 0.1498 - categorical_accuracy: 0.5339 - val_loss: 0.3669 - val_categorical_accuracy: 0.2963\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=15,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/10\n",
      "480706/480706 [==============================] - 24s 50us/step - loss: 0.3729 - categorical_accuracy: 0.2750 - val_loss: 0.2868 - val_categorical_accuracy: 0.3534\n",
      "Epoch 2/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2979 - categorical_accuracy: 0.3678 - val_loss: 0.2798 - val_categorical_accuracy: 0.3122\n",
      "Epoch 3/10\n",
      "480706/480706 [==============================] - 22s 45us/step - loss: 0.2621 - categorical_accuracy: 0.3925 - val_loss: 0.2765 - val_categorical_accuracy: 0.2912\n",
      "Epoch 4/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2378 - categorical_accuracy: 0.3910 - val_loss: 0.2806 - val_categorical_accuracy: 0.2862\n",
      "Epoch 5/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2195 - categorical_accuracy: 0.3993 - val_loss: 0.2868 - val_categorical_accuracy: 0.2821\n",
      "Epoch 6/10\n",
      "480706/480706 [==============================] - 21s 45us/step - loss: 0.2054 - categorical_accuracy: 0.4168 - val_loss: 0.2885 - val_categorical_accuracy: 0.2942\n",
      "Epoch 7/10\n",
      "480706/480706 [==============================] - 21s 45us/step - loss: 0.1938 - categorical_accuracy: 0.4396 - val_loss: 0.2931 - val_categorical_accuracy: 0.2959\n",
      "Epoch 8/10\n",
      "480706/480706 [==============================] - 21s 45us/step - loss: 0.1837 - categorical_accuracy: 0.4620 - val_loss: 0.2958 - val_categorical_accuracy: 0.3023\n",
      "Epoch 9/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1755 - categorical_accuracy: 0.4806 - val_loss: 0.3047 - val_categorical_accuracy: 0.3062\n",
      "Epoch 10/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1686 - categorical_accuracy: 0.4963 - val_loss: 0.3069 - val_categorical_accuracy: 0.3098\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 63s 130us/step - loss: 0.3368 - categorical_accuracy: 0.3093 - val_loss: 0.2784 - val_categorical_accuracy: 0.3377\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 60s 125us/step - loss: 0.2544 - categorical_accuracy: 0.3886 - val_loss: 0.2754 - val_categorical_accuracy: 0.3392\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 59s 124us/step - loss: 0.2061 - categorical_accuracy: 0.4286 - val_loss: 0.2780 - val_categorical_accuracy: 0.3276\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 61s 127us/step - loss: 0.1781 - categorical_accuracy: 0.4674 - val_loss: 0.2845 - val_categorical_accuracy: 0.3838\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 131s 273us/step - loss: 0.2407 - categorical_accuracy: 0.4084 - val_loss: 0.2657 - val_categorical_accuracy: 0.3660\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 134s 278us/step - loss: 0.1200 - categorical_accuracy: 0.5198 - val_loss: 0.3120 - val_categorical_accuracy: 0.3779\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 129s 269us/step - loss: 0.0849 - categorical_accuracy: 0.5433 - val_loss: 0.3533 - val_categorical_accuracy: 0.3933\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 123s 256us/step - loss: 0.0670 - categorical_accuracy: 0.5531 - val_loss: 0.3648 - val_categorical_accuracy: 0.3614\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 144s 299us/step - loss: 0.2603 - categorical_accuracy: 0.3927 - val_loss: 0.2619 - val_categorical_accuracy: 0.3735\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 144s 300us/step - loss: 0.1281 - categorical_accuracy: 0.5149 - val_loss: 0.2991 - val_categorical_accuracy: 0.3854\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 141s 293us/step - loss: 0.0891 - categorical_accuracy: 0.5421 - val_loss: 0.3305 - val_categorical_accuracy: 0.3654\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 142s 294us/step - loss: 0.0699 - categorical_accuracy: 0.5525 - val_loss: 0.3636 - val_categorical_accuracy: 0.3623\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[top_3_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 155s 323us/step - loss: 0.2645 - top_3_accuracy: 0.6709 - val_loss: 0.2829 - val_top_3_accuracy: 0.6989\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 151s 315us/step - loss: 0.0995 - top_3_accuracy: 0.9275 - val_loss: 0.3524 - val_top_3_accuracy: 0.7083\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 156s 324us/step - loss: 0.0604 - top_3_accuracy: 0.9550 - val_loss: 0.4098 - val_top_3_accuracy: 0.6998\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 151s 314us/step - loss: 0.0439 - top_3_accuracy: 0.9633 - val_loss: 0.4590 - val_top_3_accuracy: 0.7104\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 144s 300us/step - loss: 0.2591 - top_3_accuracy: 0.6832 - val_loss: 0.2614 - val_top_3_accuracy: 0.7131\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 140s 292us/step - loss: 0.1269 - top_3_accuracy: 0.8907 - val_loss: 0.3014 - val_top_3_accuracy: 0.7368\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 139s 290us/step - loss: 0.0876 - top_3_accuracy: 0.9269 - val_loss: 0.3333 - val_top_3_accuracy: 0.7359\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 140s 292us/step - loss: 0.0685 - top_3_accuracy: 0.9408 - val_loss: 0.3611 - val_top_3_accuracy: 0.7363\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8475/8475 [==============================] - 2s 203us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3741736157664859, 0.7189380530903121]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cc_test_data,cc_test_data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy,'accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 135s 280us/step - loss: 0.2571 - top_3_accuracy: 0.6866 - acc: 0.8944 - categorical_accuracy: 0.3799 - val_loss: 0.2664 - val_top_3_accuracy: 0.7184 - val_acc: 0.8875 - val_categorical_accuracy: 0.3795\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 135s 280us/step - loss: 0.1281 - top_3_accuracy: 0.8894 - acc: 0.9481 - categorical_accuracy: 0.5082 - val_loss: 0.2937 - val_top_3_accuracy: 0.7343 - val_acc: 0.8843 - val_categorical_accuracy: 0.3934\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 131s 272us/step - loss: 0.0888 - top_3_accuracy: 0.9259 - acc: 0.9658 - categorical_accuracy: 0.5418 - val_loss: 0.3326 - val_top_3_accuracy: 0.7342 - val_acc: 0.8792 - val_categorical_accuracy: 0.3857\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 130s 271us/step - loss: 0.0696 - top_3_accuracy: 0.9397 - acc: 0.9741 - categorical_accuracy: 0.5522 - val_loss: 0.3629 - val_top_3_accuracy: 0.7288 - val_acc: 0.8783 - val_categorical_accuracy: 0.3844\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5)))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy,'accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"2xBilstm-{epoch:02d}-{val_loss:.2f}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358484 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "358484/358484 [==============================] - 94s 261us/step - loss: 0.0679 - top_3_accuracy: 0.9434 - acc: 0.9739 - categorical_accuracy: 0.5914 - val_loss: 0.3665 - val_top_3_accuracy: 0.7188 - val_acc: 0.8772 - val_categorical_accuracy: 0.3850\n",
      "\n",
      "Epoch 00001: saving model to 2xBilstm-01-0.37-0.39.hdf5\n",
      "Epoch 2/4\n",
      "358484/358484 [==============================] - 94s 263us/step - loss: 0.0613 - top_3_accuracy: 0.9476 - acc: 0.9767 - categorical_accuracy: 0.5897 - val_loss: 0.4108 - val_top_3_accuracy: 0.7012 - val_acc: 0.8706 - val_categorical_accuracy: 0.3561\n",
      "\n",
      "Epoch 00002: saving model to 2xBilstm-02-0.41-0.36.hdf5\n",
      "Epoch 3/4\n",
      "358484/358484 [==============================] - 94s 261us/step - loss: 0.0556 - top_3_accuracy: 0.9517 - acc: 0.9788 - categorical_accuracy: 0.5880 - val_loss: 0.3938 - val_top_3_accuracy: 0.7240 - val_acc: 0.8772 - val_categorical_accuracy: 0.3819\n",
      "\n",
      "Epoch 00003: saving model to 2xBilstm-03-0.39-0.38.hdf5\n",
      "Epoch 4/4\n",
      "358484/358484 [==============================] - 94s 261us/step - loss: 0.0512 - top_3_accuracy: 0.9535 - acc: 0.9806 - categorical_accuracy: 0.5852 - val_loss: 0.4308 - val_top_3_accuracy: 0.7143 - val_acc: 0.8719 - val_categorical_accuracy: 0.3810\n",
      "\n",
      "Epoch 00004: saving model to 2xBilstm-04-0.43-0.38.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=1024, epochs=4,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./trainHistoryDict', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d4927a29b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d4928d2f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize training history\n",
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8475/8475 [==============================] - 10s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.31330052172539863,\n",
       " 0.6825958701291267,\n",
       " 0.8748166782384776,\n",
       " 0.35622418887495644]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('50%_categorical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./2xBilstm-03-0.15-0.59.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27368/27368 [==============================] - 31s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14074560044130624,\n",
       " 0.8990061385559778,\n",
       " 0.9414096788787173,\n",
       " 0.6011400175387314]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(cc_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = cc_val_data_out - pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.absolute(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "error.to_csv('bilstm_error.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "!explorer ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2969.5"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc_val_df)/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5089.301023368861,\n",
       " 762.4743669615234,\n",
       " 2454.0194316451343,\n",
       " 1656.4140921296591,\n",
       " 10343.44581935413,\n",
       " 2204.0897995197242,\n",
       " 499.975531778603,\n",
       " 4319.007700273058,\n",
       " 9885.208288726579,\n",
       " 11999.036386445297,\n",
       " 406.4953425794674,\n",
       " 1292.0463068031086,\n",
       " 15.940705289792575,\n",
       " 26.371238619690075]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[error[cat].sum() for cat in cc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_anagram 0.5518053803934577\n",
      "is_homophone 0.30609167682116556\n",
      "is_double 0.6011806544941535\n",
      "is_cryptic 0.6089757691653158\n",
      "is_contain 0.5840784809618912\n",
      "is_reverse 0.3757398226252513\n",
      "is_alternate 0.6820948591795403\n",
      "is_init 0.7701511591071786\n",
      "is_delete 0.8669714338472706\n",
      "is_charade 0.8708205520317365\n",
      "is_&lit 0.47654788110136853\n",
      "is_hidden 0.4530316643769665\n",
      "is_spoonerism 0.09839941536908997\n",
      "is_palindrome 0.3995642215104557\n"
     ]
    }
   ],
   "source": [
    "error_col_sums = [error[cat].sum() for cat in cc_types]\n",
    "length_per_cat = [len(cc_val_df[cc_val_df[cat]==True]) for cat in cc_types]\n",
    "for cat,err,leng in zip(cc_types,error_col_sums,length_per_cat):\n",
    "    print(cat,err/leng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9223,\n",
       " 2491,\n",
       " 4082,\n",
       " 2720,\n",
       " 17709,\n",
       " 5866,\n",
       " 733,\n",
       " 5608,\n",
       " 11402,\n",
       " 13779,\n",
       " 853,\n",
       " 2852,\n",
       " 162,\n",
       " 66]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(cc_val_df[cc_val_df[cat]==True]) for cat in cc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['is_anagram', 'is_homophone', 'is_double', 'is_cryptic', 'is_contain',\n",
       "       'is_reverse', 'is_alternate', 'is_init', 'is_delete', 'is_charade',\n",
       "       'is_&lit', 'is_hidden', 'is_spoonerism', 'is_palindrome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_anagram',\n",
       " 'is_homophone',\n",
       " 'is_double',\n",
       " 'is_cryptic',\n",
       " 'is_contain',\n",
       " 'is_reverse',\n",
       " 'is_alternate',\n",
       " 'is_init',\n",
       " 'is_delete',\n",
       " 'is_charade',\n",
       " 'is_&lit',\n",
       " 'is_hidden',\n",
       " 'is_spoonerism',\n",
       " 'is_palindrome']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Proceeding smoothly and evenly, judge back observing cases'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt = pad_sequences(tokenizer.texts_to_sequences([query]),maxlen=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(inpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_anagram',\n",
       " 'is_homophone',\n",
       " 'is_double',\n",
       " 'is_cryptic',\n",
       " 'is_contain',\n",
       " 'is_reverse',\n",
       " 'is_alternate',\n",
       " 'is_init',\n",
       " 'is_delete',\n",
       " 'is_charade',\n",
       " 'is_&lit',\n",
       " 'is_hidden',\n",
       " 'is_spoonerism',\n",
       " 'is_palindrome']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_anagram 0.00080093107\n",
      "is_homophone 0.001205507\n",
      "is_double 0.00011718823\n",
      "is_cryptic 3.4680426e-05\n",
      "is_contain 0.9938917\n",
      "is_reverse 0.0020614178\n",
      "is_alternate 0.9986004\n",
      "is_init 2.895232e-06\n",
      "is_delete 0.01853707\n",
      "is_charade 0.0053280066\n",
      "is_&lit 3.5364006e-05\n",
      "is_hidden 0.00079043105\n",
      "is_spoonerism 1.4816669e-06\n",
      "is_palindrome 1.3082043e-05\n"
     ]
    }
   ],
   "source": [
    "for a,b in zip(cc_types,preds[0]):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5)))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy,'accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"3xBilstm-{epoch:02d}-{val_loss:.2f}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358484 samples, validate on 41573 samples\n",
      "Epoch 1/4\n",
      "358484/358484 [==============================] - 151s 422us/step - loss: 0.0826 - top_3_accuracy: 0.9334 - acc: 0.9671 - categorical_accuracy: 0.5997 - val_loss: 0.1175 - val_top_3_accuracy: 0.9118 - val_acc: 0.9529 - val_categorical_accuracy: 0.5970\n",
      "\n",
      "Epoch 00001: saving model to 3xBilstm-01-0.12-0.60.hdf5\n",
      "Epoch 2/4\n",
      "358484/358484 [==============================] - 148s 412us/step - loss: 0.0775 - top_3_accuracy: 0.9373 - acc: 0.9694 - categorical_accuracy: 0.5986 - val_loss: 0.1096 - val_top_3_accuracy: 0.9160 - val_acc: 0.9557 - val_categorical_accuracy: 0.5944\n",
      "\n",
      "Epoch 00002: saving model to 3xBilstm-02-0.11-0.59.hdf5\n",
      "Epoch 3/4\n",
      "358484/358484 [==============================] - 144s 401us/step - loss: 0.0729 - top_3_accuracy: 0.9400 - acc: 0.9713 - categorical_accuracy: 0.6010 - val_loss: 0.1078 - val_top_3_accuracy: 0.9255 - val_acc: 0.9566 - val_categorical_accuracy: 0.6311\n",
      "\n",
      "Epoch 00003: saving model to 3xBilstm-03-0.11-0.63.hdf5\n",
      "Epoch 4/4\n",
      "358484/358484 [==============================] - 144s 403us/step - loss: 0.0689 - top_3_accuracy: 0.9428 - acc: 0.9729 - categorical_accuracy: 0.5977 - val_loss: 0.0999 - val_top_3_accuracy: 0.9297 - val_acc: 0.9603 - val_categorical_accuracy: 0.6230\n",
      "\n",
      "Epoch 00004: saving model to 3xBilstm-04-0.10-0.62.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=1024, epochs=4,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
