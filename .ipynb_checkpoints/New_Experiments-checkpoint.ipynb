{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import keras\n",
    "from keras.layers import Dense,Embedding, Flatten, Conv1D, GlobalMaxPooling1D, LSTM, Bidirectional\n",
    "from keras.preprocessing.text import text_to_word_sequence,Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./cryptic_dataset/combined_fifteen_times_final_filtered.pickle\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A priest, old chap moved when digesting extremes of religiosity in unorthodox books \n",
      " APOCRYPHA : A + P(abbrev. for “priest”) + O(abbrev. for “old”) + { anagram of(moved) CHAP containing(when digesting) outermost letters of(extremes of) “religiousity” }. Answer: The books that are not accepted by certain faiths as being part of the Bible. \n",
      "clue             A priest, old chap moved when digesting extrem...\n",
      "exp               APOCRYPHA : A + P(abbrev. for “priest”) + O(a...\n",
      "is_anagram                                                    True\n",
      "is_homophone                                                 False\n",
      "is_double                                                    False\n",
      "is_cryptic                                                   False\n",
      "is_contain                                                    True\n",
      "is_reverse                                                   False\n",
      "is_alternate                                                 False\n",
      "is_init                                                      False\n",
      "is_delete                                                    False\n",
      "is_charade                                                    True\n",
      "is_&lit                                                      False\n",
      "is_hidden                                                    False\n",
      "is_spoonerism                                                False\n",
      "is_palindrome                                                False\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_index = 4\n",
    "print(df.iloc[df_index]['clue'])\n",
    "print(df.iloc[df_index]['exp'])\n",
    "print(df.iloc[df_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_types = \"is_anagram\tis_homophone\tis_double\tis_cryptic\tis_contain\tis_reverse\tis_alternate\tis_init\tis_delete\tis_charade\tis_&lit\tis_hidden\tis_spoonerism\tis_palindrome\".split('\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.clue = df.clue.apply(text_to_word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_types_dfs = [df[df[cc_type]==True] for cc_type in cc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for cc_type,cc_type_df in zip(cc_types,cc_types_dfs):\n",
    "    cc_type_df['category'] = cc_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc_types_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc_test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [df.sample(20) for df in cc_types_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(samples).to_csv(\"cryptic_clues_size20_samples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_val_test(df):\n",
    "    length = len(df)\n",
    "    input_len = math.floor(length*0.7)\n",
    "    val_len  = math.floor(length*0.2)\n",
    "    test_len = math.floor(length*0.1)\n",
    "    input_df = df[:input_len]\n",
    "    val_df = df[input_len:input_len+val_len]\n",
    "    test_df = df[input_len+val_len:]\n",
    "    return input_df,val_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cc_types_df = pd.concat([get_input_val_test(df)[0] for df in cc_types_dfs])\n",
    "val_cc_types_df = pd.concat([get_input_val_test(df)[1] for df in cc_types_dfs])\n",
    "test_cc_types_df = pd.concat([get_input_val_test(df)[2] for df in cc_types_dfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clue</th>\n",
       "      <th>exp</th>\n",
       "      <th>is_anagram</th>\n",
       "      <th>is_homophone</th>\n",
       "      <th>is_double</th>\n",
       "      <th>is_cryptic</th>\n",
       "      <th>is_contain</th>\n",
       "      <th>is_reverse</th>\n",
       "      <th>is_alternate</th>\n",
       "      <th>is_init</th>\n",
       "      <th>is_delete</th>\n",
       "      <th>is_charade</th>\n",
       "      <th>is_&amp;lit</th>\n",
       "      <th>is_hidden</th>\n",
       "      <th>is_spoonerism</th>\n",
       "      <th>is_palindrome</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89003</th>\n",
       "      <td>Altar? I’m nervous of marriage</td>\n",
       "      <td>*(altar im)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89013</th>\n",
       "      <td>What burglars use as the last resort</td>\n",
       "      <td>(THE LAST)* [* = resort]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89020</th>\n",
       "      <td>Shed a pound at one work-out</td>\n",
       "      <td>L (a pound) + (AT ONE)* [* = work-out]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89028</th>\n",
       "      <td>race he organised would keep you awake</td>\n",
       "      <td>(A RACE HE)* [* = organised] There’s actually...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89029</th>\n",
       "      <td>“All together” possibly means the Home Counties</td>\n",
       "      <td>(MEANS)* + SE (Home Counties, the South East)...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89033</th>\n",
       "      <td>Beautiful virgin of myth also roamed freely</td>\n",
       "      <td>AND (also) + (ROAMED)* [* = freely]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89037</th>\n",
       "      <td>Medicine prepared without one for such diseases</td>\n",
       "      <td>(MEDICINE minus I (one))* [* = prepared]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89044</th>\n",
       "      <td>Drink knocked back, around time chap crashes?</td>\n",
       "      <td>GIN (drink) backwards + T (time) in anagram o...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89045</th>\n",
       "      <td>Without limits, José Cura could be a legendary...</td>\n",
       "      <td>Anagram (could be) of [j]OS[e] CURA</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89048</th>\n",
       "      <td>Blokeish freak, needing shot of heroin, produc...</td>\n",
       "      <td>Anagram of BLOKEIS[h]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89061</th>\n",
       "      <td>Have meal in café? It may offer tea!</td>\n",
       "      <td>Reverse anagram of TEA</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89062</th>\n",
       "      <td>Son has more fancy new address</td>\n",
       "      <td>S (son) + anagram (fancy) of MORE + N (new)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89068</th>\n",
       "      <td>Opening for film score in motion picture</td>\n",
       "      <td>F[ilm] + anagram (in motion) of SCORE</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89076</th>\n",
       "      <td>Filled with power, great sun I suspect?</td>\n",
       "      <td>P (power) in anagram (suspect) of GREAT SUN I...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89078</th>\n",
       "      <td>Saviour, I am he, struggling to rescue ship</td>\n",
       "      <td>SS (ship) in anagram of I AM HE</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89081</th>\n",
       "      <td>Cleaner criminal opposed war</td>\n",
       "      <td>Anagram of OPPOSED WAR</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89087</th>\n",
       "      <td>Piper cares to play an organ</td>\n",
       "      <td>PAN (piper) + anagram (to play) of CARES</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89092</th>\n",
       "      <td>Fixed rate includes ten more</td>\n",
       "      <td>X (ten) in anagram (fixed) of RATE</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89098</th>\n",
       "      <td>An insect after metamorphosis, for example</td>\n",
       "      <td>Anagram of AN INSECT</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89107</th>\n",
       "      <td>Dodgy shiner not ultimately genuine</td>\n",
       "      <td>RHINESTONE : Anagram of(Dodgy) [SHINER NOT + ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89110</th>\n",
       "      <td>North African countries suffering big harm</td>\n",
       "      <td>MAGHRIB : Anagram of(suffering) BIG HARM. Ans...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89119</th>\n",
       "      <td>Managed to break into holiday home — it’s very...</td>\n",
       "      <td>GRANITE : RAN(managed, say, a business) conta...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89121</th>\n",
       "      <td>Billy Graham type is “OT/NT-basher”, put unfai...</td>\n",
       "      <td>SOUTHERN BAPTIST : Anagram of(… unfairly) IS ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89122</th>\n",
       "      <td>I mendset that’s broken for selling off</td>\n",
       "      <td>DIVESTMENT : Anagram of(… that’s broken) I ME...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89158</th>\n",
       "      <td>Breakfast ingredient fresh from fridge, for ex...</td>\n",
       "      <td>(FRIDGE + E.G. (for example))* [* = fresh from]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89159</th>\n",
       "      <td>Nave tidied up following a number of days of p...</td>\n",
       "      <td>(NAVE)*coming after NO ((a) number, numero) [...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89174</th>\n",
       "      <td>Terrible acting, so lacking in belief</td>\n",
       "      <td>(ACTING + SO)* [* = terrible]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89176</th>\n",
       "      <td>It goes amiss to be a selfish type</td>\n",
       "      <td>(IT GOES)* [* = amiss]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89186</th>\n",
       "      <td>The ego-trip of a German writer</td>\n",
       "      <td>(THE EGO)* [* = trip]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89188</th>\n",
       "      <td>Ridiculous pseuds holding potty assumptions a...</td>\n",
       "      <td>Anagram of (ridiculous) PSEUDS containing (h...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_anagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130159</th>\n",
       "      <td>Surrey town  in memo spelt the wrong way</td>\n",
       "      <td>EPSOM  - hidden in (in) a reversal of (the ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_hidden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130171</th>\n",
       "      <td>Port  imbibed by grandad enthusiastically</td>\n",
       "      <td>ADEN  - hidden word: grandAD ENthusiastical...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_hidden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130329</th>\n",
       "      <td>Somewhat fiendish  purpose</td>\n",
       "      <td>END  - hidden word: fiENDish   5   General ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_hidden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130379</th>\n",
       "      <td>Examine  some plain spectacles</td>\n",
       "      <td>INSPECT  – Hidden (some) in {pla}IN SPECT{acl...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_hidden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130384</th>\n",
       "      <td>Part ofnot entirely without a harvest</td>\n",
       "      <td>UTAH  - hidden in withoUT A Harvest   \\n</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_hidden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132043</th>\n",
       "      <td>Many a sparrow is too much for  abandoned baby...</td>\n",
       "      <td>nyas  - hidden in maNY A Sparrow. There is a ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_hidden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79855</th>\n",
       "      <td>Down According to Spooner, owed foolish person...</td>\n",
       "      <td>“due Nellie” Spoonerised</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is_spoonerism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80117</th>\n",
       "      <td>Interchange leads to dreary Slough, symbol of ...</td>\n",
       "      <td>BULLDOG DULL BOG [dreary Slough] with the ini...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is_spoonerism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80361</th>\n",
       "      <td>Spooner’s announced fight for nightwear</td>\n",
       "      <td>Spoonerism of “said box”.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is_spoonerism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80950</th>\n",
       "      <td>Wheel trim grips earth</td>\n",
       "      <td>SHEAVE SHAVE (trim) round or ‘gripping’ E (ea...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is_spoonerism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81043</th>\n",
       "      <td>Spooner’s poem to Chelsea that may go to one’s...</td>\n",
       "      <td>SUN BONNET A Spoonerism of BUN SONNET = “poem...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is_spoonerism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81558</th>\n",
       "      <td>“Dress will detract from the man” says Spooner</td>\n",
       "      <td>The Rev.William Archibald Spooner has a lot t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is_spoonerism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82454</th>\n",
       "      <td>29ABe first to sleep with leaders in trade? A ...</td>\n",
       "      <td>a useless venture / A Spoonerism that doesn’t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is_spoonerism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84371</th>\n",
       "      <td>Spooner’s insect labels – they may be kept in ...</td>\n",
       "      <td>spoonerism of BEE (insect) TAGS (labels)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is_spoonerism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88437</th>\n",
       "      <td>17AOpening hours of hostilities as described b...</td>\n",
       "      <td>opening / Spoonerism – The Rev Spooner (Oxfor...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is_spoonerism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89201</th>\n",
       "      <td>Noise of train overhead by coastal resident</td>\n",
       "      <td>CHOUGH (sounds like [overheard] CHUFF [noise...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is_spoonerism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89764</th>\n",
       "      <td>Looking for scandal? Reverend Spooner’s causin...</td>\n",
       "      <td>Spoonerism of ‘Making Ruck’=”causing punch-up”</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is_spoonerism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90169</th>\n",
       "      <td>Stealthily avoid Spooner’s spot of light breat...</td>\n",
       "      <td>SLIP BY : Spoonerism of “blip”(a spot of ligh...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is_spoonerism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90523</th>\n",
       "      <td>Multi-channel tech I designed with Spooner</td>\n",
       "      <td>(Tech I Spooner)*</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is_spoonerism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91400</th>\n",
       "      <td>It could be William Spooner’s cherished reputa...</td>\n",
       "      <td>FIRST NAME ‘Nursed fame’ – Spooner’s cherishe...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is_spoonerism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92465</th>\n",
       "      <td>Spooner’s fighting ’usky?</td>\n",
       "      <td>OUTBOUND OUTBOUND A spoonerism on BOUT ‘OUND ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is_spoonerism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95008</th>\n",
       "      <td>Lively movement in Spooner’s beer glass</td>\n",
       "      <td>a BITTER JUG for the Reverend Spooner</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is_spoonerism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97332</th>\n",
       "      <td>See 16  16, It’s easy to rouse Irish port, ac...</td>\n",
       "      <td>Spoonerism of ‘wake Cork’=”rouse Irish port”</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>is_spoonerism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82300</th>\n",
       "      <td>Stop rising and falling</td>\n",
       "      <td>PULL UP – palindrome</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>is_palindrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83100</th>\n",
       "      <td>Bit of exercise, going forwards and backwards</td>\n",
       "      <td>The ‘going forwards and backwards’ refers to ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>is_palindrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84588</th>\n",
       "      <td>Retired to one’s lair, whichever way one looks...</td>\n",
       "      <td>DENNED – palindrome.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>is_palindrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88008</th>\n",
       "      <td>Part of chronicles, one read both ways, Latin</td>\n",
       "      <td>ANNA (a chronicle and palindrome) then L (Lat...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>is_palindrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91544</th>\n",
       "      <td>Up-and-down Auntie?</td>\n",
       "      <td>Palindrome</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>is_palindrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95940</th>\n",
       "      <td>It’s bread whichever way you look at it</td>\n",
       "      <td>NAAN : A palindrome(… whichever way you look ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>is_palindrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96336</th>\n",
       "      <td>Public unmoved by direction of study</td>\n",
       "      <td>a palindrome i.e. “unmoved by direction of st...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>is_palindrome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12602 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     clue  \\\n",
       "89003                     Altar? I’m nervous of marriage    \n",
       "89013               What burglars use as the last resort    \n",
       "89020                       Shed a pound at one work-out    \n",
       "89028             race he organised would keep you awake    \n",
       "89029    “All together” possibly means the Home Counties    \n",
       "89033        Beautiful virgin of myth also roamed freely    \n",
       "89037    Medicine prepared without one for such diseases    \n",
       "89044      Drink knocked back, around time chap crashes?    \n",
       "89045   Without limits, José Cura could be a legendary...   \n",
       "89048   Blokeish freak, needing shot of heroin, produc...   \n",
       "89061               Have meal in café? It may offer tea!    \n",
       "89062                     Son has more fancy new address    \n",
       "89068           Opening for film score in motion picture    \n",
       "89076            Filled with power, great sun I suspect?    \n",
       "89078        Saviour, I am he, struggling to rescue ship    \n",
       "89081                       Cleaner criminal opposed war    \n",
       "89087                       Piper cares to play an organ    \n",
       "89092                       Fixed rate includes ten more    \n",
       "89098         An insect after metamorphosis, for example    \n",
       "89107                Dodgy shiner not ultimately genuine    \n",
       "89110         North African countries suffering big harm    \n",
       "89119   Managed to break into holiday home — it’s very...   \n",
       "89121   Billy Graham type is “OT/NT-basher”, put unfai...   \n",
       "89122            I mendset that’s broken for selling off    \n",
       "89158   Breakfast ingredient fresh from fridge, for ex...   \n",
       "89159   Nave tidied up following a number of days of p...   \n",
       "89174              Terrible acting, so lacking in belief    \n",
       "89176                 It goes amiss to be a selfish type    \n",
       "89186                    The ego-trip of a German writer    \n",
       "89188    Ridiculous pseuds holding potty assumptions a...   \n",
       "...                                                   ...   \n",
       "130159          Surrey town  in memo spelt the wrong way    \n",
       "130171         Port  imbibed by grandad enthusiastically    \n",
       "130329                       Somewhat fiendish  purpose     \n",
       "130379                    Examine  some plain spectacles    \n",
       "130384             Part ofnot entirely without a harvest    \n",
       "132043  Many a sparrow is too much for  abandoned baby...   \n",
       "79855   Down According to Spooner, owed foolish person...   \n",
       "80117   Interchange leads to dreary Slough, symbol of ...   \n",
       "80361            Spooner’s announced fight for nightwear    \n",
       "80950                             Wheel trim grips earth    \n",
       "81043   Spooner’s poem to Chelsea that may go to one’s...   \n",
       "81558     “Dress will detract from the man” says Spooner    \n",
       "82454   29ABe first to sleep with leaders in trade? A ...   \n",
       "84371   Spooner’s insect labels – they may be kept in ...   \n",
       "88437   17AOpening hours of hostilities as described b...   \n",
       "89201        Noise of train overhead by coastal resident    \n",
       "89764   Looking for scandal? Reverend Spooner’s causin...   \n",
       "90169   Stealthily avoid Spooner’s spot of light breat...   \n",
       "90523         Multi-channel tech I designed with Spooner    \n",
       "91400   It could be William Spooner’s cherished reputa...   \n",
       "92465                          Spooner’s fighting ’usky?    \n",
       "95008            Lively movement in Spooner’s beer glass    \n",
       "97332    See 16  16, It’s easy to rouse Irish port, ac...   \n",
       "82300                            Stop rising and falling    \n",
       "83100      Bit of exercise, going forwards and backwards    \n",
       "84588   Retired to one’s lair, whichever way one looks...   \n",
       "88008      Part of chronicles, one read both ways, Latin    \n",
       "91544                                Up-and-down Auntie?    \n",
       "95940            It’s bread whichever way you look at it    \n",
       "96336               Public unmoved by direction of study    \n",
       "\n",
       "                                                      exp  is_anagram  \\\n",
       "89003                                        *(altar im)         True   \n",
       "89013                           (THE LAST)* [* = resort]         True   \n",
       "89020             L (a pound) + (AT ONE)* [* = work-out]         True   \n",
       "89028    (A RACE HE)* [* = organised] There’s actually...        True   \n",
       "89029    (MEANS)* + SE (Home Counties, the South East)...        True   \n",
       "89033                AND (also) + (ROAMED)* [* = freely]         True   \n",
       "89037           (MEDICINE minus I (one))* [* = prepared]         True   \n",
       "89044    GIN (drink) backwards + T (time) in anagram o...        True   \n",
       "89045                Anagram (could be) of [j]OS[e] CURA         True   \n",
       "89048                              Anagram of BLOKEIS[h]         True   \n",
       "89061                             Reverse anagram of TEA         True   \n",
       "89062        S (son) + anagram (fancy) of MORE + N (new)         True   \n",
       "89068              F[ilm] + anagram (in motion) of SCORE         True   \n",
       "89076    P (power) in anagram (suspect) of GREAT SUN I...        True   \n",
       "89078                    SS (ship) in anagram of I AM HE         True   \n",
       "89081                             Anagram of OPPOSED WAR         True   \n",
       "89087           PAN (piper) + anagram (to play) of CARES         True   \n",
       "89092                 X (ten) in anagram (fixed) of RATE         True   \n",
       "89098                               Anagram of AN INSECT         True   \n",
       "89107    RHINESTONE : Anagram of(Dodgy) [SHINER NOT + ...        True   \n",
       "89110    MAGHRIB : Anagram of(suffering) BIG HARM. Ans...        True   \n",
       "89119    GRANITE : RAN(managed, say, a business) conta...        True   \n",
       "89121    SOUTHERN BAPTIST : Anagram of(… unfairly) IS ...        True   \n",
       "89122    DIVESTMENT : Anagram of(… that’s broken) I ME...        True   \n",
       "89158    (FRIDGE + E.G. (for example))* [* = fresh from]         True   \n",
       "89159    (NAVE)*coming after NO ((a) number, numero) [...        True   \n",
       "89174                      (ACTING + SO)* [* = terrible]         True   \n",
       "89176                             (IT GOES)* [* = amiss]         True   \n",
       "89186                              (THE EGO)* [* = trip]         True   \n",
       "89188     Anagram of (ridiculous) PSEUDS containing (h...        True   \n",
       "...                                                   ...         ...   \n",
       "130159     EPSOM  - hidden in (in) a reversal of (the ...       False   \n",
       "130171     ADEN  - hidden word: grandAD ENthusiastical...       False   \n",
       "130329     END  - hidden word: fiENDish   5   General ...       False   \n",
       "130379   INSPECT  – Hidden (some) in {pla}IN SPECT{acl...       False   \n",
       "130384           UTAH  - hidden in withoUT A Harvest   \\n       False   \n",
       "132043   nyas  - hidden in maNY A Sparrow. There is a ...       False   \n",
       "79855                           “due Nellie” Spoonerised        False   \n",
       "80117    BULLDOG DULL BOG [dreary Slough] with the ini...       False   \n",
       "80361                          Spoonerism of “said box”.        False   \n",
       "80950    SHEAVE SHAVE (trim) round or ‘gripping’ E (ea...       False   \n",
       "81043    SUN BONNET A Spoonerism of BUN SONNET = “poem...       False   \n",
       "81558    The Rev.William Archibald Spooner has a lot t...       False   \n",
       "82454    a useless venture / A Spoonerism that doesn’t...       False   \n",
       "84371           spoonerism of BEE (insect) TAGS (labels)        False   \n",
       "88437    opening / Spoonerism – The Rev Spooner (Oxfor...       False   \n",
       "89201     CHOUGH (sounds like [overheard] CHUFF [noise...       False   \n",
       "89764     Spoonerism of ‘Making Ruck’=”causing punch-up”        False   \n",
       "90169    SLIP BY : Spoonerism of “blip”(a spot of ligh...       False   \n",
       "90523                                  (Tech I Spooner)*         True   \n",
       "91400    FIRST NAME ‘Nursed fame’ – Spooner’s cherishe...       False   \n",
       "92465    OUTBOUND OUTBOUND A spoonerism on BOUT ‘OUND ...       False   \n",
       "95008              a BITTER JUG for the Reverend Spooner        False   \n",
       "97332       Spoonerism of ‘wake Cork’=”rouse Irish port”        False   \n",
       "82300                               PULL UP – palindrome        False   \n",
       "83100    The ‘going forwards and backwards’ refers to ...       False   \n",
       "84588                               DENNED – palindrome.        False   \n",
       "88008    ANNA (a chronicle and palindrome) then L (Lat...       False   \n",
       "91544                                         Palindrome        False   \n",
       "95940    NAAN : A palindrome(… whichever way you look ...       False   \n",
       "96336    a palindrome i.e. “unmoved by direction of st...       False   \n",
       "\n",
       "        is_homophone  is_double  is_cryptic  is_contain  is_reverse  \\\n",
       "89003          False      False       False       False       False   \n",
       "89013          False      False       False       False       False   \n",
       "89020          False      False       False       False       False   \n",
       "89028          False      False       False       False       False   \n",
       "89029          False      False       False       False       False   \n",
       "89033          False      False       False       False       False   \n",
       "89037          False      False       False       False       False   \n",
       "89044          False      False       False        True       False   \n",
       "89045          False      False       False       False       False   \n",
       "89048          False      False       False       False       False   \n",
       "89061          False      False       False       False        True   \n",
       "89062          False      False       False       False       False   \n",
       "89068          False      False       False       False       False   \n",
       "89076          False      False       False        True       False   \n",
       "89078          False      False       False        True       False   \n",
       "89081          False      False       False       False       False   \n",
       "89087          False      False       False       False       False   \n",
       "89092          False      False       False        True       False   \n",
       "89098          False      False       False       False       False   \n",
       "89107          False      False       False       False       False   \n",
       "89110          False      False       False       False       False   \n",
       "89119          False      False       False        True       False   \n",
       "89121          False      False       False       False       False   \n",
       "89122          False      False       False       False       False   \n",
       "89158          False      False       False       False       False   \n",
       "89159          False      False        True       False       False   \n",
       "89174          False      False       False       False       False   \n",
       "89176          False      False       False       False       False   \n",
       "89186          False      False       False       False       False   \n",
       "89188          False      False       False        True       False   \n",
       "...              ...        ...         ...         ...         ...   \n",
       "130159         False      False       False        True        True   \n",
       "130171         False      False       False       False       False   \n",
       "130329         False      False       False       False       False   \n",
       "130379         False      False       False        True       False   \n",
       "130384         False      False       False        True       False   \n",
       "132043         False      False       False        True       False   \n",
       "79855          False      False       False       False       False   \n",
       "80117          False      False       False       False       False   \n",
       "80361          False      False       False       False       False   \n",
       "80950          False      False       False       False       False   \n",
       "81043          False      False       False       False       False   \n",
       "81558          False      False       False       False       False   \n",
       "82454          False      False       False       False       False   \n",
       "84371          False      False       False       False       False   \n",
       "88437          False      False       False       False       False   \n",
       "89201           True      False       False        True       False   \n",
       "89764          False      False       False       False       False   \n",
       "90169          False      False       False       False       False   \n",
       "90523          False      False       False       False       False   \n",
       "91400          False      False       False       False       False   \n",
       "92465          False      False       False       False       False   \n",
       "95008          False      False       False       False       False   \n",
       "97332          False      False       False       False       False   \n",
       "82300          False      False       False       False       False   \n",
       "83100          False      False       False       False       False   \n",
       "84588          False      False       False       False       False   \n",
       "88008          False      False       False       False       False   \n",
       "91544          False      False       False       False       False   \n",
       "95940          False      False       False       False       False   \n",
       "96336          False      False       False       False       False   \n",
       "\n",
       "        is_alternate  is_init  is_delete  is_charade  is_&lit  is_hidden  \\\n",
       "89003          False    False      False       False    False      False   \n",
       "89013          False    False      False       False    False      False   \n",
       "89020          False    False      False        True    False      False   \n",
       "89028          False    False      False        True    False      False   \n",
       "89029          False    False      False        True    False      False   \n",
       "89033          False    False      False        True    False      False   \n",
       "89037          False    False       True       False    False      False   \n",
       "89044          False    False      False        True    False      False   \n",
       "89045          False    False       True       False    False      False   \n",
       "89048          False    False       True       False    False      False   \n",
       "89061          False    False      False       False    False      False   \n",
       "89062          False    False      False        True    False      False   \n",
       "89068          False    False       True        True    False      False   \n",
       "89076          False    False      False       False    False      False   \n",
       "89078          False    False      False       False    False      False   \n",
       "89081          False    False      False       False    False      False   \n",
       "89087          False    False      False        True    False      False   \n",
       "89092          False    False      False       False    False      False   \n",
       "89098          False    False      False       False    False      False   \n",
       "89107          False    False      False        True    False      False   \n",
       "89110          False    False      False       False    False      False   \n",
       "89119          False    False      False       False    False      False   \n",
       "89121          False    False      False        True    False      False   \n",
       "89122          False    False      False       False    False      False   \n",
       "89158          False    False      False        True    False      False   \n",
       "89159          False    False      False       False    False      False   \n",
       "89174          False    False      False        True    False      False   \n",
       "89176          False    False      False       False    False      False   \n",
       "89186          False    False      False       False    False      False   \n",
       "89188          False    False      False       False    False      False   \n",
       "...              ...      ...        ...         ...      ...        ...   \n",
       "130159         False    False      False       False    False       True   \n",
       "130171         False    False      False       False    False       True   \n",
       "130329         False    False      False        True    False       True   \n",
       "130379         False    False      False       False    False       True   \n",
       "130384         False    False       True       False    False       True   \n",
       "132043         False    False      False       False    False       True   \n",
       "79855          False    False      False       False    False      False   \n",
       "80117          False     True       True       False    False      False   \n",
       "80361          False    False      False       False    False      False   \n",
       "80950          False    False      False       False    False      False   \n",
       "81043          False    False      False       False    False      False   \n",
       "81558          False    False      False       False    False      False   \n",
       "82454          False     True      False        True    False      False   \n",
       "84371          False    False      False       False    False      False   \n",
       "88437          False    False      False       False    False      False   \n",
       "89201          False    False       True       False    False      False   \n",
       "89764          False    False      False       False    False      False   \n",
       "90169          False    False      False        True    False      False   \n",
       "90523          False    False      False       False    False      False   \n",
       "91400          False    False      False       False    False      False   \n",
       "92465          False    False      False       False    False      False   \n",
       "95008          False    False      False       False    False      False   \n",
       "97332          False    False      False       False    False      False   \n",
       "82300          False    False      False       False    False      False   \n",
       "83100          False    False      False       False    False      False   \n",
       "84588          False    False      False       False    False      False   \n",
       "88008          False    False      False       False    False      False   \n",
       "91544          False    False      False       False    False      False   \n",
       "95940          False    False      False       False    False      False   \n",
       "96336          False    False      False       False    False      False   \n",
       "\n",
       "        is_spoonerism  is_palindrome       category  \n",
       "89003           False          False     is_anagram  \n",
       "89013           False          False     is_anagram  \n",
       "89020           False          False     is_anagram  \n",
       "89028           False          False     is_anagram  \n",
       "89029           False          False     is_anagram  \n",
       "89033           False          False     is_anagram  \n",
       "89037           False          False     is_anagram  \n",
       "89044           False          False     is_anagram  \n",
       "89045           False          False     is_anagram  \n",
       "89048           False          False     is_anagram  \n",
       "89061           False          False     is_anagram  \n",
       "89062           False          False     is_anagram  \n",
       "89068           False          False     is_anagram  \n",
       "89076           False          False     is_anagram  \n",
       "89078           False          False     is_anagram  \n",
       "89081           False          False     is_anagram  \n",
       "89087           False          False     is_anagram  \n",
       "89092           False          False     is_anagram  \n",
       "89098           False          False     is_anagram  \n",
       "89107           False          False     is_anagram  \n",
       "89110           False          False     is_anagram  \n",
       "89119           False          False     is_anagram  \n",
       "89121           False          False     is_anagram  \n",
       "89122           False          False     is_anagram  \n",
       "89158           False          False     is_anagram  \n",
       "89159           False          False     is_anagram  \n",
       "89174           False          False     is_anagram  \n",
       "89176           False          False     is_anagram  \n",
       "89186           False          False     is_anagram  \n",
       "89188           False          False     is_anagram  \n",
       "...               ...            ...            ...  \n",
       "130159          False          False      is_hidden  \n",
       "130171          False          False      is_hidden  \n",
       "130329          False          False      is_hidden  \n",
       "130379          False          False      is_hidden  \n",
       "130384          False          False      is_hidden  \n",
       "132043          False          False      is_hidden  \n",
       "79855            True          False  is_spoonerism  \n",
       "80117            True          False  is_spoonerism  \n",
       "80361            True          False  is_spoonerism  \n",
       "80950            True          False  is_spoonerism  \n",
       "81043            True          False  is_spoonerism  \n",
       "81558            True          False  is_spoonerism  \n",
       "82454            True          False  is_spoonerism  \n",
       "84371            True          False  is_spoonerism  \n",
       "88437            True          False  is_spoonerism  \n",
       "89201            True          False  is_spoonerism  \n",
       "89764            True          False  is_spoonerism  \n",
       "90169            True          False  is_spoonerism  \n",
       "90523            True          False  is_spoonerism  \n",
       "91400            True          False  is_spoonerism  \n",
       "92465            True          False  is_spoonerism  \n",
       "95008            True          False  is_spoonerism  \n",
       "97332            True          False  is_spoonerism  \n",
       "82300           False           True  is_palindrome  \n",
       "83100           False           True  is_palindrome  \n",
       "84588           False           True  is_palindrome  \n",
       "88008           False           True  is_palindrome  \n",
       "91544           False           True  is_palindrome  \n",
       "95940           False           True  is_palindrome  \n",
       "96336           False           True  is_palindrome  \n",
       "\n",
       "[12602 rows x 17 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cc_types_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = input_cc_types_df.groupby('category').count().max()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clue</th>\n",
       "      <th>exp</th>\n",
       "      <th>is_anagram</th>\n",
       "      <th>is_homophone</th>\n",
       "      <th>is_double</th>\n",
       "      <th>is_cryptic</th>\n",
       "      <th>is_contain</th>\n",
       "      <th>is_reverse</th>\n",
       "      <th>is_alternate</th>\n",
       "      <th>is_init</th>\n",
       "      <th>is_delete</th>\n",
       "      <th>is_charade</th>\n",
       "      <th>is_&amp;lit</th>\n",
       "      <th>is_hidden</th>\n",
       "      <th>is_spoonerism</th>\n",
       "      <th>is_palindrome</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_&amp;lit</th>\n",
       "      <td>597</td>\n",
       "      <td>597</td>\n",
       "      <td>597</td>\n",
       "      <td>597</td>\n",
       "      <td>597</td>\n",
       "      <td>597</td>\n",
       "      <td>597</td>\n",
       "      <td>597</td>\n",
       "      <td>597</td>\n",
       "      <td>597</td>\n",
       "      <td>597</td>\n",
       "      <td>597</td>\n",
       "      <td>597</td>\n",
       "      <td>597</td>\n",
       "      <td>597</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_alternate</th>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_anagram</th>\n",
       "      <td>12961</td>\n",
       "      <td>12961</td>\n",
       "      <td>12961</td>\n",
       "      <td>12961</td>\n",
       "      <td>12961</td>\n",
       "      <td>12961</td>\n",
       "      <td>12961</td>\n",
       "      <td>12961</td>\n",
       "      <td>12961</td>\n",
       "      <td>12961</td>\n",
       "      <td>12961</td>\n",
       "      <td>12961</td>\n",
       "      <td>12961</td>\n",
       "      <td>12961</td>\n",
       "      <td>12961</td>\n",
       "      <td>12961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_charade</th>\n",
       "      <td>19784</td>\n",
       "      <td>19784</td>\n",
       "      <td>19784</td>\n",
       "      <td>19784</td>\n",
       "      <td>19784</td>\n",
       "      <td>19784</td>\n",
       "      <td>19784</td>\n",
       "      <td>19784</td>\n",
       "      <td>19784</td>\n",
       "      <td>19784</td>\n",
       "      <td>19784</td>\n",
       "      <td>19784</td>\n",
       "      <td>19784</td>\n",
       "      <td>19784</td>\n",
       "      <td>19784</td>\n",
       "      <td>19784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_contain</th>\n",
       "      <td>25606</td>\n",
       "      <td>25606</td>\n",
       "      <td>25606</td>\n",
       "      <td>25606</td>\n",
       "      <td>25606</td>\n",
       "      <td>25606</td>\n",
       "      <td>25606</td>\n",
       "      <td>25606</td>\n",
       "      <td>25606</td>\n",
       "      <td>25606</td>\n",
       "      <td>25606</td>\n",
       "      <td>25606</td>\n",
       "      <td>25606</td>\n",
       "      <td>25606</td>\n",
       "      <td>25606</td>\n",
       "      <td>25606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_cryptic</th>\n",
       "      <td>2042</td>\n",
       "      <td>2042</td>\n",
       "      <td>2042</td>\n",
       "      <td>2042</td>\n",
       "      <td>2042</td>\n",
       "      <td>2042</td>\n",
       "      <td>2042</td>\n",
       "      <td>2042</td>\n",
       "      <td>2042</td>\n",
       "      <td>2042</td>\n",
       "      <td>2042</td>\n",
       "      <td>2042</td>\n",
       "      <td>2042</td>\n",
       "      <td>2042</td>\n",
       "      <td>2042</td>\n",
       "      <td>2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_delete</th>\n",
       "      <td>14713</td>\n",
       "      <td>14713</td>\n",
       "      <td>14713</td>\n",
       "      <td>14713</td>\n",
       "      <td>14713</td>\n",
       "      <td>14713</td>\n",
       "      <td>14713</td>\n",
       "      <td>14713</td>\n",
       "      <td>14713</td>\n",
       "      <td>14713</td>\n",
       "      <td>14713</td>\n",
       "      <td>14713</td>\n",
       "      <td>14713</td>\n",
       "      <td>14713</td>\n",
       "      <td>14713</td>\n",
       "      <td>14713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_double</th>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_hidden</th>\n",
       "      <td>2117</td>\n",
       "      <td>2117</td>\n",
       "      <td>2117</td>\n",
       "      <td>2117</td>\n",
       "      <td>2117</td>\n",
       "      <td>2117</td>\n",
       "      <td>2117</td>\n",
       "      <td>2117</td>\n",
       "      <td>2117</td>\n",
       "      <td>2117</td>\n",
       "      <td>2117</td>\n",
       "      <td>2117</td>\n",
       "      <td>2117</td>\n",
       "      <td>2117</td>\n",
       "      <td>2117</td>\n",
       "      <td>2117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_homophone</th>\n",
       "      <td>1843</td>\n",
       "      <td>1843</td>\n",
       "      <td>1843</td>\n",
       "      <td>1843</td>\n",
       "      <td>1843</td>\n",
       "      <td>1843</td>\n",
       "      <td>1843</td>\n",
       "      <td>1843</td>\n",
       "      <td>1843</td>\n",
       "      <td>1843</td>\n",
       "      <td>1843</td>\n",
       "      <td>1843</td>\n",
       "      <td>1843</td>\n",
       "      <td>1843</td>\n",
       "      <td>1843</td>\n",
       "      <td>1843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_init</th>\n",
       "      <td>1770</td>\n",
       "      <td>1770</td>\n",
       "      <td>1770</td>\n",
       "      <td>1770</td>\n",
       "      <td>1770</td>\n",
       "      <td>1770</td>\n",
       "      <td>1770</td>\n",
       "      <td>1770</td>\n",
       "      <td>1770</td>\n",
       "      <td>1770</td>\n",
       "      <td>1770</td>\n",
       "      <td>1770</td>\n",
       "      <td>1770</td>\n",
       "      <td>1770</td>\n",
       "      <td>1770</td>\n",
       "      <td>1770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_palindrome</th>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_reverse</th>\n",
       "      <td>5618</td>\n",
       "      <td>5618</td>\n",
       "      <td>5618</td>\n",
       "      <td>5618</td>\n",
       "      <td>5618</td>\n",
       "      <td>5618</td>\n",
       "      <td>5618</td>\n",
       "      <td>5618</td>\n",
       "      <td>5618</td>\n",
       "      <td>5618</td>\n",
       "      <td>5618</td>\n",
       "      <td>5618</td>\n",
       "      <td>5618</td>\n",
       "      <td>5618</td>\n",
       "      <td>5618</td>\n",
       "      <td>5618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_spoonerism</th>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                clue    exp  is_anagram  is_homophone  is_double  is_cryptic  \\\n",
       "category                                                                       \n",
       "is_&lit          597    597         597           597        597         597   \n",
       "is_alternate     513    513         513           513        513         513   \n",
       "is_anagram     12961  12961       12961         12961      12961       12961   \n",
       "is_charade     19784  19784       19784         19784      19784       19784   \n",
       "is_contain     25606  25606       25606         25606      25606       25606   \n",
       "is_cryptic      2042   2042        2042          2042       2042        2042   \n",
       "is_delete      14713  14713       14713         14713      14713       14713   \n",
       "is_double        403    403         403           403        403         403   \n",
       "is_hidden       2117   2117        2117          2117       2117        2117   \n",
       "is_homophone    1843   1843        1843          1843       1843        1843   \n",
       "is_init         1770   1770        1770          1770       1770        1770   \n",
       "is_palindrome     46     46          46            46         46          46   \n",
       "is_reverse      5618   5618        5618          5618       5618        5618   \n",
       "is_spoonerism    113    113         113           113        113         113   \n",
       "\n",
       "               is_contain  is_reverse  is_alternate  is_init  is_delete  \\\n",
       "category                                                                  \n",
       "is_&lit               597         597           597      597        597   \n",
       "is_alternate          513         513           513      513        513   \n",
       "is_anagram          12961       12961         12961    12961      12961   \n",
       "is_charade          19784       19784         19784    19784      19784   \n",
       "is_contain          25606       25606         25606    25606      25606   \n",
       "is_cryptic           2042        2042          2042     2042       2042   \n",
       "is_delete           14713       14713         14713    14713      14713   \n",
       "is_double             403         403           403      403        403   \n",
       "is_hidden            2117        2117          2117     2117       2117   \n",
       "is_homophone         1843        1843          1843     1843       1843   \n",
       "is_init              1770        1770          1770     1770       1770   \n",
       "is_palindrome          46          46            46       46         46   \n",
       "is_reverse           5618        5618          5618     5618       5618   \n",
       "is_spoonerism         113         113           113      113        113   \n",
       "\n",
       "               is_charade  is_&lit  is_hidden  is_spoonerism  is_palindrome  \n",
       "category                                                                     \n",
       "is_&lit               597      597        597            597            597  \n",
       "is_alternate          513      513        513            513            513  \n",
       "is_anagram          12961    12961      12961          12961          12961  \n",
       "is_charade          19784    19784      19784          19784          19784  \n",
       "is_contain          25606    25606      25606          25606          25606  \n",
       "is_cryptic           2042     2042       2042           2042           2042  \n",
       "is_delete           14713    14713      14713          14713          14713  \n",
       "is_double             403      403        403            403            403  \n",
       "is_hidden            2117     2117       2117           2117           2117  \n",
       "is_homophone         1843     1843       1843           1843           1843  \n",
       "is_init              1770     1770       1770           1770           1770  \n",
       "is_palindrome          46       46         46             46             46  \n",
       "is_reverse           5618     5618       5618           5618           5618  \n",
       "is_spoonerism         113      113        113            113            113  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_cc_types_df.groupby('category').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [input_cc_types_df]\n",
    "for class_index, group in input_cc_types_df.groupby('category'):\n",
    "    sample = group.sample(max_size-len(group), replace=True, )\n",
    "    lst.append(sample)\n",
    "upsampled_input_cc_types_df = pd.concat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_input_df = upsampled_input_cc_types_df.drop('category',axis=1)\n",
    "cc_val_df = val_cc_types_df.drop('category',axis=1).drop_duplicates()\n",
    "cc_test_df = test_cc_types_df.drop('category',axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df.clue.tolist())\n",
    "cc_input_data = pad_sequences(tokenizer.texts_to_sequences(cc_input_df.clue.tolist()),maxlen=15)\n",
    "cc_val_data = pad_sequences(tokenizer.texts_to_sequences(cc_val_df.clue.tolist()),maxlen=15)\n",
    "cc_test_data = pad_sequences(tokenizer.texts_to_sequences(cc_test_df.clue.tolist()),maxlen=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stubbornness ruined body defending posh group of drivers ',\n",
       " 'A priest, old chap moved when digesting extremes of religiosity in unorthodox books ',\n",
       " 'Dubious name associated with individual plant ',\n",
       " 'Opportunist always following Cuban revolutionary around college ',\n",
       " 'Stay hiker disrupted with no end of drink in a frenzied state ',\n",
       " 'Awkward to-do amid bow, say, in part of church ',\n",
       " 'Preserve trailed by celebrated baseball player in capital ',\n",
       " 'Candour unwisely shown about large witches’ pot ',\n",
       " 'Children’s author had dollar exchanged ',\n",
       " 'Dagger found in street by messy toilet ',\n",
       " 'Language used when armchair almost collapsed ',\n",
       " 'Get near volatile chemical substance ',\n",
       " 'Article put in last, possibly at an angle ',\n",
       " 'Pickled sot, half unwell, found nirvana in drink barrel ',\n",
       " 'Colour and curious tint mixed by small urchin ',\n",
       " 'It’s a tragedy how foul Macbeth butchered new duke ',\n",
       " 'Perhaps pink eggs with red tea? Romantic supper ',\n",
       " 'Vera and I dance like this for a hunk ',\n",
       " 'Thin material fashions elegant grey coat ',\n",
       " 'Responsible for eating a hot stew ',\n",
       " 'Complaint from guy pissed with Labour’s extremes ',\n",
       " 'Say someone did something bad, screwing up time? ',\n",
       " 'Throb near to crack that’s odious ',\n",
       " 'Top off, “old boy” freed, Kurt Cobain gyrates with hard-on, as a show-starter ',\n",
       " 'Boris, broken with age, loveless – a minor TV character ',\n",
       " 'Establishment also contrived Cameron’s end ',\n",
       " 'Was on manoeuvres with females, so removed from board? ',\n",
       " 'Green, jumped-up sort demands a parliamentary enforcer for each paparazzo ',\n",
       " 'Proof of innocence given by setter during arrangement of bail ',\n",
       " 'Alternative source of milk for ewe’s runt organised ',\n",
       " 'Disturbed Derby’s second rider with odds fix ',\n",
       " 'Actors with neat arrangement for half an instrument ',\n",
       " 'Fluffed lines — time to sign up ',\n",
       " 'Great golfer superior to these messing about ',\n",
       " 'Attend to drunken son beset by booze ',\n",
       " 'Biological groups sure began to evolve ',\n",
       " 'Our mistress, no maiden, is looking silly in traditional male garment ',\n",
       " 'Never heard of him until I have to google him for this blog 23 Brighter lady involved with boy in audacious act of exploitation ',\n",
       " 'Alien foe erring unexpectedly ',\n",
       " 'Marine life form hurricanes unsettled — number finally destroyed ',\n",
       " 'Star terribly coy about nasty porn? Quite the opposite ',\n",
       " 'Pass out leek recipe? ',\n",
       " 'Insincere praise for pelvic rise exercise ',\n",
       " 'One spins around heavy star without it ',\n",
       " 'Swift work women learnt in translation in a day ',\n",
       " 'Older stars transformed Swift work ',\n",
       " 'Martial piece, say, tackled by wayward genius ',\n",
       " 'Magicians in Glubbdubdrib, terribly cross about rulers ',\n",
       " 'Upset spirit that shuffled about in the dark ',\n",
       " 'Opponent of progress diluted fluid ',\n",
       " 'Pantograph user creates squiggles round itself? Not in the morning ',\n",
       " 'Found emigration tricky after money ran out ',\n",
       " 'How one looks in new change of attire? ',\n",
       " ' Feels master’s almost finished rewriting Scene 1 ',\n",
       " ' What might help a photographer get clearer pictures is sun mixed with sleet ',\n",
       " ' Treatment of an ulcer that’s hard to understand ',\n",
       " ' Manageress belly dancing for governing body ',\n",
       " ' Electronic number in version remixed for club ',\n",
       " '1DRock act promotes fifties clubs: one makes albums ',\n",
       " '4DScrawled on old note one last letter resembling capital? ',\n",
       " '7DFirst-placer from Aintree’s odds on for Cheltenham? ',\n",
       " 'Together as earlier? Yes, man almost smitten ',\n",
       " 'Turkish bread recipe for millions in S American capital ',\n",
       " 'Head of safety ordered carbon and steel picks ',\n",
       " 'Greta is upset and bristles ',\n",
       " 'Ideal is to refurbish seats in church ',\n",
       " 'I’m no lunatic, coming in to reduce hate ',\n",
       " 'Dude perhaps worried at the end of term ',\n",
       " 'Throbs wildly holding club’s top dish ',\n",
       " 'La Costa resort by the sea ',\n",
       " 'Jo prayed to be free of danger ',\n",
       " 'Coal rise affected heating units ',\n",
       " 'Talk toabout a powerful measure ',\n",
       " 'Components of a company troublingat present ',\n",
       " 'Rock band with two number ones so bad ',\n",
       " 'Chaser o’er ground? ',\n",
       " 'Prayer that could take people to a different level ',\n",
       " 'Novice making a mess of one contest, say ',\n",
       " 'Major confusion of other mortals with me ',\n",
       " 'energy varies with sun – that’s neat ',\n",
       " ' Noxious chemicals distorted plants left out ',\n",
       " 'New pie chart and inscription ',\n",
       " 'Passing a new variety of maple here ',\n",
       " 'Gremlins able to produce statuary from Athens ',\n",
       " 'No gents prepared to step into the light during a winter solstice ',\n",
       " 'He paints foreign actor ',\n",
       " 'Pale trio, ill-informed, producing a hair-remover ',\n",
       " 'Stage direction when these are off ',\n",
       " 'Pirate coined new term for reduction in value ',\n",
       " 'Let’s rise anew with boundless energy! ',\n",
       " 'The French near building are less encumbered ',\n",
       " 'Wickedness ends daily activity ',\n",
       " 'Wrought iron, hot with reason like study of 19s, say ',\n",
       " 'Blairist many construed as concerned with race ',\n",
       " 'Writer lost plot with trifle ',\n",
       " 'It’s more the difficult matter to be proved ',\n",
       " 'One quits in clean fashion, which is futile ',\n",
       " 'Vegetable is hard to cultivate ',\n",
       " 'Oddly, I want the termite ',\n",
       " 'No gin — my one failing, a disgrace ',\n",
       " 'Set aside for being hopelessly ecstasy-addicted ',\n",
       " 'rat coming out on an unequal social footing ',\n",
       " 'Recipient of from dead seers, weirdly ',\n",
       " 'Toponym constituting source of “Love and peace, man” ',\n",
       " 'Instrument for brewing ales etc ',\n",
       " 'Bitterly worked out our alimony [sic] ',\n",
       " 'Wasted cold rations, eating last bits of Dutch cheese ',\n",
       " 'Antarctic troops haul up ',\n",
       " 'One mostly gloating about depressed figures? ',\n",
       " 'More than one star acts on Sorry! ',\n",
       " 'Crib clue for “melting pot” ',\n",
       " 'Earl created king ',\n",
       " 'Cast Pete in play and watch ',\n",
       " 'Straying in herd can result in obstruction ',\n",
       " 'Raises a secret amendment ',\n",
       " 'Split up and set off with compass ',\n",
       " 'Some fine tuning for new task we accepted ',\n",
       " 'Cinema broadcast shows nervous wrens meeting slippery character ',\n",
       " 'Design style redcoat ordered ',\n",
       " 'Painter meant to be different ',\n",
       " 'They’re proverbially poor children supported by posh children in organised crime ',\n",
       " 'Lowest point in drain in need of repair ',\n",
       " 'Draw left good swimmer last in relay ',\n",
       " 'Departed behind schedule ',\n",
       " 'I’m great playing Scott Joplin music ',\n",
       " ' Company repaired old china showing type of fracture ',\n",
       " ' Crazily hot on girl displaying thingamy ',\n",
       " ' Mum in grip of drastic trembling, emoting wildly ',\n",
       " ' Nut tree, red leaves clipped ',\n",
       " ' Man in battered RR, not hip, bird-like figure ',\n",
       " ' Concoction of phenol that’s given relief in former days ',\n",
       " ' Cripple a panic disturbed, name receiving cheers ',\n",
       " ' Gentile’s faith of old hidden in mini-chest ',\n",
       " ' Graces bust – cache for love-letter ',\n",
       " 'Fancy Lorraine getting behind France, finally, in the past? ',\n",
       " 'First to tell funny story about king and revolutionary ',\n",
       " 'So don’t regret getting different dog ',\n",
       " 'Round-the-clock work blocking busy line in old city ',\n",
       " 'Suitable model brought in by a new Pope ',\n",
       " 'One delivering shopkeeper’s goods may be confused by an order ',\n",
       " 'Swallow, initially, a spot of outrageously used flattery ',\n",
       " 'Port Labrador sacked ',\n",
       " 'Explosive star and moon unknown in relevant study ',\n",
       " 'This might ultimately do leap after development! ',\n",
       " 'Fool roaming around with compilers ',\n",
       " 'Mac Flecknoe was his laconic study ',\n",
       " 'Sirocco winds in middle of summer — small world! ',\n",
       " 'sweet conical arrangement of sulphur and flour cooked with Aga ',\n",
       " 'Plant developed a curl of the smallest chemical bit ',\n",
       " 'One ran admin by arrangement ',\n",
       " 'Has racist agitated for purification? ',\n",
       " 'Thorn’s dealt with in a way ',\n",
       " 'Robust and hearty eccentric ',\n",
       " 'Stucco is a puzzle to science ',\n",
       " 'Philosopher’s daughter stupidly rioted ',\n",
       " 'Abnormal respect for symbol of authority ',\n",
       " 'Turned up in badly made trousers, Earl? ',\n",
       " 'Modest problem contained by using an orderly ',\n",
       " 'Embarrassing lunge stops short with erotic dancing ',\n",
       " 'Instrument integral to work ',\n",
       " 'Giant sort of painting turning up, as carved design ',\n",
       " 'Compound sat in hole for laboratory device ',\n",
       " ' I’m amazed to comprehend awful drivel making outlook on life ',\n",
       " ' One having big bill in place that’s falling apart',\n",
       " ' Non-kosher ingredient for cooking plant ',\n",
       " ' Got rid of soap actor finally – Den is murdered ',\n",
       " ' Does paper over cracked centre of plaster, sized ',\n",
       " 'Composer of swing with her composition ',\n",
       " 'Most of Chinese Gordon’s vacillation during War brings dismissal ',\n",
       " 'No relative may make such a telling statement ',\n",
       " 'Helps beast in distress ',\n",
       " 'Excursions from Tunis go free ',\n",
       " 'Purge has racist components ',\n",
       " 'Feeling I’m one to get pushed around ',\n",
       " 'One from the country drew out guide, only to leave unmoved ',\n",
       " 'Perhaps a case for adopting some Citicorp handling? ',\n",
       " 'Director’s power to keep in employment? no thanks ',\n",
       " 'One’s fare should be idle and be carried away ',\n",
       " 'Underdeveloped area in Hebridean isle making great progress ',\n",
       " 'Noted director fromseen unexpectedly having prepared talk with composer ',\n",
       " 'Retired Catholic getting unusually irate about Independent standards? ',\n",
       " 'Select deals arranged for Kent tourist attraction ',\n",
       " 'Obscure diet once devised after gourmet’s heart ',\n",
       " 'Abundance of crystals treating ailments ',\n",
       " 'Urgent: couple of Latins getting frisky in clandestine love affair ',\n",
       " 'Describing lung membranes, soft with questionable allure ',\n",
       " 'Start lap dancing, showing tail? ',\n",
       " 'Elegant, idly swimming in water ',\n",
       " 'Saint Paul’s man, perhaps, finding one with Saint Martin extremely unreliable ',\n",
       " 'Number in frilly drape, slightly wavy ',\n",
       " 'Old canto – it’s bound in pink paper ',\n",
       " 'Poem that’s upset one with depression ',\n",
       " 'Teen party, dancing? Here’s an attractive evergreen ',\n",
       " 'Creates pets frolicking, a Lowry speciality? ',\n",
       " 'Apple that may come from dark trees, grown wild ',\n",
       " 'One mineral enclosing another hopper crushed round edge ',\n",
       " 'German king has right to seize gold ',\n",
       " '[Casting off] mark of status? ',\n",
       " 'Deep rim is reshaped to form outer [stone] covering ',\n",
       " 'With difficulty manage endless real estate [elision] for Seller’s former spouse ',\n",
       " 'Extra person departs to India in a roundabout way ',\n",
       " 'Le Carré novel, more readable ',\n",
       " 'Vessel’s gone out with everybody on board ',\n",
       " 'Hanger-on ruined pair’s tea ',\n",
       " 'Type of cattle under an ageaffected? ',\n",
       " 'Unfortunately did for two found washed up on a beach? ',\n",
       " 'Sold us roe, processed, having no smell ',\n",
       " 'Chewing caramels and beginning to think he’s so clever ',\n",
       " 'County set berserk — berserk! — about contents of this ',\n",
       " 'Emsworth resolved to avoid women and female relations ',\n",
       " 'Albert’s cap found next to lion, dead annoyed and sounding stuffed ',\n",
       " 'Neat gin, skipping tonic ',\n",
       " 'Old prince ugly like a pig ',\n",
       " 'Pauli with no funds, somehow — that’s embarrassing ',\n",
       " 'Abstract painters’ oil ',\n",
       " 'What may produce bangs that could be supersonic ',\n",
       " 'Film in San Marino not so bad ',\n",
       " 'Some err, wanting new direction — feeling this? ',\n",
       " 'Give up work, when under the doctor ',\n",
       " 'Lecturer, a figure in mathematics, brief and to the point ',\n",
       " 'Bradford car firm which produced the Javelin and developed Jet',\n",
       " 'Henry Langridge lashed out at large kite ',\n",
       " 'Roofless Stanhope rebuilt as this? ',\n",
       " 'Liner – it can’t crash ',\n",
       " 'Points out very different 1950s Vauxhall model ',\n",
       " 'Standard variation of nine weights ',\n",
       " 'The police broke rule for a Chinook ',\n",
       " 'Illness of US soldier having to sit out under gate in Ypres ',\n",
       " 'Emergency rations bringing out the camp in me ',\n",
       " 'Formed from diamonds under loose heaps ',\n",
       " 'Doctor missed unusual quake ',\n",
       " 'got grass tool out – as one interested in such? ',\n",
       " 'Countess, fine in character innately ',\n",
       " 'One has to grieve having lost last love ',\n",
       " 'Where mutiny holds sway mostly more bleed at sea ',\n",
       " 'Wind? As to this – not trades possibly ',\n",
       " '1ARogue doctor mostly trading through the Internet ',\n",
       " '13ARuddy Ford I left rotting ',\n",
       " '15AEndless Listener puzzles can be drawn out ',\n",
       " '21AAfricans born in India returned in due course ',\n",
       " '38Aunit trained to keep going ',\n",
       " '40AMixed nougat and nuts scoffed by a girl ',\n",
       " '5DAccidentally reveal a table containing universal basis for tax assessment ',\n",
       " '11DOne inquiring about railroad moulding tool ',\n",
       " '29Dpotion I’d spiked with ecstasy could yield this neat narcotic ',\n",
       " 'Picks up little boxes extremely eager to find gun (10,5)',\n",
       " 'Michelle? Douglas? Boy’s in a mess ',\n",
       " 'Rock group praised for playing during fair ',\n",
       " 'Admitting nothing in crash I paid off the other driver ',\n",
       " 'or D Terminus? There’s confusion here ',\n",
       " 'French Romantic’s treble casseroles with chorizo ',\n",
       " 'Needing to believe, see printed signs ',\n",
       " 'Resolve “Allardyce Sacked” headline? ',\n",
       " 'Warwick was keg man rolling in dry white wine and cassis ',\n",
       " 'Chants may be composed by sailor … ',\n",
       " 'Give new spirit to priest in sheer confusion ',\n",
       " 'Organise swimmer to reverse aquatic movement ',\n",
       " 'Worry a hit might spoil Dreamliner’s quality? ',\n",
       " 'Toast drunk once in judge’s garb ',\n",
       " 'Notes detached and cast out by censor ',\n",
       " 'scene suited for necromancy? ',\n",
       " 'Classic writing makes it personal ',\n",
       " 'Shame about oral outburst going to extremes ',\n",
       " 'Nerds arise! Break the monotony ',\n",
       " 'They make the grandee enraged or angered ',\n",
       " 'It could get Charon in a fix on the Styx ',\n",
       " 'Side playing away from home fails to survive ',\n",
       " 'Mature and moving programme ',\n",
       " 'Transport backed by heroes turning from much backed animal ',\n",
       " 'Fictional agent in sticky situation, no beds available ',\n",
       " 'Performed some of dance stoned, grabbing debauched man ',\n",
       " 'Greek excitedly reads about percussion instrument ',\n",
       " 'Canines still in periphery to explore the ground ',\n",
       " 'Boxes frantically, vest in coating of sweat when it’s over ',\n",
       " 'Food freak – term, I fancy, used around noon ',\n",
       " 'Name suprisingly moderate building by the Seine ',\n",
       " 'A huge development in the city ',\n",
       " 'Trust company wrongly fined ',\n",
       " 'Reckless person’s crazy road speed ',\n",
       " 'Concern of an eleven yet to be organised ',\n",
       " 'New Year, when there’s a situation of uncertainty ',\n",
       " 'Playing leapfrog, female ignored climbing frame in garden ',\n",
       " 'More attend new art gallery ',\n",
       " 'Wilde sees wild flower ',\n",
       " 'I’m in Maltese mess when I eat ',\n",
       " 'Admit no air that’s hazy — one may be lost in it! ',\n",
       " 'Urge to travel as a result of chilblains? ',\n",
       " 'Awfully isolated, having dismissed fifty yes-men ',\n",
       " 'Backer of the Big Issue is into wrestling after getting in uniform ',\n",
       " 'Transported round Chinese port through two channels ',\n",
       " 'One exposed truants, I fancy ',\n",
       " 'Dodgy claims re law-breaking events? ',\n",
       " 'Outline of a semicircle one’s represented ',\n",
       " 'Groups require actions or else ',\n",
       " 'Nun involved with chapel from Atlantic to North Sea ',\n",
       " 'Beaten at cards playing deuce over time ',\n",
       " 'Variety of rose with identifying 24, outstanding digital feature ',\n",
       " 'Native disrupted mass in country abroad ',\n",
       " 'One in Paris describing plain cakes not commented upon? ',\n",
       " 'Former student likes fancy pillar ',\n",
       " 'Realm most disturbed in disorder ',\n",
       " 'Envies me at translation of Asian language ',\n",
       " 'Not connected with religious matters, clause upset reverend at first ',\n",
       " 'Mexican dish, notice, eaten by the odd Chilean ',\n",
       " 'Very vulgar, this silly game ',\n",
       " 'Splendour of Greek article under bust ',\n",
       " 'Dreadful score opener in test bagged – a duck ',\n",
       " 'Cycling in a seaport the next phase after 9 + 26 down, 8 and 2-15? ',\n",
       " 'Law-abiding bores vexed former secretary of state ',\n",
       " 'Oboe’s entrance in Enigma Variations — one’s feeling one’s all that matters ',\n",
       " 'Start to rise and flit, crossword setter style ',\n",
       " 'Clue ending with “shift”, a luxury one’s allowed ',\n",
       " 'Benign tumour has you rising in a mad frenzy ',\n",
       " 'Fields of influence in Bristol: not large but diverse ',\n",
       " 'Caught out, inspect dodgy part of loot ',\n",
       " 'Yale exposed active frat process ',\n",
       " 'Week passes without base smear freaking out unknown ',\n",
       " 'Lunatic pipes up ',\n",
       " 'Begin to ignore princess coy about weakness of mine ',\n",
       " 'Further education dispelled thesis fixations ',\n",
       " 'School has damaged ancient legwear ',\n",
       " 'Sex up rare bats ',\n",
       " 'Desperate airlines name missing Jew, perhaps ',\n",
       " 'Special ride crashed… ',\n",
       " 'Singular lady drunk ales ',\n",
       " '25Wipe up around middle of mask — it makes one look slimier! ',\n",
       " 'Skin of massive yams rotted fruit ',\n",
       " 'Outside court, lady injured foot ',\n",
       " 'Officer farmed out nursery item ',\n",
       " 'Pause as a cure for breakdown ',\n",
       " 'It’s natural — alter this and you get something else ',\n",
       " 'In cramped condition heartless Henry is an insensitive type ',\n",
       " 'Drains are directed to the lowest points ',\n",
       " 'Someone once contrived to emulate ',\n",
       " 'Repulsive scheme to turn to dust ',\n",
       " 'Not now as formerly mad one decorates pine, right? ',\n",
       " 'Pa argues for a change of veggie ',\n",
       " 'Surprisingly your bit boxed a newspaper’s stiff notice? ',\n",
       " 'A crawler somehow spirited it away ',\n",
       " ' Actor Antonio’s cast as Leo mercurial in Renaissance feature ',\n",
       " ' Ear takes bashing with Audible Poet ',\n",
       " ' Dishevelled I’m sat with bin consuming 5 nutritional items ',\n",
       " '1AOld computers malfunctioning in case ',\n",
       " '37AStockings worn only in new style ',\n",
       " '1DPays for drug costs out of joint ',\n",
       " '8DEnglish bananas taste rank ',\n",
       " 'Possibly hammered loose cable with a pin ',\n",
       " 'Manage to interrupt appeal ',\n",
       " 'Muses, in the end, about missing daughter ',\n",
       " '13A Scapa were the last answered Defiance that’s intolerable after volunteers leave unexpectedly ',\n",
       " 'You snivel unpleasantly, wishing you were me? ',\n",
       " 'Put in letters for ice-breaker keeping weapon ',\n",
       " 'Do this to cite this for ',\n",
       " 'See 20 See 20 Supply lamps the ginnel needed … ',\n",
       " '… needed again with heater fitted in Soviet city ',\n",
       " '  See you shortly at Cannes? No, beat it, punk! ',\n",
       " ' Box contains one b—– big key ',\n",
       " ' Seeing dictator on the warpath, make exit as one ',\n",
       " ' Spirit guide, if seen, is way in ',\n",
       " 'Thief pilfers hot stew ',\n",
       " 'Abstainer in Cairo cooked cheese ',\n",
       " 'Men let oil reform as a cream ',\n",
       " 'One crèche managed consistency ',\n",
       " 'After tea, engineer got on at a station in Tennessee ',\n",
       " 'Run into it in need of refreshing food ',\n",
       " 'Least reliable butcher likes wrapping article in paper ',\n",
       " 'One’s bent perhaps, not broken, kept in safe ',\n",
       " 'Drastic changes suppress mother’s tantrums ',\n",
       " 'They perform simulated outré sex without clothes at first ',\n",
       " 'Unusual orange coloured fern? ',\n",
       " 'Idea Clint formulated is not different ',\n",
       " 'Reason for fall in grain silo when working ',\n",
       " 'Architectural feature home had in Barking ',\n",
       " 'Not using present to mark courtship by mail? ',\n",
       " 'Uncertain if fluids be suitable for pouring ',\n",
       " 'Upset ace fined for open disobedience ',\n",
       " 'Grace, opening batsman, gets unusual singles ',\n",
       " 'Induct into office when I answer correctly ',\n",
       " 'He swore it might be different ',\n",
       " 'Peg possibly owed a pound ',\n",
       " 'Create a stir, try some skill ',\n",
       " 'Held with an awkward grip ',\n",
       " 'No, I am wrong, she was Ruth’s mother-in-law ',\n",
       " 'Location for Hamlet relies on redevelopment ',\n",
       " 'Depicting characters performing in play or art ',\n",
       " 'Cause amazement to a holy man on his involvement ',\n",
       " 'A smuttier rag may upset JPs ',\n",
       " 'Ability to understand, perhaps too late, things hid obscurely ',\n",
       " 'Old stone fouled up by the oil ',\n",
       " 'Bishop with inner conceit upset man, I understand ',\n",
       " 'Negotiate for a shire here? ',\n",
       " 'Poshstrains awkwardly to convey fairness and good humour ',\n",
       " 'Madcap rowing wife goes for genital area ',\n",
       " 'Where Walesa was active, being originally gay and “queer”, singular and constant ',\n",
       " 'Insult Balls, ultimately dismissed as “easy to pick up” ',\n",
       " 'MPs talk of Mates condom distribution to include, initially, errant bishop ',\n",
       " 'Brief tingle he produced, core of penis ',\n",
       " 'Mad Paxman booting bloke in rear: “Tell me more than that!” ',\n",
       " 'Somehow a loser with nothing can, probably ',\n",
       " 'Nasty parent runs wild brandishing fancy gun ',\n",
       " 'No city dust here; it disperses ',\n",
       " 'Reform goes wrong for these intimate friends ',\n",
       " 'Top royal in total disorder gets reprimand ',\n",
       " 'Identified disease daughter agonised about ',\n",
       " 'Bill enters rambling races and walks ',\n",
       " 'Romney’s upset to squander Republican capital ',\n",
       " 'Birds, we sense, get excited about love and little weight ',\n",
       " 'Make a noise with this awfully long note ',\n",
       " 'Smell of deer and cologne? Go away to freshen up! ',\n",
       " 'screens “1Turning Twisting Messi Tricks” ',\n",
       " 'Armstrong’s conclusion after cyclist loses halo: “I cycle nice and clean” ',\n",
       " 'Clear foul: Luxembourg tripped Bale! That one could remember ',\n",
       " 'Maybe Boycott is in, so can’t bowl over ',\n",
       " 'Soldiers must seek order without hesitation ',\n",
       " 'Early birds found here at Cheshire mill ',\n",
       " ' Clue I botched with no hint of science that is about amino acid ',\n",
       " ' Gulf shimmering with gold magnificence ',\n",
       " ' Ridges in runny cheeses he cut, cut in slices ',\n",
       " 'trat staple? let art run free with this! ',\n",
       " ' You may find such rumbling ain’t silent! ',\n",
       " ' Ape grabbing it’s punished, hit wrongly ',\n",
       " ' You may find it rash going wild with one in Cornish teas! ',\n",
       " 'Heated, dry out? ',\n",
       " 'Artisan concocting kitsch balm ',\n",
       " 'Journalist in news broadcast in European country ',\n",
       " 'Gripped, bit and chewed bananas ',\n",
       " 'Ethnic origin of Tony Blair disputed ',\n",
       " 'Vase containing ornate icon showing fabulous creature ',\n",
       " 'Show clan misinterpreted a form of Langue d’oc ',\n",
       " 'Star in East, twinkling, seen by chance ',\n",
       " 'It has a laxative effect in repeat runs ',\n",
       " 'Like a joiner‘s debut in carpentry work — value it poorly ',\n",
       " 'Reformed human sin with Pope Victor’s tactics ',\n",
       " 'character made guard fret ',\n",
       " 'Has changed number held by fictional agent almost beyond the pale ',\n",
       " 'Sing or dance with seals ',\n",
       " 'Bird removed top of rue ',\n",
       " 'sprayed Dettol over part of fower ',\n",
       " 'Flower water put in sticky paste ',\n",
       " 'King George is back in Aberdeen perhaps, finding somewhere to drink ',\n",
       " 'Bravery shown when drunken plastic surgeon removes splints ',\n",
       " 'More crazy about the Opel Rio! ',\n",
       " 'Precedent established overstats ',\n",
       " 'Modest girl’s rest I’ve disturbed ',\n",
       " 'Environmentalist fight for 201Olympics run by Coe – not well – initially ',\n",
       " 'Dog-tired, Anna, having lost Pole, suffered humiliation ',\n",
       " 'Tricksunder pressure to hold old lecturer ',\n",
       " 'Everything we hear is ideal, but endlessly complicated ',\n",
       " 'Group of similar creatures silly boy and I pet ',\n",
       " 'Snares fish in cod nets ',\n",
       " 'Forging equipment villain dismantled after disposing of duplicates ',\n",
       " 'Deal with secret dicky bird ',\n",
       " 'Trojan wife for whom Charon made trip ',\n",
       " 'More and more grain’s nicely ground ',\n",
       " 'Drink from Lombardy you almost ordered ',\n",
       " 'Ealing production that’s good-humoured ',\n",
       " 'Dances in show done up the pole ',\n",
       " 'Yuan finally extracted from curious Cantonese wallet ',\n",
       " 'Thrown cigarette end missing forest resident ',\n",
       " 'Poems representing 21’s clue ',\n",
       " 'Animal in area – tent abandoned ',\n",
       " 'Practical person‘s grim past at camp ',\n",
       " 'Desert deal possibly in the frame ',\n",
       " 'Stephano crashed carriage ',\n",
       " 'Family magazine disagreed, strangely, with others around ',\n",
       " 'Mother runs with ghastly hat on in race ',\n",
       " 'Who might supply our best stamps? ',\n",
       " 'Box of valuables found in wreckage of usherette’s car ',\n",
       " 'Avengers manufactured chemical weapon ',\n",
       " 'Question we try to compose on keyboard ',\n",
       " 'Tories, taking north not south, are obliterated by old labour ',\n",
       " 'Lift wreckage from nearest port ',\n",
       " 'Carelessly, I bang rock into snake ',\n",
       " 'Knotted yarn left frayed by violin string ',\n",
       " 'Denial set in code ',\n",
       " 'Eats cooked meal with man contracted to help in moving home? ',\n",
       " 'set core cryptic! ',\n",
       " 'Is around, evolved, or is gone ',\n",
       " 'React badly about kiss for Cornish Tom ',\n",
       " 'How to supply team with fruity mix of tarts for winter season? ',\n",
       " 'No stamp duty to pay after exchanging? ',\n",
       " 'Police coming around to arrest model after some bust up with a servant ',\n",
       " 'Abandoned when leased to doctor ',\n",
       " 'Roamed freely near the edges but kept within bounds ',\n",
       " 'A souvenir not put out after I object repeatedly ',\n",
       " ' Mother uses broken toy shark to make dolls ',\n",
       " ' Doctor nearly materialised, leaving the Master in multiple universes ',\n",
       " ' Fossil title title written untidily with biro ',\n",
       " 'Wrongly diagnosed Pinterish condition? ',\n",
       " 'With odd shape worker becomes fair game ',\n",
       " 'Workers hold wayward lad for local officials ',\n",
       " 'Possibly a looser of particles endangering the ozone? ',\n",
       " 'Ink-pad designed for press ',\n",
       " 'Refer everyone to due amendment ',\n",
       " 'Drivers tucked into fresh motel porridge ',\n",
       " 'Decided to change depot ',\n",
       " 'One has to retain extraordinary stillness ',\n",
       " 'Spontaneously smile upon stumbling ',\n",
       " 'Style shown by some private landlords ',\n",
       " 'Foul vapours over Chad hiding a massively uneven contest ',\n",
       " 'Maybe cat’s milk could make us careful ',\n",
       " ' Ouris set to get Love Master sketch ',\n",
       " 'repaired with deeper piece of cotton wool? ',\n",
       " ' Sunday best for recycling good belt attachment? ',\n",
       " 'Rams, angry looking with level temperature ',\n",
       " 'Assessment of the result of coming to have new input in organic computers ',\n",
       " 'They’re sickening for Cameron at present? A strong pill prepared ',\n",
       " 'And the consequences when that’s ballsed up? ',\n",
       " 'I censor a badly written summary of play’s plot ',\n",
       " 'Drink in Soho, having time to get wasted ',\n",
       " 'Tea ordered in attempt to reach agreement between states ',\n",
       " 'State adopting dancing bear is not far away ',\n",
       " 'Surrealist painter claiming right to meet central character in Carroll’s Looking Glass ',\n",
       " 'Managed to get rid of plunder ',\n",
       " 'Worried aunt got me a vegetable ',\n",
       " 'Girl out, so arranged for a physician ',\n",
       " 'Must opera turn into long-running play? ',\n",
       " 'Refused to have anything to with editor after groin trouble ',\n",
       " '9ALaudatory address for which grey snakes in the grass? ',\n",
       " '13AMotors around with John Paul I, snapping at the heels of the rich and famous? ',\n",
       " '21AHaving run into broken-down minibus, German settling ',\n",
       " '23Atenner buys novelty egg-carrier ',\n",
       " '2DOne going in dodgy harbour inns with Iris? It’s really not a good time ',\n",
       " '4DBox-occupier who talked up training got physical work on hands and feet ',\n",
       " '5DThe horrendous early botching up of work that can’t be made secure ',\n",
       " '7Dbreakdown of communication, basically? Not if I can fix it! ',\n",
       " 'One has letters missing in returned post, only half of programs distributed ',\n",
       " 'Most of gross income shaped bioengineering ',\n",
       " 'State’s no-go area essentially rebuilt ',\n",
       " 'Left following depression, having worked notice to get whip-round ',\n",
       " 'An iris starts to seed cultivated hybrid fowers ',\n",
       " 'Called for medical to be reviewed ',\n",
       " 'These are green lemons, having gone off ',\n",
       " ' Copper falls out with copper ',\n",
       " ' One more broadcast on the air ',\n",
       " ' That’s a surprise! I manage to lose in broken resistance ',\n",
       " ' Buddhist states toss Ravi out ',\n",
       " 'One who angles for compliments? ',\n",
       " 'Louis, for example, isn’t a problem ',\n",
       " 'Won’t play Rugby, possibly ',\n",
       " 'Beau to Marion, a rogue ',\n",
       " 'Paul, confused about identity, retired ',\n",
       " 'Task I prepared for Hindu goddess ',\n",
       " 'Collectible Mountain of Mourne, endlessly mysterious ',\n",
       " 'Energy shown by ever-rising officer ',\n",
       " 'Two beasts that may get hot in the light ',\n",
       " 'This ginger ale he brewed for a national organisation ',\n",
       " 'Clothes items? Girls wear ’em possibly, but not I! ',\n",
       " 'The broken-down train isn’t moving ',\n",
       " 'Tory boss may make an attempt to elicit sympathy ',\n",
       " 'A crying need for free trade cut ',\n",
       " 'Incorporate dome by reconstruction ',\n",
       " 'Creature ailing badly ',\n",
       " 'Pulls out Greene’s novel ',\n",
       " 'Rigidity of stone in building ',\n",
       " 'Revolutionary socialist’s not the first to sign a petition ',\n",
       " 'Wren perhaps could migrate to the Arctic ',\n",
       " 'Urinal apt to splash? you need something waterproof ',\n",
       " 'Volume is in unacceptably poor condition ',\n",
       " 'Stress A&E should be involved? You may after whack on the head ',\n",
       " 'Old mate shelters in stunted and gnarled lime tree ',\n",
       " 'See 16 Criminal prevailed before ending in slammer, one going down for a long time ',\n",
       " 'Bit of fun with possible role to impress partner, initially — later a 26? ',\n",
       " 'Sax was being almost all jazzy? ',\n",
       " 'Upset tabloid concealing dread, rubbished paper as aggressive performer ',\n",
       " 'Incoherent speech, so a drawl collapsed and died ',\n",
       " 'Attempt an overdue repair ',\n",
       " 'Strep is running wild in elves ',\n",
       " 'What a student seeks from investigation initially into reproduction of old map ',\n",
       " 'Not nice to play a trick in front of Bond ',\n",
       " 'Fail to avoid young lady ',\n",
       " 'Name one volatile gas ',\n",
       " 'lawyer, character defending army suspect ',\n",
       " 'Drudge recalled being beaten about at home ',\n",
       " 'Leader of military junta shot head of charging animal ',\n",
       " 'They provide traction, as shown in broadcast about foremost of cars ',\n",
       " 'Accepted the law needs changing in a protectorate ',\n",
       " 'Mistakenly, hero to cause alarm ',\n",
       " 'Farmer’s ploy: first time, show hesitation ',\n",
       " 'At home, Electra was weaving twine ',\n",
       " 'Unhappily, ten pester my parent, whose now childless ',\n",
       " 'Inaction caused by wayward English dude eating fat ',\n",
       " 'Get garage to reassemble the combination ',\n",
       " 'Not much of a press, perhaps ',\n",
       " 'Water-lily collection going to America ',\n",
       " 'Slovenly in duty, has to be removed ',\n",
       " 'Naive politician caught in a web of lies ',\n",
       " 'Thought broadcast item dated ',\n",
       " 'Body-builders stride so energetically ',\n",
       " 'Shun ale that distributed free ',\n",
       " 'Like an egg – so veto a pie ',\n",
       " 'Fool introduces square dance ',\n",
       " 'Flower having faded petal ',\n",
       " 'Drunken leader embracing lady around village in Derbyshire ',\n",
       " 'Unstable wet mass at Cornish resort ',\n",
       " 'City in France – one in Nepal, maybe ',\n",
       " 'Giant turning up gold onisland ',\n",
       " 'Penalties converted in the eastern Mediterranean ',\n",
       " 'Master of Thornfield Hall disturbs the scorer in Medway town ',\n",
       " 'Sexton’s dilapidated car is restored outside ',\n",
       " 'Starts to observe some flowing and ebbing — no longer like a river mouth ',\n",
       " 'Tree’s unknown in wild US, alas ',\n",
       " 'I incorrectly told false notion ',\n",
       " 'Reparations fix new home in Australian camp ',\n",
       " 'Interpreter of scriptures and curious men sit here at university ',\n",
       " 'Sweaty American returned smelling badly ',\n",
       " 'Stop leaving African pigs standing up in bedding material ',\n",
       " 'Teaser: eg “oddities and whatnots” ',\n",
       " 'Police duo outlook? ',\n",
       " 'Barge recklessly overloaded with pudding ingredient, a root ',\n",
       " 'Clue to tone of pudding ',\n",
       " 'To make pudding, boil diced ingredients in empty tank ',\n",
       " 'Strange custom, to live in Devon ',\n",
       " 'Entice with an apple crumble ',\n",
       " 'One doing another in,sore, beaten with a rock ',\n",
       " 'Faint mention about a show of facts ',\n",
       " 'Naughty download showing scene in nature ',\n",
       " 'Drop something at the bottom of the garden? ',\n",
       " 'A bomb exploding round sticky stuff ',\n",
       " 'Helium or argon, which could be angriest? ',\n",
       " 'Slippery creature gives manager',\n",
       " 'Kept your feet out of water? Your dinner starts with hors d’oeuvre ',\n",
       " 'Take top job away from idle fellow in whom is the problem? ',\n",
       " 'Bird that can’t fly — hence fly is to make milk? ',\n",
       " 'Tube to opening of Camden theatre, perhaps ',\n",
       " 'Hospital patient given wrong test recordings ',\n",
       " 'He makes entries with one in the amazing Tardis ',\n",
       " 'Alcoholics Anonymous propose changing addictive programme? ',\n",
       " 'Tired out after recording “Shame” ',\n",
       " 'Lose water vapour like terrapins at sea ',\n",
       " 'A person came largely in order to get cheese ',\n",
       " 'Reproduction in main salon obscuring one new painting ',\n",
       " 'Sale a doc organised – medico’s responsibility? ',\n",
       " 'Spade, say, endlessly varied type for moving earth ',\n",
       " 'Cruise, perhaps, miles off circling island ',\n",
       " 'Roman is misbehaving in confines of party avoiding excess ',\n",
       " 'Boat lately at sea carrying Republican in fierce fight ',\n",
       " 'Momentum and energy introduced by politician in woven suit ',\n",
       " ' Isotope, abnormally hot and not regressive ',\n",
       " ' Senior corgi may be trained as this, ergo it bites ',\n",
       " ' Yuletide symbol for kids, tin sleigh entangled with bits of coloured ribbon ',\n",
       " 'Crow put him off? That’s about right ',\n",
       " 'Workmen’s tools left in crooked spire ',\n",
       " 'Inspect burst main feedingriver ',\n",
       " 'Quietly he interrupts young relative ',\n",
       " 'First home, one with tail wagging ',\n",
       " 'Powder copper put in malt extract ',\n",
       " 'See 8 15 Taurus conflicted with Libra, so involved in stitch-up? ',\n",
       " 'Very good cleaning fluid removing stain in the end ',\n",
       " 'Sunlit cheek? ',\n",
       " 'Like coming to break a/c limit in cricket club ',\n",
       " 'Principle right for small boy and father to hold ',\n",
       " 'In big town there’s a very small space ',\n",
       " 'Groups with members one over the eight — and seen to be drunk ',\n",
       " 'An idea if seal be broken ',\n",
       " 'Roach cooked by new magistrate in Athens ',\n",
       " 'Club bouncer is important in organisation that engages 50 ',\n",
       " 'Pigs at the dance seeking meal ',\n",
       " 'Sketch has detainee in row over Pound ',\n",
       " 'Terrible rip in chair? I see what you’re saying! ',\n",
       " 'Given after breakdown, important point’s made ',\n",
       " 'Muslim claim is falsely made ',\n",
       " 'Muddles ahead in Mshambles ',\n",
       " 'Steers by intercepting one mobile ',\n",
       " 'Old shabby togs the best clothes for bouncer ',\n",
       " 'Runs I’d built up in scramble ',\n",
       " 'Uneasy with this hormone, rep produces progesterone ',\n",
       " 'Raja‘s partner acting about ran him out ',\n",
       " 'Stars only when topless upset old-fashioned wife ',\n",
       " 'Argyll’s own heathen abandoning the northern bogus ',\n",
       " 'Student sweetheart from St Andrew’s? Scotsman’s daughter in hand ',\n",
       " 'Spots cloister, soaks up forbidden reset ',\n",
       " 'Victor runs away from unusually revolting freckles ',\n",
       " 'Letters missing in this post offce mail delivered around Greece ',\n",
       " 'One’s taken in by the modulated pitch of speech ',\n",
       " 'Researcher is a rogue to experimental mice ',\n",
       " 'Ill-disposed ladies to be separated ',\n",
       " 'Disturbance in court, perhaps ',\n",
       " 'Propose a broadcast on a serialdrama ',\n",
       " 'Elisha ordered to take in male Biblical outcast ',\n",
       " 'Years possibly follow as a metal tester ',\n",
       " 'Joyous beaux rent asunder ',\n",
       " 'Over-large herb is malformed? Nonsense! ',\n",
       " 'Play with cutie cultivating trees ',\n",
       " 'Pedal let out outside study ',\n",
       " 'Land to which Nahuatl moved ',\n",
       " 'Flower found in garden, haymaking? ',\n",
       " 'Armoured horse receiving garbled call ',\n",
       " ' Commercialand radio essentially are due for shake-up ',\n",
       " 'help back film – not half obscene language, crude anyhow ',\n",
       " 'Toss Sappho the salt ',\n",
       " 'A sad, panting tussle for unenthusiastic mates ',\n",
       " 'Art deco building, one of Butlin’s finest! ',\n",
       " 'Enrage ref, misbehaving and running around ',\n",
       " 'Damage to feral vagrant ',\n",
       " 'Manage to find lines in Old English ',\n",
       " 'Wacky road race with rum bulletproof vehicle ',\n",
       " 'English resort’s pebbly beach ',\n",
       " 'Expand range, line less fashionable, out ',\n",
       " 'Doctor being fired for asking questions in the military ',\n",
       " 'The Oldie circulated by University Hospital ',\n",
       " 'Pools win ultimately leads to a tiara being ordered ',\n",
       " 'Representative reset the password ',\n",
       " 'Dogged by extremely unspeakable actions following representation ',\n",
       " 'Cast kept entertaining sudden great demand before a popular ballet ',\n",
       " 'Irregular code is broken with constant input ',\n",
       " 'Final eliminator involved being knocked out ',\n",
       " 'The last of many put the men in a spin ',\n",
       " 'Threatens to throw grenades around noon ',\n",
       " 'rich man’s destroyed by insurgency ',\n",
       " 'Place in which Callas represented Norma, ultimately ',\n",
       " 'Canoe wrecked in water ',\n",
       " 'Siren in car sent hens crazy ',\n",
       " 'They make cuts in the plot and Sue reacts badly ',\n",
       " 'Stir green tea without hesitation to promote new growth ',\n",
       " 'Being logical, I call at any trouble ',\n",
       " 'Surprising her with gift that’s carried by rail and road ',\n",
       " 'Insignificant student, weed, possibly British ',\n",
       " 'Queen, new to palace across river ',\n",
       " 'Republic created by Romanians after revolution ',\n",
       " 'Drunkard spilt a beer in it ',\n",
       " 'Poor lad crossing slack tourist centre near Pikes Peak ',\n",
       " 'Raging bull with ear infection ',\n",
       " 'Gull in pool, audibly weak, in distress ',\n",
       " 'Wrought iron panel, beyond compare ',\n",
       " 'This antelope band, wild? Indians’ bag possibly ',\n",
       " 'Alone, penning bit of rag in style displaying difficulty with words ',\n",
       " 'Poisonous gas is best dispersed round battalion’s rear ',\n",
       " 'My lord appears thus when receiving one ',\n",
       " 'Scruffy titches sit uneasily after audience disapproval returns ',\n",
       " 'Slow shifting of crust scattered by a messy bird ',\n",
       " 'King on phone abandoned former charm, showing aversion to empty space ',\n",
       " 'Threat to croc’s young – munching on Munchie! ',\n",
       " 'Glandular infection: it’s found among some Yemenis ',\n",
       " 'Feasts abroad, most free from risk ',\n",
       " 'One avoiding work, badly riled ',\n",
       " 'Clear river blocked by unrulyclan ',\n",
       " 'Opera singer, Lanza, cut short La Scala broadcast ',\n",
       " 'Having energy and space to develop, find way out ',\n",
       " 'Period when entire term is recollected? ',\n",
       " 'I relaxed with some hot drink ',\n",
       " 'Power associated with new regalia is appropriate ',\n",
       " 'Treaty has potential to enrage me over time ',\n",
       " 'Ad reads “Gold Blend — a very large one?” ',\n",
       " 'Give way to die — lung collapses ',\n",
       " 'Engineer nominates state ',\n",
       " 'In foyer, a chair — American diva’s reclining, is she? ',\n",
       " 'Order daily entries — vet’s record of weight against a standard ',\n",
       " 'Pact I arranged for everyone behind surrender ',\n",
       " 'Brief appearance is shut out from what follows, oddly ',\n",
       " 'Fresh changes embracing condition of law officer ',\n",
       " 'Maybe cheers up around the third part of pole vault ',\n",
       " 'Dramatist‘s predicament involving awkward way to finish off actor ',\n",
       " 'Roughly pin elm around each flower ',\n",
       " 'Annoyed by coffees he’d ruined ',\n",
       " 'Thoroughly cleaned tile dries out after a bit of soaking ',\n",
       " 'Historic old chapel destroyed ',\n",
       " 'For example, flat screen’s manufactured badly – first four components missing ',\n",
       " 'Drinker‘s drunk 3 ',\n",
       " 'Bird hosting party let off, as sweet ',\n",
       " 'See 25 See 25 25,Carrying drugs primarily, a suspect not to be trusted popping sweet in mouth ',\n",
       " 'dishonest organisation leaves one dumbfounded ',\n",
       " 'Opt for oil production as responsibility of minister ',\n",
       " 'Value mid-afternoon tea-break ',\n",
       " 'They act unthinkingly, placing plant needing warmth in a sickly sun ',\n",
       " 'New rise to be paid now? Remains to be seen ',\n",
       " 'The sound of free speech ',\n",
       " ' Breaking the speed limits in Cardiff and Crewe causes vocal complaint ',\n",
       " 'Changing a belief’s not impossible ',\n",
       " 'horse being exercised on the beach ',\n",
       " 'Bail due for release, it’s heard ',\n",
       " 'He accepts Kate is upset, right? ',\n",
       " 'Go really wild with Pilgrim’s Progress for example ',\n",
       " 'Veto using proportional representation? ',\n",
       " 'Guard ordered to breached line ',\n",
       " 'The last sort of quality needed by cat burglars ',\n",
       " 'Measure introduced in Burma somehow gives protection ',\n",
       " 'Funny bones with bit of bridle ',\n",
       " 'My groundhogs! ',\n",
       " 'Foot rot for a peasant? ',\n",
       " 'Producer of pictures getting actors into cast ',\n",
       " 'Human error in pact with rhino ',\n",
       " 'Awfully hot in cold place causing problem, in a way ',\n",
       " 'State aid, so majority in parliament speculate about fine mess ',\n",
       " 'No breach? Not quite, with half 7s in bother ',\n",
       " 'A log trail that’s mistaken for reptile ',\n",
       " 'Fellow in gaol possibly prison camp ',\n",
       " 'Queen with family left out forced to divide into branches ',\n",
       " 'No hat-peg’s made into geometric shape ',\n",
       " 'Lacking oxygen a pilot’s in trouble — this might result in a crash ',\n",
       " 'Bulging of fat bun? Could be ',\n",
       " 'Following from events on record laic scribbled ',\n",
       " 'For wicked liar in old play that’s a small share for the Bard ',\n",
       " 'Asia trip arranged for 5 down in retirement ',\n",
       " 'Tries scheme that goes awry, resulting in lists of offences ',\n",
       " 'Prejudice wrongly treated as crime, mostly ',\n",
       " 'Oddly deficient clue thus confused investigator ',\n",
       " 'Kind of criminal, awfully bad, disrupted court ',\n",
       " 'Notorious professor misrepresented Tory aim about part of basic education ',\n",
       " 'Wrongfully take them in as killers ',\n",
       " 'Austria, say, turned right out of churchyard ',\n",
       " 'Wine helps to blur the effect of skidding ',\n",
       " 'Muslim leader, no leader for Jihad possibly ',\n",
       " 'Aspirations about half the games not playing in Ramadan ',\n",
       " 'Give a preliminary payment for real wood',\n",
       " '21.Domain of Polish nobleman, corrupt Tsar’s toy ',\n",
       " '31.Noun in this may be rendered Anglice? ',\n",
       " '1.Jokily woman soprano follows choir copies ',\n",
       " '7.Don sari that’s creased? It might have benefited from this ',\n",
       " '12.Rough motoring with ice concerning direction-finders? ',\n",
       " '12A[II] Thematic treatment ',\n",
       " '13A[I] turned plunderer showing form again ',\n",
       " '1D[I] old relative said – range active getting recipe for one ',\n",
       " '1D[II] Gas highly excited, like a weird ',\n",
       " '5D[II] Describing hearing German car, the French ',\n",
       " '8D[I] Thematic deduction ',\n",
       " '14D[I] Small group struggling there ',\n",
       " 'Exposer of vagrant in love with tart ',\n",
       " 'Having no choice? Send if worried to cattle farm on other side ',\n",
       " 'Hurts that may get us down? ',\n",
       " 'Moral degeneration in the mouth ',\n",
       " 'The in thing is outrageous size — get it? ',\n",
       " 'Arthur feels Lancelot initially refined oil cleaner ',\n",
       " 'It is clear and could be true to life ',\n",
       " 'Church ladies’ outfit to wear off duty ',\n",
       " 'Term sees alternative terminology across the pond … ',\n",
       " 'In muddled head reminder turns up to get Mother’s Pride? ',\n",
       " 'English student managed somehow to get to college ',\n",
       " 'Gran sits knitting for Leo, say ',\n",
       " 'Desktop tool which could be dear, eg ',\n",
       " 'Dance bar’s bustling, getting in is a buzz ',\n",
       " 'Give a clue in that anagram ',\n",
       " 'Stick in plug and reuse mobile ',\n",
       " 'Parking in Allegro’s chaotic – it’s a quick animal! ',\n",
       " 'Snack item ape chewed ',\n",
       " 'Single figure picks up crate to distribute fruit ',\n",
       " 'Antipodeans around here heard parrot flapping in sea ',\n",
       " 'Mother, prepared when travelling, cut out page for navigator ',\n",
       " 'Fixed work, in building line, means capital no longer used ',\n",
       " 'Bottom drain repaired ',\n",
       " 'Irish tart formulated complaint ',\n",
       " 'Was cautious after speedy Alfa crashed ',\n",
       " 'Delicious food makes Maria sob uncontrollably ',\n",
       " 'Dicky tramples on old British leader ',\n",
       " 'Somehow put Britain above the EU, for example ',\n",
       " 'Could be bad sign for the corporation ',\n",
       " 'Scripts one translates for the examiners ',\n",
       " 'Dogs let loose in the gallery ',\n",
       " 'Exotic wine number six comes top ',\n",
       " 'Luther’s Reformation exposed fraud ',\n",
       " 'Non-physical position, mostly – no, it involved being hugged',\n",
       " 'Diss second character in True Romance‘s sad moves — they might need hankies?',\n",
       " 'One investigating hit left to regret coming back',\n",
       " 'Final bit of Quentin Tarantino lie damages Universal',\n",
       " 'Informalvariation in kinky erotic show',\n",
       " 'Gent led criminal having joined Reservoir Dogs',\n",
       " 'Woman with degree from commercial university’s got into great career ',\n",
       " 'Show off horse in Arab style with even trot ',\n",
       " 'Fox comes to grief at last in tortuous fable ',\n",
       " 'Nick subtly hit on lady taking away her heart by cunning ',\n",
       " 'Cock up with business trip ',\n",
       " 'Very happy to mention review about Wicked cast ',\n",
       " 'Northern side of church’s poorly lit by candles, primarily ',\n",
       " 'Sorry about constant time taken off with awful flu ',\n",
       " 'False god to love, love therefore not true? ',\n",
       " 'Obsolete institution: Act I — the goalpost must be moved ',\n",
       " 'Kipling’s pony, a cross beast, playing and 22 down ',\n",
       " 'Long wait on the cards for sleeper over sleepers ',\n",
       " 'Encouragement to beat about the bush, almost wildly ',\n",
       " 'Fibbed half-heartedly, with lies perhaps generating this response ',\n",
       " 'Religious official trying to convert Iraq, so intruding ',\n",
       " 'After Metamorphoses, Ovid was to issue a denial ',\n",
       " 'Elite nags, whipped into shape, run this ',\n",
       " 'Member of oppressive regime thrashed a servant ',\n",
       " 'Thrower thrown into former heaven ',\n",
       " 'Sadly I with 35 Sicilian raised as 27 ',\n",
       " 'Greek play, sly one, exposed layers of feminism ',\n",
       " 'Colossi left floundering manage with electronic test instrument ',\n",
       " 'Very little space for food — I thrash wildly about ',\n",
       " 'Pitiful elastic – no good as a Wonderbra ',\n",
       " 'Rocks ache on receiving Fergie’s ‘premier’ rub ',\n",
       " 'Nuts central on getting screwed, that’s clear ',\n",
       " 'do fantastically, wearing Goldsmith junior’s heavenly belt ',\n",
       " 'Recession: PM bins Helen’s interpretation as gobbledegook ',\n",
       " 'Smart arse scruffy teens, taking Cyclops in ',\n",
       " 'Andy right pissed – adding water! ',\n",
       " 'Positive types‘ yen: easy arse movement ',\n",
       " 'Hot dating collapsed without nitrogen – pissed off ',\n",
       " 'Speculative, in no way a lion, ballsed up ',\n",
       " '“Unremoveable MP” is turned with a tenner ',\n",
       " 'New Tory constitution embracing ‘two ways’, hardly a way to get in ',\n",
       " 'Pop star Jack: “No hotel to be trashed before noon” ',\n",
       " 'Stokes is cross struggling in hold ',\n",
       " 'Central Americans omit ski at sea ',\n",
       " 'Packs of eight alter our cost ',\n",
       " 'Room with central Heating spoilt print ',\n",
       " 'For short life-stories put nothing in twice ',\n",
       " 'Say two GIs with Ninth tussling over female? ',\n",
       " 'Sat in posh car, an American lawyer waves to expose foe ',\n",
       " ' Led me up, staggering, to strip ',\n",
       " ' Condemned a grim, worn-out plant ',\n",
       " 'Risky system revealed to a frisky A-lister ',\n",
       " 'Lutz performer performing trick with ease ',\n",
       " 'Completes the hole – gods went wild ',\n",
       " 'A fire left raging following death',\n",
       " 'Group out late in old capital ',\n",
       " ' It is apparent during a piano duet, possibly ',\n",
       " 'Dunks beer mugs washed up with last of slops ',\n",
       " 'Pairs a pal’s circulated for valuations ',\n",
       " 'What delay motorists? Stupid arrows do round centre of Tokyo ',\n",
       " 'Snapshot in public house got Harpo upset ',\n",
       " 'Wear still to be treated in part of building ',\n",
       " ' Line with crudity translated in disbelief ',\n",
       " ' Badly hurt ear or other part of the body ',\n",
       " 'Skin disease returned when brushing against coloured plant ',\n",
       " 'Former coppers in brief conversation wrongly interpret the Spanish Creed ',\n",
       " 'Gelatinous stuff put in a barrel before decorating cake—not good ',\n",
       " 'Promiscuous person, one beyond hope of recovery in all but name ',\n",
       " 'Living entity, soaring freely, marks/ internet prefix from Cyprus mountain forgetting last letter ',\n",
       " 'Environmentally adapted group run from tense battle site in pursuit of Italian author ',\n",
       " 'Subject to town hall causing milieu’s panic ',\n",
       " 'Overplay muddle over old Frenchman ',\n",
       " 'Grounds for a divorce? At first it’s a mix-up ',\n",
       " 'Artist turned and entered: “I can’t act romantically; the atmosphere’s frosty here” ',\n",
       " 'Actress Jessica sorts out Big Bird ',\n",
       " 'Coaches condemned divers after acting by Suarez, primarily ',\n",
       " 'Meltdown result for Sheen … ',\n",
       " '… wild man is paid and gets in round, which leads to alcoholism ',\n",
       " 'Lodgers get us rent on Sunday ',\n",
       " 'Unkempt Boris muffles answer — it shows constant pressure ',\n",
       " 'cry, all upset and emotional ',\n",
       " 'Fix note to end of Coleridge’s rime: “… then wander without horse” ',\n",
       " 'Old and new Conservative regularly likes wearing fake tan ',\n",
       " 'British concert artist covers sad rock songs ',\n",
       " 'Sailor’s rime — a Royal Navy jingle? ',\n",
       " 'Food sheikh’s dished out and child cut ',\n",
       " 'The French heroes are moved by a site of possible shipwreck ',\n",
       " 'I’ll leave Luigi stewing fruit ',\n",
       " 'Record in new demon cut ',\n",
       " 'I p-perked up, having been made dry and cured ',\n",
       " 'Acts of cleaning up the “sharp end” with unusual dilatoriness ',\n",
       " 'Searched for broken leg in use ',\n",
       " 'Big brains, say, Shed, Arachne and Gordius, each only beginning to appear addled ',\n",
       " 'Sport that’s practised by cheating footballers ',\n",
       " 'Demonstrated as cadet suggested? ',\n",
       " 'Kaleidoscopic expression coming up now certainly — ouch, that’s horrible! (12,4)',\n",
       " 'Old, doddering man? Protect the woman with child ',\n",
       " 'Monstrous party on the up through Gulf War not all bad ',\n",
       " 'Not obvious an ulcer burst ',\n",
       " 'Seems an alternative in a body ',\n",
       " 'In conflict we laid down guns, finally ousted by monarch, hurt? ',\n",
       " 'Wrapping not quite 8, also so long? ',\n",
       " 'I’ll get caught by rabid pet on tiptoe ',\n",
       " 'Relies on farcical setting for play ',\n",
       " 'Callas recollected a famous opera venue ',\n",
       " 'Helicopter carrying old-fashioned peasant ',\n",
       " 'Wrist mangler, rotten in a test of strength ',\n",
       " 'What’s left, for example, in moulded clay ',\n",
       " 'Seaman overhauled Polaris after power cut ',\n",
       " 'Heavenly food for Rambo is a stew ',\n",
       " 'Mopers hate fresh air ',\n",
       " 'Landscape artists in sunhats, wearing sort of ',\n",
       " 'It goes before time, unfortunately, for show-off ',\n",
       " 'They possibly burn with heat in seconds ',\n",
       " 'Convert in the glen is free from superstition ',\n",
       " 'Luxury accommodation seen in silhouette ',\n",
       " 'Crazy Iranian losing head in fantasy world ',\n",
       " 'Bruise becoming more active ',\n",
       " 'Armada let loose in artwork by 4 down 12 (10,6)',\n",
       " 'Invariably 4 down people‘s trendy bass rendition ',\n",
       " 'Rebukes for violent pub attacks ',\n",
       " 'Point learnt afresh, always to be remembered ',\n",
       " 'Ray eager to resolve doubtful situation ',\n",
       " 'Bar attire set out for judge ',\n",
       " 'cider’s mixed in cocktail ',\n",
       " 'Reproduce new way to get things done ',\n",
       " 'Unfortunately, Don’s away at the moment ',\n",
       " 'Amend paper said to go by the board ',\n",
       " 'golfer upset about first putt in game ',\n",
       " 'Satellite dish under woodwork for starters, possibly in a good position ',\n",
       " 'Dynamic Duo seen with person, slow and clumsy ',\n",
       " 'Value fuse, unless blown ',\n",
       " 'Dessert cooked by tramp last month ',\n",
       " '“Land of Hope” formed aria — run it ',\n",
       " 'Food for friar ',\n",
       " 'Pray church leader with bible to give us another look ',\n",
       " '34Alied about / old age once ',\n",
       " '25ATransported lady in / soft and slow ',\n",
       " '24Apath – environmentalists, primarily, are shaking / American climber ',\n",
       " '3ABase person, worthy of media coverage / drives into water ',\n",
       " '4ASacked nursemaid into some relevant collective concept? ',\n",
       " '9ARotten flesh in reserve perhaps for Mass at Ellesmere Island? ',\n",
       " '18AKeep for sale too many TVs: cooker needs shifting ',\n",
       " '5DHastens progress of former partner despite arguing ',\n",
       " '16D/Married males in coracle, all at sea, name puzzle’s star ',\n",
       " 'One helping satanists out ',\n",
       " 'Notice job is to be relocated — protest! ',\n",
       " 'State of California, if left in chaos ',\n",
       " 'A motto rewritten for the vegetarian ',\n",
       " 'An emphasis at sea? ',\n",
       " ...]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_input_df.clue.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_input_data_out = cc_input_df[cc_input_df.columns[2:]] * 1\n",
    "cc_val_data_out = cc_val_df[cc_val_df.columns[2:]] * 1\n",
    "cc_test_data_out = cc_test_df[cc_test_df.columns[2:]] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300))\n",
    "model.add(Dense(14, activation='relu', input_dim=15))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358484 samples, validate on 15859 samples\n",
      "Epoch 1/6\n",
      "358484/358484 [==============================] - 4s 12us/step - loss: 2.6402 - categorical_accuracy: 0.1630 - val_loss: 1.8977 - val_categorical_accuracy: 0.2437\n",
      "Epoch 2/6\n",
      "358484/358484 [==============================] - 4s 11us/step - loss: 2.2714 - categorical_accuracy: 0.1858 - val_loss: 1.8944 - val_categorical_accuracy: 0.2451\n",
      "Epoch 3/6\n",
      "358484/358484 [==============================] - 4s 11us/step - loss: 2.2680 - categorical_accuracy: 0.1890 - val_loss: 1.8931 - val_categorical_accuracy: 0.2467\n",
      "Epoch 4/6\n",
      "358484/358484 [==============================] - 4s 11us/step - loss: 2.2668 - categorical_accuracy: 0.1901 - val_loss: 1.8930 - val_categorical_accuracy: 0.2483\n",
      "Epoch 5/6\n",
      "358484/358484 [==============================] - 4s 11us/step - loss: 2.2676 - categorical_accuracy: 0.1922 - val_loss: 1.8963 - val_categorical_accuracy: 0.2471\n",
      "Epoch 6/6\n",
      "358484/358484 [==============================] - 4s 11us/step - loss: 2.2662 - categorical_accuracy: 0.1918 - val_loss: 1.8925 - val_categorical_accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7961/7961 [==============================] - 0s 14us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8774394556559924, 0.24695390026378597]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 300,input_length=15))\n",
    "model.add(Dense(300, activation='relu', input_dim=15))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358484 samples, validate on 15859 samples\n",
      "Epoch 1/4\n",
      "358484/358484 [==============================] - 5s 15us/step - loss: 2.2927 - categorical_accuracy: 0.1763 - val_loss: 1.8880 - val_categorical_accuracy: 0.2399\n",
      "Epoch 2/4\n",
      "358484/358484 [==============================] - 5s 14us/step - loss: 2.2690 - categorical_accuracy: 0.1828 - val_loss: 1.8880 - val_categorical_accuracy: 0.2403\n",
      "Epoch 3/4\n",
      "358484/358484 [==============================] - 5s 13us/step - loss: 2.2717 - categorical_accuracy: 0.1815 - val_loss: 1.8893 - val_categorical_accuracy: 0.2406\n",
      "Epoch 4/4\n",
      "358484/358484 [==============================] - 5s 13us/step - loss: 2.2704 - categorical_accuracy: 0.1821 - val_loss: 1.8871 - val_categorical_accuracy: 0.2438\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7961/7961 [==============================] - 0s 13us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.870498187741717, 0.24180379349327974]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300,input_length=15))\n",
    "model.add(Dense(300, activation='sigmoid', input_dim=15))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358484 samples, validate on 15859 samples\n",
      "Epoch 1/4\n",
      "358484/358484 [==============================] - 12s 34us/step - loss: 0.3581 - categorical_accuracy: 0.2702 - val_loss: 0.2852 - val_categorical_accuracy: 0.3747\n",
      "Epoch 2/4\n",
      "358484/358484 [==============================] - 11s 32us/step - loss: 0.3446 - categorical_accuracy: 0.2829 - val_loss: 0.2922 - val_categorical_accuracy: 0.3554\n",
      "Epoch 3/4\n",
      "358484/358484 [==============================] - 11s 32us/step - loss: 0.3363 - categorical_accuracy: 0.2831 - val_loss: 0.2930 - val_categorical_accuracy: 0.3540\n",
      "Epoch 4/4\n",
      "132992/358484 [==========>...................] - ETA: 7s - loss: 0.3311 - categorical_accuracy: 0.2849"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-d552d07aaa30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc_input_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcc_input_data_out\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc_val_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcc_val_data_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300,input_length=15))\n",
    "model.add(Dense(300, activation='sigmoid', input_dim=15))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 17s 35us/step - loss: 0.3612 - categorical_accuracy: 0.2776 - val_loss: 0.3047 - val_categorical_accuracy: 0.3257\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 16s 33us/step - loss: 0.3472 - categorical_accuracy: 0.2888 - val_loss: 0.3023 - val_categorical_accuracy: 0.2896\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 16s 33us/step - loss: 0.3392 - categorical_accuracy: 0.2916 - val_loss: 0.3045 - val_categorical_accuracy: 0.3026\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 16s 33us/step - loss: 0.3315 - categorical_accuracy: 0.2933 - val_loss: 0.3047 - val_categorical_accuracy: 0.3212\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358484 samples, validate on 15859 samples\n",
      "Epoch 1/4\n",
      "358484/358484 [==============================] - 6s 16us/step - loss: 0.3291 - categorical_accuracy: 0.3197 - val_loss: 0.2708 - val_categorical_accuracy: 0.3540\n",
      "Epoch 2/4\n",
      "358484/358484 [==============================] - 5s 15us/step - loss: 0.1876 - categorical_accuracy: 0.5207 - val_loss: 0.2840 - val_categorical_accuracy: 0.3600\n",
      "Epoch 3/4\n",
      "358484/358484 [==============================] - 5s 15us/step - loss: 0.1188 - categorical_accuracy: 0.6113 - val_loss: 0.3202 - val_categorical_accuracy: 0.3588\n",
      "Epoch 4/4\n",
      "358484/358484 [==============================] - 5s 15us/step - loss: 0.0821 - categorical_accuracy: 0.6546 - val_loss: 0.3613 - val_categorical_accuracy: 0.3578\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(Conv1D(filters=15,kernel_size=2))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 13s 28us/step - loss: 0.3132 - categorical_accuracy: 0.3622 - val_loss: 0.2806 - val_categorical_accuracy: 0.3209\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 12s 25us/step - loss: 0.1933 - categorical_accuracy: 0.4961 - val_loss: 0.3093 - val_categorical_accuracy: 0.3052\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 12s 24us/step - loss: 0.1522 - categorical_accuracy: 0.5294 - val_loss: 0.3411 - val_categorical_accuracy: 0.3040\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 12s 24us/step - loss: 0.1292 - categorical_accuracy: 0.5360 - val_loss: 0.3725 - val_categorical_accuracy: 0.2919\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=15))\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/10\n",
      "480706/480706 [==============================] - 22s 45us/step - loss: 0.3965 - categorical_accuracy: 0.2432 - val_loss: 0.3013 - val_categorical_accuracy: 0.3406\n",
      "Epoch 2/10\n",
      "480706/480706 [==============================] - 20s 41us/step - loss: 0.3287 - categorical_accuracy: 0.3195 - val_loss: 0.2875 - val_categorical_accuracy: 0.3196\n",
      "Epoch 3/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.2611 - categorical_accuracy: 0.4215 - val_loss: 0.2971 - val_categorical_accuracy: 0.3073\n",
      "Epoch 4/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.2048 - categorical_accuracy: 0.5103 - val_loss: 0.3144 - val_categorical_accuracy: 0.3185\n",
      "Epoch 5/10\n",
      "480706/480706 [==============================] - 20s 41us/step - loss: 0.1678 - categorical_accuracy: 0.5882 - val_loss: 0.3387 - val_categorical_accuracy: 0.3311\n",
      "Epoch 6/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.1401 - categorical_accuracy: 0.6242 - val_loss: 0.3645 - val_categorical_accuracy: 0.3281\n",
      "Epoch 7/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.1198 - categorical_accuracy: 0.6423 - val_loss: 0.3948 - val_categorical_accuracy: 0.3228\n",
      "Epoch 8/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.1046 - categorical_accuracy: 0.6477 - val_loss: 0.4164 - val_categorical_accuracy: 0.3355\n",
      "Epoch 9/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.0925 - categorical_accuracy: 0.6491 - val_loss: 0.4457 - val_categorical_accuracy: 0.3339\n",
      "Epoch 10/10\n",
      "480706/480706 [==============================] - 21s 43us/step - loss: 0.0828 - categorical_accuracy: 0.6541 - val_loss: 0.4727 - val_categorical_accuracy: 0.3281\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=15,dropout=0.5))\n",
    "# model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358484 samples, validate on 15859 samples\n",
      "Epoch 1/10\n",
      "358484/358484 [==============================] - 17s 48us/step - loss: 0.3952 - categorical_accuracy: 0.2279 - val_loss: 0.2860 - val_categorical_accuracy: 0.3814\n",
      "Epoch 2/10\n",
      "358484/358484 [==============================] - 16s 44us/step - loss: 0.3145 - categorical_accuracy: 0.3416 - val_loss: 0.2739 - val_categorical_accuracy: 0.3641\n",
      "Epoch 3/10\n",
      "358484/358484 [==============================] - 16s 45us/step - loss: 0.2660 - categorical_accuracy: 0.4149 - val_loss: 0.2724 - val_categorical_accuracy: 0.3771\n",
      "Epoch 4/10\n",
      "358484/358484 [==============================] - 16s 44us/step - loss: 0.2338 - categorical_accuracy: 0.4856 - val_loss: 0.2725 - val_categorical_accuracy: 0.3940\n",
      "Epoch 5/10\n",
      "358484/358484 [==============================] - 16s 44us/step - loss: 0.2086 - categorical_accuracy: 0.5290 - val_loss: 0.2734 - val_categorical_accuracy: 0.3673\n",
      "Epoch 6/10\n",
      "358484/358484 [==============================] - 16s 44us/step - loss: 0.1889 - categorical_accuracy: 0.5496 - val_loss: 0.2793 - val_categorical_accuracy: 0.3726\n",
      "Epoch 7/10\n",
      "358484/358484 [==============================] - 15s 43us/step - loss: 0.1727 - categorical_accuracy: 0.5675 - val_loss: 0.2852 - val_categorical_accuracy: 0.3592\n",
      "Epoch 8/10\n",
      "358484/358484 [==============================] - 15s 43us/step - loss: 0.1597 - categorical_accuracy: 0.5824 - val_loss: 0.2945 - val_categorical_accuracy: 0.3593\n",
      "Epoch 9/10\n",
      "358484/358484 [==============================] - 16s 44us/step - loss: 0.1493 - categorical_accuracy: 0.5926 - val_loss: 0.3056 - val_categorical_accuracy: 0.3508\n",
      "Epoch 10/10\n",
      "316416/358484 [=========================>....] - ETA: 1s - loss: 0.1413 - categorical_accuracy: 0.5988"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-3e898d711c6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc_input_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcc_input_data_out\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc_val_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcc_val_data_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m    117\u001b[0m            (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   4117\u001b[0m     \"\"\"\n\u001b[1;32m   4118\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 4119\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   4120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   4031\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4033\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4034\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   4169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4170\u001b[0m         \u001b[0;31m# warn and return nans like mean would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4171\u001b[0;31m         \u001b[0mrout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_median_nancheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2956\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 2957\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \"\"\"\n\u001b[0;32m--> 544\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=15,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/10\n",
      "480706/480706 [==============================] - 24s 50us/step - loss: 0.3729 - categorical_accuracy: 0.2750 - val_loss: 0.2868 - val_categorical_accuracy: 0.3534\n",
      "Epoch 2/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2979 - categorical_accuracy: 0.3678 - val_loss: 0.2798 - val_categorical_accuracy: 0.3122\n",
      "Epoch 3/10\n",
      "480706/480706 [==============================] - 22s 45us/step - loss: 0.2621 - categorical_accuracy: 0.3925 - val_loss: 0.2765 - val_categorical_accuracy: 0.2912\n",
      "Epoch 4/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2378 - categorical_accuracy: 0.3910 - val_loss: 0.2806 - val_categorical_accuracy: 0.2862\n",
      "Epoch 5/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2195 - categorical_accuracy: 0.3993 - val_loss: 0.2868 - val_categorical_accuracy: 0.2821\n",
      "Epoch 6/10\n",
      "480706/480706 [==============================] - 21s 45us/step - loss: 0.2054 - categorical_accuracy: 0.4168 - val_loss: 0.2885 - val_categorical_accuracy: 0.2942\n",
      "Epoch 7/10\n",
      "480706/480706 [==============================] - 21s 45us/step - loss: 0.1938 - categorical_accuracy: 0.4396 - val_loss: 0.2931 - val_categorical_accuracy: 0.2959\n",
      "Epoch 8/10\n",
      "480706/480706 [==============================] - 21s 45us/step - loss: 0.1837 - categorical_accuracy: 0.4620 - val_loss: 0.2958 - val_categorical_accuracy: 0.3023\n",
      "Epoch 9/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1755 - categorical_accuracy: 0.4806 - val_loss: 0.3047 - val_categorical_accuracy: 0.3062\n",
      "Epoch 10/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1686 - categorical_accuracy: 0.4963 - val_loss: 0.3069 - val_categorical_accuracy: 0.3098\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 63s 130us/step - loss: 0.3368 - categorical_accuracy: 0.3093 - val_loss: 0.2784 - val_categorical_accuracy: 0.3377\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 60s 125us/step - loss: 0.2544 - categorical_accuracy: 0.3886 - val_loss: 0.2754 - val_categorical_accuracy: 0.3392\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 59s 124us/step - loss: 0.2061 - categorical_accuracy: 0.4286 - val_loss: 0.2780 - val_categorical_accuracy: 0.3276\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 61s 127us/step - loss: 0.1781 - categorical_accuracy: 0.4674 - val_loss: 0.2845 - val_categorical_accuracy: 0.3838\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 131s 273us/step - loss: 0.2407 - categorical_accuracy: 0.4084 - val_loss: 0.2657 - val_categorical_accuracy: 0.3660\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 134s 278us/step - loss: 0.1200 - categorical_accuracy: 0.5198 - val_loss: 0.3120 - val_categorical_accuracy: 0.3779\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 129s 269us/step - loss: 0.0849 - categorical_accuracy: 0.5433 - val_loss: 0.3533 - val_categorical_accuracy: 0.3933\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 123s 256us/step - loss: 0.0670 - categorical_accuracy: 0.5531 - val_loss: 0.3648 - val_categorical_accuracy: 0.3614\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 144s 299us/step - loss: 0.2603 - categorical_accuracy: 0.3927 - val_loss: 0.2619 - val_categorical_accuracy: 0.3735\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 144s 300us/step - loss: 0.1281 - categorical_accuracy: 0.5149 - val_loss: 0.2991 - val_categorical_accuracy: 0.3854\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 141s 293us/step - loss: 0.0891 - categorical_accuracy: 0.5421 - val_loss: 0.3305 - val_categorical_accuracy: 0.3654\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 142s 294us/step - loss: 0.0699 - categorical_accuracy: 0.5525 - val_loss: 0.3636 - val_categorical_accuracy: 0.3623\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[top_3_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 155s 323us/step - loss: 0.2645 - top_3_accuracy: 0.6709 - val_loss: 0.2829 - val_top_3_accuracy: 0.6989\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 151s 315us/step - loss: 0.0995 - top_3_accuracy: 0.9275 - val_loss: 0.3524 - val_top_3_accuracy: 0.7083\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 156s 324us/step - loss: 0.0604 - top_3_accuracy: 0.9550 - val_loss: 0.4098 - val_top_3_accuracy: 0.6998\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 151s 314us/step - loss: 0.0439 - top_3_accuracy: 0.9633 - val_loss: 0.4590 - val_top_3_accuracy: 0.7104\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 144s 300us/step - loss: 0.2591 - top_3_accuracy: 0.6832 - val_loss: 0.2614 - val_top_3_accuracy: 0.7131\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 140s 292us/step - loss: 0.1269 - top_3_accuracy: 0.8907 - val_loss: 0.3014 - val_top_3_accuracy: 0.7368\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 139s 290us/step - loss: 0.0876 - top_3_accuracy: 0.9269 - val_loss: 0.3333 - val_top_3_accuracy: 0.7359\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 140s 292us/step - loss: 0.0685 - top_3_accuracy: 0.9408 - val_loss: 0.3611 - val_top_3_accuracy: 0.7363\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8475/8475 [==============================] - 2s 203us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3741736157664859, 0.7189380530903121]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cc_test_data,cc_test_data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy,'accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358484 samples, validate on 15859 samples\n",
      "Epoch 1/4\n",
      "137728/358484 [==========>...................] - ETA: 56s - loss: 0.3606 - top_3_accuracy: 0.4328 - acc: 0.8618 - categorical_accuracy: 0.2838"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-3829db48133d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc_input_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcc_input_data_out\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc_val_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcc_val_data_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5)))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy,'accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"2xBilstm-{epoch:02d}-{val_loss:.2f}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358484 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "358484/358484 [==============================] - 94s 261us/step - loss: 0.0679 - top_3_accuracy: 0.9434 - acc: 0.9739 - categorical_accuracy: 0.5914 - val_loss: 0.3665 - val_top_3_accuracy: 0.7188 - val_acc: 0.8772 - val_categorical_accuracy: 0.3850\n",
      "\n",
      "Epoch 00001: saving model to 2xBilstm-01-0.37-0.39.hdf5\n",
      "Epoch 2/4\n",
      "358484/358484 [==============================] - 94s 263us/step - loss: 0.0613 - top_3_accuracy: 0.9476 - acc: 0.9767 - categorical_accuracy: 0.5897 - val_loss: 0.4108 - val_top_3_accuracy: 0.7012 - val_acc: 0.8706 - val_categorical_accuracy: 0.3561\n",
      "\n",
      "Epoch 00002: saving model to 2xBilstm-02-0.41-0.36.hdf5\n",
      "Epoch 3/4\n",
      "358484/358484 [==============================] - 94s 261us/step - loss: 0.0556 - top_3_accuracy: 0.9517 - acc: 0.9788 - categorical_accuracy: 0.5880 - val_loss: 0.3938 - val_top_3_accuracy: 0.7240 - val_acc: 0.8772 - val_categorical_accuracy: 0.3819\n",
      "\n",
      "Epoch 00003: saving model to 2xBilstm-03-0.39-0.38.hdf5\n",
      "Epoch 4/4\n",
      "358484/358484 [==============================] - 94s 261us/step - loss: 0.0512 - top_3_accuracy: 0.9535 - acc: 0.9806 - categorical_accuracy: 0.5852 - val_loss: 0.4308 - val_top_3_accuracy: 0.7143 - val_acc: 0.8719 - val_categorical_accuracy: 0.3810\n",
      "\n",
      "Epoch 00004: saving model to 2xBilstm-04-0.43-0.38.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=1024, epochs=4,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./trainHistoryDict', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-022891121980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "# Visualize training history\n",
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8475/8475 [==============================] - 10s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4468569082215121,\n",
       " 0.6974631269069548,\n",
       " 0.8684028533426358,\n",
       " 0.36448377577604446]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./2xBilstm-02-0.34-0.42.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8475/8475 [==============================] - 10s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35202644850300474,\n",
       " 0.7262536873789311,\n",
       " 0.8688748288787572,\n",
       " 0.395634218299635]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(cc_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = cc_val_data_out - pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.absolute(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "error.to_csv('bilstm_error.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "!explorer ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_anagram 0.2924838497508312\n",
      "is_homophone 0.03737007524816139\n",
      "is_double 0.10708915418964644\n",
      "is_cryptic 0.07456189476353665\n",
      "is_contain 0.38412872530491493\n",
      "is_reverse 0.09638247365935372\n",
      "is_alternate 0.017415237142226387\n",
      "is_init 0.14328271000384435\n",
      "is_delete 0.35949966664168426\n",
      "is_charade 0.41186626313342\n",
      "is_&lit 0.040231121693441355\n",
      "is_hidden 0.0556617728000054\n",
      "is_spoonerism 0.001044038090934796\n",
      "is_palindrome 0.0017078827505269522\n"
     ]
    }
   ],
   "source": [
    "error_col_sums = [error[cat].sum() for cat in cc_types]\n",
    "for cat,err in zip(cc_types,error_col_sums):\n",
    "    print(cat,err/len(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9223,\n",
       " 2491,\n",
       " 4082,\n",
       " 2720,\n",
       " 17709,\n",
       " 5866,\n",
       " 733,\n",
       " 5608,\n",
       " 11402,\n",
       " 13779,\n",
       " 853,\n",
       " 2852,\n",
       " 162,\n",
       " 66]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(cc_val_df[cc_val_df[cat]==True]) for cat in cc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['is_anagram', 'is_homophone', 'is_double', 'is_cryptic', 'is_contain',\n",
       "       'is_reverse', 'is_alternate', 'is_init', 'is_delete', 'is_charade',\n",
       "       'is_&lit', 'is_hidden', 'is_spoonerism', 'is_palindrome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_anagram',\n",
       " 'is_homophone',\n",
       " 'is_double',\n",
       " 'is_cryptic',\n",
       " 'is_contain',\n",
       " 'is_reverse',\n",
       " 'is_alternate',\n",
       " 'is_init',\n",
       " 'is_delete',\n",
       " 'is_charade',\n",
       " 'is_&lit',\n",
       " 'is_hidden',\n",
       " 'is_spoonerism',\n",
       " 'is_palindrome']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Proceeding smoothly and evenly, judge back observing cases'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt = pad_sequences(tokenizer.texts_to_sequences([query]),maxlen=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(inpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_anagram',\n",
       " 'is_homophone',\n",
       " 'is_double',\n",
       " 'is_cryptic',\n",
       " 'is_contain',\n",
       " 'is_reverse',\n",
       " 'is_alternate',\n",
       " 'is_init',\n",
       " 'is_delete',\n",
       " 'is_charade',\n",
       " 'is_&lit',\n",
       " 'is_hidden',\n",
       " 'is_spoonerism',\n",
       " 'is_palindrome']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_anagram 0.00080093107\n",
      "is_homophone 0.001205507\n",
      "is_double 0.00011718823\n",
      "is_cryptic 3.4680426e-05\n",
      "is_contain 0.9938917\n",
      "is_reverse 0.0020614178\n",
      "is_alternate 0.9986004\n",
      "is_init 2.895232e-06\n",
      "is_delete 0.01853707\n",
      "is_charade 0.0053280066\n",
      "is_&lit 3.5364006e-05\n",
      "is_hidden 0.00079043105\n",
      "is_spoonerism 1.4816669e-06\n",
      "is_palindrome 1.3082043e-05\n"
     ]
    }
   ],
   "source": [
    "for a,b in zip(cc_types,preds[0]):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Initializer for variable embedding_2/embeddings/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-644c7d63e961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_zero\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    162\u001b[0m                     \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/layers/embeddings.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             dtype=self.dtype)\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                             constraint=constraint)\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight_regularizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(value, dtype, name, constraint)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint)\u001b[0m\n\u001b[1;32m    257\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m           \u001b[0mexpected_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpected_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint)\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0;34m\"construct, such as a loop or conditional. When creating a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0;34m\"variable inside a loop or conditional, use a lambda as the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                 \"initializer.\" % name)\n\u001b[0m\u001b[1;32m    388\u001b[0m           \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m           shape = (self._initial_value.get_shape()\n",
      "\u001b[0;31mValueError\u001b[0m: Initializer for variable embedding_2/embeddings/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer."
     ]
    }
   ],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5)))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy,'accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"3xBilstm-{epoch:02d}-{val_loss:.2f}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2195\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2196\u001b[0;31m         \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2197\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'bidirectional_2/while/mul_7' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m       \u001b[0mxla_compile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaCompile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2199\u001b[0m       \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2200\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2201\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation 'bidirectional_2/while/mul_7' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-3b8ce21ab257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc_input_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcc_input_data_out\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc_val_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcc_val_data_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    496\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    497\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    499\u001b[0m                 updates = (self.updates +\n\u001b[1;32m    500\u001b[0m                            \u001b[0mtraining_updates\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_updates_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0maccumulators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccumulators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             raise ValueError('An operation has `None` for gradient. '\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   2706\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m     \"\"\"\n\u001b[0;32m-> 2708\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)\u001b[0m\n\u001b[1;32m    594\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     return _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops,\n\u001b[0;32m--> 596\u001b[0;31m                             gate_gradients, aggregation_method, stop_gradients)\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, src_graph)\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 779\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    780\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    396\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaScope\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 779\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    780\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    908\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m   return (array_ops.reshape(\n\u001b[0;32m--> 910\u001b[0;31m       math_ops.reduce_sum(gen_math_ops.mul(grad, y), rx), sx),\n\u001b[0m\u001b[1;32m    911\u001b[0m           array_ops.reshape(\n\u001b[1;32m    912\u001b[0m               math_ops.reduce_sum(gen_math_ops.mul(x, grad), ry), sy))\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   4934\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4935\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 4936\u001b[0;31m         \"Mul\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   4937\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4938\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 instructions)\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    456\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3153\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3154\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3155\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3156\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1746\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_control_flow_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_control_flow_post_processing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1755\u001b[0m       \u001b[0mcontrol_flow_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckInputFromValidContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddOp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reconstruct_sequence_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mAddOp\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m   2436\u001b[0m             \u001b[0mop_input_ctxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AddOpInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2438\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AddOpInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_AddOpInternal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_AddOpInternal\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m   2457\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2458\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2459\u001b[0;31m         \u001b[0mreal_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreal_x\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2461\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_x\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mAddValue\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m   2389\u001b[0m               \u001b[0mforward_ctxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_ctxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetWhileContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mforward_ctxt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgrad_ctxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2391\u001b[0;31m             \u001b[0mreal_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_ctxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetRealValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2392\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_external_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2393\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreal_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mGetRealValue\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;31m# Add the stack pop op in the grad context.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m         real_value = cur_grad_state.AddBackpropAccumulatedValue(\n\u001b[0;32m-> 1140\u001b[0;31m             history_value, cur_value)\n\u001b[0m\u001b[1;32m   1141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcur_grad_state\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m           \u001b[0mreal_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mAddBackpropAccumulatedValue\u001b[0;34m(self, history_value, value, dead_branch)\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0mhistory_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SwitchRefOrTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m       pop = gen_data_flow_ops.stack_pop_v2(history_value,\n\u001b[0;32m-> 1081\u001b[0;31m                                            value.dtype.base_dtype)\n\u001b[0m\u001b[1;32m   1082\u001b[0m       \u001b[0mpop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\u001b[0m in \u001b[0;36mstack_pop_v2\u001b[0;34m(handle, elem_type, name)\u001b[0m\n\u001b[1;32m   4861\u001b[0m     \u001b[0melem_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"elem_type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4862\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 4863\u001b[0;31m         \"StackPopV2\", handle=handle, elem_type=elem_type, name=name)\n\u001b[0m\u001b[1;32m   4864\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4865\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 instructions)\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    456\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3153\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3154\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3155\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3156\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1715\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_control_flow_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_stack.py\u001b[0m in \u001b[0;36mextract_stack\u001b[0;34m(extract_frame_info_fn)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mframe_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_frame_info_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     ret.append((filename, lineno, name, frame_globals, func_start_lineno,\n\u001b[0;32m---> 63\u001b[0;31m                 frame_info))\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=1024, epochs=15,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./3xBilstmHistory', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize training history\n",
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d4afb76320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl4VOX5//H3nYXsIXuABJIAAVlUkIAggisKqKh1RxS7iLba2q/Vr1q1fmu19dfFra64VK1brUtLVRRRcCmyBERlERKQkLAlJIEskP3+/XEOMISQBMgwycz9uq65Zs42c4eLzCfnOc95HlFVjDHGmNYE+boAY4wxnZ+FhTHGmDZZWBhjjGmThYUxxpg2WVgYY4xpk4WFMcaYNllYGNMBROQFEbmvnftuEJEzj/R9jDmaLCyMMca0ycLCGGNMmywsTMBwm39uFZFvRKRaRJ4TkVQRmS0ilSIyV0TiPfafIiIrRWSHiMwXkUEe24aLyDL3uH8A4c0+61wRWe4eu0BEjjvMmq8VkXwRKRORWSLSy10vIvKQiBSLyE73ZxrqbpssIqvc2jaJyC2H9Q9mjAcLCxNoLgImAAOA84DZwK+BJJzfh18AiMgA4DXgl0Ay8D7wHxHpJiLdgH8BfwcSgH+674t77AnA88B1QCLwNDBLRMIOpVAROR34A3Ap0BMoAF53N58FjHd/jjjgMqDU3fYccJ2qxgBDgU8O5XONaYmFhQk0f1XVbaq6CfgcWKSqX6lqLfAOMNzd7zLgPVX9SFXrgT8DEcBJwGggFHhYVetV9U1gicdnXAs8raqLVLVRVV8Eat3jDsWVwPOqusyt7w5gjIhkAvVADHAMIKq6WlW3uMfVA4NFJFZVy1V12SF+rjEHsLAwgWabx+vdLSxHu6974fwlD4CqNgGFQJq7bZPuPwpngcfrDOBXbhPUDhHZAfR2jzsUzWuowjl7SFPVT4DHgMeBbSIyU0Ri3V0vAiYDBSLyqYiMOcTPNeYAFhbGtGwzzpc+4FwjwPnC3wRsAdLcdXv08XhdCNyvqnEej0hVfe0Ia4jCadbaBKCqj6rqCGAITnPUre76Jap6PpCC01z2xiF+rjEHsLAwpmVvAOeIyBkiEgr8CqcpaQHwJdAA/EJEQkTkB8Aoj2OfAa4XkRPdC9FRInKOiMQcYg2vAj8UkWHu9Y7f4zSbbRCRke77hwLVQA3Q6F5TuVJEurvNZxVA4xH8OxgDWFgY0yJVXQNMA/4KbMe5GH6eqtapah3wA+AaoBzn+sbbHsfm4ly3eMzdnu/ue6g1fAzcDbyFczbTD7jc3RyLE0rlOE1VpTjXVQCuAjaISAVwvftzGHNExCY/MsYY0xY7szDGGNMmCwtjjDFtsrAwxhjTJgsLY4wxbQrxdQEdJSkpSTMzM31dhjHGdClLly7drqrJbe3nN2GRmZlJbm6ur8swxpguRUQK2t7LmqGMMca0g4WFMcaYNllYGGOMaZPfXLNoSX19PUVFRdTU1Pi6FK8LDw8nPT2d0NBQX5dijPFDfh0WRUVFxMTEkJmZyf4DhPoXVaW0tJSioiKysrJ8XY4xxg/5dTNUTU0NiYmJfh0UACJCYmJiQJxBGWN8w6/DAvD7oNgjUH5OY4xv+HUzlDHG+K3d5bBtpfMIDoWcH3n14ywsvGzHjh28+uqr/OxnPzuk4yZPnsyrr75KXFyclyozxnQJjQ1Qtg62rXCCYav7XFG0b5/0URYWXd2OHTt44oknDgiLxsZGgoODD3rc+++/7+3SjDGdza6yZqGwAkq+gwb3emRQCCQNgIwxkDrUfQyBmB5eL83Cwstuv/121q1bx7BhwwgNDSU6OpqePXuyfPlyVq1axQUXXEBhYSE1NTXcdNNNzJgxA9g3fElVVRWTJk3i5JNPZsGCBaSlpfHvf/+biIgIH/9kxpjD1tgApXluM9KKfWcLlZv37ROZBD2Gwsif7AuF5IEQEuaTkgMmLH77n5Ws2lzRoe85uFcs95w3pNV9HnjgAVasWMHy5cuZP38+55xzDitWrNjbxfX5558nISGB3bt3M3LkSC666CISExP3e4+8vDxee+01nnnmGS699FLeeustpk2zmTKN6VI2/BeWvwJbv4WSNdBY66wPCnVCIGu8EwipQ6DHsRCd4tt6mwmYsOgsRo0atd+9EI8++ijvvPMOAIWFheTl5R0QFllZWQwbNgyAESNGsGHDhqNWrzHmCJWshbn3wJr3ISIeeg2Hvqc6Zws9hkJiNoR083WVbQqYsGjrDOBoiYqK2vt6/vz5zJ07ly+//JLIyEhOPfXUFu+VCAvbd9oZHBzM7t27j0qtxpgjUFUM8x+ApS9AaCSc8RsY/TMI7ZpNyF69z0JEJorIGhHJF5HbW9nvYhFREcnxWHeHe9waETnbm3V6U0xMDJWVlS1u27lzJ/Hx8URGRvLdd9+xcOHCo1ydMabD1e2CT/8Ejw6HZS/CyB/DTcth3K+6bFCAF88sRCQYeByYABQBS0RklqquarZfDPALYJHHusHA5cAQoBcwV0QGqGqjt+r1lsTERMaOHcvQoUOJiIggNTV177aJEyfy1FNPcdxxxzFw4EBGjx7tw0qNMUekqRG+fg0+uQ8qt8Ax58KZv4Wk/r6urEN4sxlqFJCvqusBROR14HxgVbP9fgf8EbjFY935wOuqWgt8LyL57vt96cV6vebVV19tcX1YWBizZ89ucdue6xJJSUmsWLFi7/pbbrmlxf2NMT6UPxfm/AaKV0JaDlz8N6d7qx/xZjNUGlDosVzkrttLRIYDvVX13UM91j1+hojkikhuSUlJx1RtjDHttfVbeOkCePkiqK92QuInc/0uKMC7ZxYtDVakezeKBAEPAdcc6rF7V6jOBGYC5OTkHLDdGGO8YucmmHc/LH8VwrvD2X9wrk346B6Io8GbYVEE9PZYTgc87jghBhgKzHcHwesBzBKRKe041hhjjr6aCvjvI/Dl46CNcNKNzoXriHhfV+Z13gyLJUC2iGQBm3AuWE/ds1FVdwJJe5ZFZD5wi6rmishu4FUReRDnAnc2sNiLtRpjzME11jtdYOc/ALu2w7GXwOl3Q3yGrys7arwWFqraICI3Ah8CwcDzqrpSRO4FclV1VivHrhSRN3AuhjcAN3TFnlDGmC5O1bmZ7qN7nOE5Mk6Gs34HaSf4urKjzqs35anq+8D7zdb95iD7ntps+X7gfq8VZ4wxrSlaCnPugo0LnMH7Ln8NBk6CAJ07JmDu4PaVwx2iHODhhx9mxowZREZGeqEyYwx1u6C6xHlUFUN1MVSVwJbl8N27EJUM5zwIJ0yH4MD+ugzsn/4oONgQ5e3x8MMPM23aNAsLY9pLFWorWw6A6mJ3uWTfc11Vy+8TkQDjb4WxN0FYzNH9GTopCwsv8xyifMKECaSkpPDGG29QW1vLhRdeyG9/+1uqq6u59NJLKSoqorGxkbvvvptt27axefNmTjvtNJKSkpg3b56vfxRjvEsVGmqhrhrqKp3n2irnC72u6uDLu0r3D4SGg8xFH5kIUSkQleRcc4hKgehk9znFOYvY8+zHXWAPV+CExezbnRtoOlKPY2HSA63u4jlE+Zw5c3jzzTdZvHgxqsqUKVP47LPPKCkpoVevXrz33nuAM2ZU9+7defDBB5k3bx5JSUmtfoYxnVpVMaz6tzNfQ111C2HgsdzU0L73lCDoFgPdopwQiE6GxP4eX/jNgiAyKeCbkY6U/esdRXPmzGHOnDkMHz4cgKqqKvLy8hg3bhy33HILt912G+eeey7jxo3zcaXGHKHqUlg9C1a+DRu+AG1yvtTDYvZ9yUfEQ/f0fcth0c7zAcvR7iPKPT4KQsID9kKzrwROWLRxBnA0qCp33HEH11133QHbli5dyvvvv88dd9zBWWedxW9+02KnMWM6r907nIvCK96G9fOdm9YS+8O4W2DoDyBlkK8rNEcgcMLCRzyHKD/77LO5++67ufLKK4mOjmbTpk2EhobS0NBAQkIC06ZNIzo6mhdeeGG/Y60ZynRatZWwZrYTEOs+hsY6iOsDJ/0chl7kNNXaGYBfsLDwMs8hyidNmsTUqVMZM8YZZCw6OpqXX36Z/Px8br31VoKCgggNDeXJJ58EYMaMGUyaNImePXvaBW7TedTtgrwPnYDIm+NcUI5Ng1EzYMgPnIvHFhB+R1T9Y/y9nJwczc3N3W/d6tWrGTQocE59A+3nNUdRfY0zDPfKt2HNB84Iq1EpMOQCJyB6nwhBXp1LzXiJiCxV1Zy29rMzC2NMyxrqnGsPK95yhryorXDuPzjuEqeJKWMsBAX7ukpzlFhYGGP2aWqC7z91AmL1f6BmhzME96ApMPRCyDoFgkN9XaXxAb8PC1VFAqD91F+aE42PNDU5XV3nPwAlq52uqgMnO72Y+p1uN6kZ/w6L8PBwSktLSUxM9OvAUFVKS0sJDw/3dSmmq1F1urvOfwC2rXAGzPvBMzDoPAiN8HV1phPx67BIT0+nqKiIQJhyNTw8nPT0dF+XYboKVafL6/w/wNZvnPshfvCscyZh1yFMC/w6LEJDQ8nKyvJ1GcZ0HqqQ9xHM/z1s/gris+CCp5zJfGw4DNMK+99hTCBQdW6am/cH2JTr3Dh3/uNw3GV2wdq0i4WFMf5M1endNO/3ULgIuveG8x6FYVMtJMwhsbAwxl99/7lzTaLgv84d1uc8CMOvgpBuvq7MdEFeDQsRmQg8gjMH97Oq+kCz7dcDNwCNQBUwQ1VXiUgmsBpY4+66UFWv92atxviNggXOmcSGzyGmJ0z+M5xwtXV/NUfEa2EhIsHA48AEoAhYIiKzVHWVx26vqupT7v5TgAeBie62dao6zFv1GeN3ChfDvPudu66jUmDiAzDiGusCazqEN88sRgH5qroeQEReB84H9oaFqlZ47B8F2J1lxhyqoqVO76b8uc4kP2fdDzk/gm42Ha/pON4MizSg0GO5CDix+U4icgNwM9ANON1jU5aIfAVUAHep6uderNUY79m4CMo3OLO7BQWBBLuv3ee9y0HNloNb37arFL542BkBNiIBJtwLI3/iTA5kTAfzZli0dMv0AWcOqvo48LiITAXuAqYDW4A+qloqIiOAf4nIkGZnIojIDGAGQJ8+fTq6fmOOTOVW+OB2WPmO9z4jPA7O+I0zPHhYjPc+xwQ8b4ZFEdDbYzkd2NzK/q8DTwKoai1Q675eKiLrgAHAfmOQq+pMYCY4Q5R3WOXGHImmRsh9Hj6+Fxpq4bQ7nWG8UWebNjmzyGmTu6zNlj23N+1bbr5Ngp1xm8Jjff0TmwDgzbBYAmSLSBawCbgcmOq5g4hkq2qeu3gOkOeuTwbKVLVRRPoC2cB6L9ZqTMfY8g28+0vYtNQZofXchyCxn6+rMuaIeS0sVLVBRG4EPsTpOvu8qq4UkXuBXFWdBdwoImcC9UA5ThMUwHjgXhFpwOlWe72qlnmrVmOOWG2Vc0/DwichIt4ZjO/YS2zGOOM3/HqmPGOOijWz4f1bYWchnDAdzvw/iEzwdVXGtIvNlGeMt+3cBB/c5kwSlDwIfvgBZIzxdVXGeIWFhTGHqqkRFj8Dn/wOmhqc3khjfm7DaBi/ZmFhzKHY/BX855ewZTn0P9MZSiPBhsE3/s/Cwpj2qK2ET+6HxU9DVDJc/DcYcqFdwDYBI8jXBfhaeXUdv37nW9Zuq/R1KaYzUnWuSTw2ChY95QyjccNiZ0Y5CwoTQAL+zEKBd7/eTGHZLl760Si/nqvbHKIdhU4vp7WzIXUoXPZ3SG+z04gxfingzywSorpx05kD+DxvO/PX+P9c3aYdGhtgwV/h8ROdiYMm/A5mzLegMAEt4MMC4KrRGfRNiuJ3762ivrHJ1+UYXypaCs+cCnPugqxxcMMiGPsLm1XOBLyAb4YC6BYSxJ3nDOLHL+by8sICfjjWerf4vbpdUP49lK2H0nX7ngv+60wYdOnfYdB5dl3CGJeFhev0Y1IYl53Ew3PzuGBYGvFR1me+y6vfDWXfQ9m6/UOhbD1UbNp/38gkZwynsTfBuF/Z4HzGNGNh4RIR7jpnMJMe+YyH567lt+cP9XVJpj32BsJ6JxTaEwhZ4yGhHyT2hQT3Ed7dN/Ub00VYWHgY2COGqSf24eVFG5k2OoPsVJsfwGca6qC6ZN+jqhiqi6F6u/O6cosTEhVF+x8XmeR8+e8JhIQsJyAsEIw5IhYWzdw8YSD/Xr6Z+95bzYs/GuXrcvxLXbX7xV/ifPFXuV/+e197BEPNjpbfIzQKopIgpgdknrwvCPY8IuKO7s9kTICwsGgmIaobN52RzX3vrWbemmJOG5ji65K6rvWfwhcPOlOKVpVAfXXL+4V3h6gUiE6BlEHOPBDRKc6d0lHJ+15Hp9iUocb4iIVFC64ek8krizZy37urOLl/EqHB1sP4kGzPd7qerp0N3XtDn9FOGEQluV/8KRCdvC8MQsJ8XbExpg0WFi3oFhLEnZMH8ZOXcnllYQHXWFfa9tlVBp/+EZY8AyERzrwOJ/4UQsN9XZkx5ghZWBzEGYNSOLl/Eg/NzeN860rbuoY6yH0O5j8AtRXOBECn/do5izDG+AVrXzkIEeGucwdRWVPPIx/ntX1AIFKF796HJ0bDB7dDr+Fw/Rdw3sMWFMb4GQuLVhzTI5apJ/bh7wsLyC+2UWn3s+UbeGkKvH4FBAXD1H/CVe9A6hBfV2aM8QKvhoWITBSRNSKSLyK3t7D9ehH5VkSWi8gXIjLYY9sd7nFrRORsb9bZmv85cwCR3YK5773Vviqhc6ncCv++AZ4eD1tXOJP//HQBDDjLhsYwxo95LSxEJBh4HJgEDAau8AwD16uqeqyqDgP+CDzoHjsYuBwYAkwEnnDf76hLjA7jpjOymb+mhHlrin1RQudQvxs+/RM8egJ8/Q8YcwP84isYda0NsmdMAPDmmcUoIF9V16tqHfA6cL7nDqpa4bEYhTO9BO5+r6tqrap+D+S77+cTV4/JJDMxkvvfWx14o9I2NcE3b8Bfc2DefdD/dLhxMZx9v90AZ0wA8WZYpAGFHstF7rr9iMgNIrIO58ziF4d47AwRyRWR3JIS781F4YxKO5j84ipeXbTRa5/T6WxcCM+dCW9fC1GJcM37cNnLzp3SxpiA4s2waKkBWw9Yofq4qvYDbgPuOsRjZ6pqjqrmJCcnH16Vqs7wEnrA2+/nzEEpjO2fyENz17JjV93hfVZXUb4B/nkNPH82VGyGC56Ca+dD5lgfF2aM8RVv3mdRBPT2WE4HNrey/+vAk4d57OGr2QF/zoaQcOdu47g+ELfnOWPvOolO5e5zBzP5kc95eG4e/zfFD3v91FTA53+BhU+CBMEptzsT/9gQG8YEPG+GxRIgW0SygE04F6yneu4gItmquucmhnOAPa9nAa+KyINALyAbWOyVKiUYJv0Jdm6EHe5jy9ewa/v++wV345ju6cxJTGDpkhhKQ3JITMveFywxPZ0upF1JbeW+4b1L1sDimc7PffxUOONuiO3l6wqNMZ2E18JCVRtE5EbgQyAYeF5VV4rIvUCuqs4CbhSRM4F6oByY7h67UkTeAFYBDcANqtrolULDY+HEGQeur6uGHYWwsxB2FLhBUkhGWQFxlctIXDxv//2DQiA2zT0jcR/d0yE61RkTKSrZGT77aA59oeqM6rpnRriy793X7nLzQMw4Gc6+z7m5zhhjPIi20VbfVeTk5Ghubu5R+axnPlvPn9//mpcu6smJ8VVOqOzY6AaLe3ZSuZUWLrNAt5h94RGV3MrrZIhMaPtspanRmeRnTwDsDQM3GOqqPHYWJ8DiM90hvbMgPmvfs80OZ0zAEZGlqprT1n42NtRhmH5SJq8sKuDOz2v54KbTCWlpVNqGWuficPX2/Sfx8Vwu3wBFS5y/8LWlLrkCkYkHBgnsO1vYsREaPS64B4W6YZAFGSftHwrxGTbCqzHmsFhYHIZuIUH8evIgZvx9Ka8u3sjVYzIP3CkkzPmSTmjHiLVNTbC7/OChsmd5y9fOszY5gZAyGI45xz07cEMhNq3rXTsxxnR6FhaHacLgVMb2T+TBj9Yy5fhexEUewai0QUHOfQxRicAxHVajMcZ0FBtI8DCJCHedM5iK3TYqrTHG/1lYHIFBPWO5fFQf/v5lAfnFVW0fYIwxXZSFxRG6ecIAIkKD+f37NiqtMcZ/WVgcoaToMH5+Rn8++a6YT9d6b3wqY4zxJQuLDjD9pEwyEiO5791VNATaqLTGmIBgYdEBwkKCuXPyIPKKq3htcQCNSmuMCRgWFh1kwuBUTurndKXduave1+UYY0yHsrDoICLC3ecOZqd1pTXG+CELiw40qGcsl43sw0tfbmBdiXWlNcb4DwuLDvarswYQHhrM79+zrrTGGP9hYdHBkqLD+Pnp/fn4u2I+s660xhg/YWHhBdeMdbvSvreKeutKa4zxAxYWXhAWEszd5wxm7bYqfvfuKl+XY4wxR8zCwkvOHJzKjPF9eenLAl5ZVODrcowx5ohYWHjRbROP4ZQBydzz75UsWl/q63KMMeaweTUsRGSiiKwRkXwRub2F7TeLyCoR+UZEPhaRDI9tjSKy3H3M8mad3hIcJDx6xXD6JEby01eWUVS+y9clGWPMYfFaWIhIMPA4MAkYDFwhIoOb7fYVkKOqxwFvAn/02LZbVYe5jyneqtPbukeE8uzVOdQ3NvGTF3PZVdfg65KMMeaQefPMYhSQr6rrVbUOeB0433MHVZ2nqnv+3F4IpHuxHp/pmxzNY1NPYO22Sn71xtc0NamvSzLGmEPizbBIAwo9lovcdQfzY2C2x3K4iOSKyEIRuaClA0RkhrtPbklJ576n4ZQByfx68iBmr9jKXz/J93U5xhhzSLw5B7e0sK7FP6lFZBqQA5zisbqPqm4Wkb7AJyLyraqu2+/NVGcCMwFycnI6/Z/rPz45i1VbKnho7loG9ohm4tCevi7JGGPapV1nFiJyk4jEiuM5EVkmIme1cVgR0NtjOR3Y3MJ7nwncCUxR1do961V1s/u8HpgPDG9PrZ2ZiPD7C49lWO84bn7ja1ZvqfB1ScYY0y7tbYb6kapWAGcBycAPgQfaOGYJkC0iWSLSDbgc2K9Xk4gMB57GCYpij/XxIhLmvk4CxgJ+cXdbeGgwM68aQUx4CD95MZfSqtq2DzLGGB9rb1jsaVKaDPxNVb+m5WamvVS1AbgR+BBYDbyhqitF5F4R2dO76U9ANPDPZl1kBwG5IvI1MA94QFX9IiwAUmLDmXlVDiVVtfzslWU2JIgxptMT1bab+kXkbzgXp7OA44FgYL6qjvBuee2Xk5Ojubm5vi7jkPzrq0388h/LmTa6D/ddcKyvyzHGBCARWaqqOW3t194L3D8GhgHrVXWXiCTgNEWZI3DB8DS+21rJU5+u45gesUwbndH2QcYY4wPtbYYaA6xR1R1uz6W7gJ3eKytw3Hr2QE4/JoX/m7WShTYkiDGmk2pvWDwJ7BKR44H/BQqAl7xWVQAJDhIevnwYGYmR/PTlpRSW2ZAgxpjOp71h0aDOxY3zgUdU9REgxntlBZbY8FCenT6Sxibl2pdyqa61IUGMMZ1Le8OiUkTuAK4C3nPHfQr1XlmBJyspisevdIYEufmN5TYkiDGmU2lvWFwG1OLcb7EVp2fUn7xWVYAal53MnecM5sOV23jk4zxfl2OMMXu1KyzcgHgF6C4i5wI1qmrXLLzgR2MzuWREOo98nMfsb7f4uhxjjAHaP9zHpcBi4BLgUmCRiFzszcIClYhw34VDOaGPMyTIqs02JIgxxvfa2wx1JzBSVaer6tU4w4/f7b2yAltYSDBPXTWCuMhQrn3JhgQxxvhee8MiyHPsJqD0EI41hyElxhkSZHtVLT99ZRl1DTYkiDHGd9r7hf+BiHwoIteIyDXAe8D73ivLAByb3p0/XXI8i78v455ZK2nP0CzGGOMN7RruQ1VvFZGLcEZ/FWCmqr7j1coMAFOO78V3Wyp4Yv46BveM4aoxmb4uyRgTgNo9+ZGqvgW85cVazEHcctZA1m6r5Lf/WUW/lGhO6pfk65KMMQGm1WYoEakUkYoWHpUiYt10jpKgIOGhy4aRlRTFDa8sY2OpDQlijDm6Wg0LVY1R1dgWHjGqGnu0ijQQEx7Ks9NzaFL44QuL2bJzt69LMsYEEOvR1IVkJEbxzNU5FFfUctETC8jbVunrkowxAcLCoosZlZXAP64bQ32TcvFTX7K0oMzXJRljAoCFRRc0uFcsb//0JBKiujH1mUV8tGqbr0syxvg5r4aFiEwUkTUiki8it7ew/WYRWSUi34jIxyKS4bFtuojkuY/p3qyzK+qdEMmb14/hmB4xXPf3XF5fvNHXJRlj/JjXwsIdxvxxYBIwGLhCRAY32+0rIEdVjwPeBP7oHpsA3AOciDO0yD0iEu+tWruqxOgwXr12NOOyk7n97W/568d5duOeMcYrvHlmMQrIV9X1qloHvI4zedJeqjpPVff0A10IpLuvzwY+UtUyVS0HPgImerHWLisqLIRnp+fwgxPS+MtHa/nNv1fSaHNhGGM6WLtvyjsMaUChx3IRzpnCwfwYmN3KsWkdWp0fCQ0O4i+XHE9yTBhPf7qe7VW1PHTZMMJDg31dmjHGT3gzLKSFdS3+ySsi04Ac4JRDOVZEZgAzAPr06XN4VfoJEeGOSYNIiQnnd++uoqx6MTOvzqF7hE1oaIw5ct5shioCensspwObm+8kImfiDIE+RVVrD+VYVZ2pqjmqmpOcnNxhhXdlPz45i0evGM6yjeVc9vSXbKuo8XVJxhg/4M2wWAJki0iWiHQDLgdmee4gIsOBp3GCwnMI9A+Bs0Qk3r2wfZa7zrTDlON78bdrRlFYtosfPLGA/OIqX5dkjOnivBYWqtoA3IjzJb8aeENVV4rIvSIyxd3tT0A08E8RWS4is9xjy4Df4QTOEuBed51pp5Ozk/jHdWOobWjkkqcWsGxjua9LMsZ0YeIvXS1zcnI0NzfX12V0OgWl1Vz9/GK2VdTwxJUncPoxqb4uyRjTiYjIUlXNaWs/u4Pbz2UkRvHWT08iOyWGa19ayhu5hW0fZIwxzVhYBICk6DBemzGak/ol8r9vfsPj8/IhLgqgAAAWNUlEQVTt5j1jzCGxsAgQ0WEhPDd9JOcP68WfPlzDb/+ziia7ec8Y007evM/CdDLdQoJ46NJhJEeH8ewX31NSVcuDlx5PWIjdvGeMaZ2FRYAJChLuOncwqbHh3P/+asqq6nj66hHEhtvNe8aYg7NmqAB17fi+PHTZ8SzZUMZlTy+k2G7eM8a0wsIigF04PJ3nrhlJQWk1P3hyAfnFNvOeMaZlFhYB7pQBybw+YzS76xqZ/OgXPDI3j9qGRl+XZYzpZCwsDMelxzH7pnGcPaQHD81dy6SHP2dB/nZfl2WM6UQsLAwAKbHh/PWK4bz0o1E0qjL12UX8zz+WU1JZ2/bBxhi/Z2Fh9jN+QDIf/nI8vzi9P+9+s5kz/jKfVxYV2D0ZxgQ4CwtzgPDQYG4+ayCzbxrPkF7dufOdFVz01AJWba7wdWnGGB+xsDAH1T8lmlevPZGHLjuejaW7OO+xL7j/vVVU1zb4ujRjzFFmYWFaJSJcODydT351KpeN7M0zn3/PmQ9+yocrt9r4UsYEEAsL0y7dI0P5/YXH8tZPT6J7RCjX/X0p176US1H5Ll+XZow5CiwszCEZkRHPf35+MndOHsSCdaVMePAznvp0HfWNTb4uzRjjRRYW5pCFBgdx7fi+fHTzKYzLTuKB2d9x7qNfkLvBJjM0xl9ZWJjDlhYXwcyrc3jm6hwqa+q5+Kkvuf2tbyivrvN1acaYDmZhYY7YhMGpfHTzKVw3vi//XFrEGQ9+yptLi+wCuDF+xKthISITRWSNiOSLyO0tbB8vIstEpEFELm62rVFElruPWd6s0xy5qLAQ7pg8iHd/fjJZSVHc8s+vuXzmQhuc0Bg/Id76609EgoG1wASgCFgCXKGqqzz2yQRigVuAWar6pse2KlWNbu/n5eTkaG5ubscUb45IU5PyRm4hf5j9HbvqGrg0pzfXn9KP3gmRvi7NGNOMiCxV1Zy29vPm5EejgHxVXe8W9DpwPrA3LFR1g7vNutL4kaAg4fJRfThzcCoPfrSWf+YW8fqSQs4f1oufndqP/ikxvi7RGHOIvNkMlQYUeiwXuevaK1xEckVkoYhc0NIOIjLD3Se3pKTkSGo1XpAUHcbvLzyWz/73NK45KZPZ325lwkOf8dOXl7Ji005fl2eMOQTeDAtpYd2htHn1cU+NpgIPi0i/A95Mdaaq5qhqTnJy8uHWabysR/dw7j53MF/cdho3nNqfL/K3c+5fv2D684tZYt1tjekSvBkWRUBvj+V0YHN7D1bVze7zemA+MLwjizNHX2J0GLecPZD/3n46t549kBWbdnLJU19y6VNf8unaEus9ZUwn5s2wWAJki0iWiHQDLgfa1atJROJFJMx9nQSMxeNah+naYsNDueG0/nxx2+ncc95gCst3Mf35xUx57L98sGKLDYduTCfktd5QACIyGXgYCAaeV9X7ReReIFdVZ4nISOAdIB6oAbaq6hAROQl4GmjCCbSHVfW51j7LekN1XXUNTby9rIgnP11HQekuslOi+dlp/TjvuF6EBNutQMZ4U3t7Q3k1LI4mC4uur6Gxife+3cIT89axZlslvRMiuP6Uflw8Ip2wkGBfl2eMX7KwMF1WU5Py8XfFPDYvn68Ld5AaG8a14/oy9cQ+RHbzZm9vYwKPhYXp8lSVBetKeeyTfL5cX0p8ZCg/HJvF9JMy6R4R6uvyjPELFhbGrywtKOeJefl8/F0x0WEhTBudwVVjMkiLi/B1acZ0aRYWxi+t2lzBE/Pzef/bLQCcfkwKV47OYHx2MsFBLd3aY4xpTWcY7sOYDje4VyyPTT2BovJdvLZ4I/9YUsjc1cWkx0cw9cQ+XJrTm6ToMF+XaYzfsTML06XVNTQxZ9VWXl5YwML1ZYQGC5OG9mTa6AxGZsYjYmcbxrTGmqFMwMkvruTlhRt5a1kRlTUNDEiNZtroDC4YnkZsuF0QN6YlFhYmYO2qa+A/X2/m5YUb+XbTTiK7BXP+sF5ceWIGQ9O6+7o8YzoVCwtjgG+KdvDywgJmfb2ZmvomhvWOY9roDM49rifhoXajnzEWFsZ42LmrnreWFfHyogLWl1TTPSKUS0akc+XoDLKSonxdnjE+Y2FhTAtUlS/Xl/LKwo18uHIrDU3Kyf2TmDa6D2cMSiXUxqIyAcbCwpg2FFfU8I8lhby2eCObd9aQGhvGxSPSmTS0J0N6xVpPKhMQLCyMaafGJmXed8W8vKiAz9aW0KTQJyGSiUN7MHFoD4alxxFkN/wZP2VhYcxhKK2q5aNV25i9YisL1m2nvlHpERu+NzhGZibYneLGr1hYGHOEdu6u5+PVTnB8traE2oYmEqO6cdaQVCYO7clJ/RLtGofp8iwsjOlA1bUNzFtTzAcrtjLvu2Kq6xqJDQ/hzMGpTBrak3HZSdYV13RJFhbGeElNfSOf521n9ootzF21jYqaBqK6BXPaMSlMGtqTUwcmExVmw66ZrsEGEjTGS8JDg5kwOJUJg1Opa2jiy/WlfLBiC3NWbuPdb7YQFhLEKQOSmTi0B2cMSrW5N4xf8PYc3BOBR3Dm4H5WVR9otn08zhzdxwGXq+qbHtumA3e5i/ep6outfZadWRhfa2hsYsmGcj5YsYUPVm5lW0UtocHCSf2SOHNwKuOzk8hItBsATefi82YoEQkG1gITgCJgCXCFqq7y2CcTiAVuAWbtCQsRSQBygRxAgaXACFUtP9jnWViYzqSpSfmqcMfe4Cgs2w04XXLHD0hiXHYyY/ol2gCHxuc6QzPUKCBfVde7Bb0OnA/sDQtV3eBua2p27NnAR6pa5m7/CJgIvObFeo3pMEFBwoiMeEZkxPPryYP4fns1n+dt57O1Jby9bBMvL9xIcJAwvHcc47KTGT8giePS46xbrum0vBkWaUChx3IRcOIRHJvWfCcRmQHMAOjTp8/hVWmMl4kIfZOj6ZsczfSTMqlraGLZxnI+zyvh87ztPPzxWh6au5bY8BBOznbOOsZlJ5EeH+nr0o3Zy5th0dKfSO1t82rXsao6E5gJTjNU+0szxne6hQQxum8io/smcuvZUFZdx3/znbOOz/O28/63WwHomxzFeDc4RvdNtB5Wxqe8+b+vCOjtsZwObD6EY09tduz8DqnKmE4mIaob5x3fi/OO74Wqkl9cxWd52/k8r4TXl2zkhQUbCA0WTugTz/gByYzPTmZIr1gbgsQcVd68wB2Cc4H7DGATzgXuqaq6soV9XwDebXaBeylwgrvLMpwL3GUH+zy7wG38UU19I8sKyvk0r4TP125n1ZYKwAmYsf2TGJWVQE5GPANSY+x6hzksPu8N5RYxGadrbDDwvKreLyL3ArmqOktERgLvAPFADbBVVYe4x/4I+LX7Vver6t9a+ywLCxMISiprnSarvBK+yNtOcWUtADFhIQzPiCfHfRzfO86arUy7dIqwOJosLEygUVUKy3azdGMZuRvKWVpQzpptlahCcJAwqGcMORkJjMiIJycznp7dI3xdsumELCyMCUA7d9fz1UYnOHI3lLO8cAe76xsBSIuL2BscIzLiOaZHrDVdmU5xn4Ux5ijrHhHKqQNTOHVgCgD1jU18t6WS3IIycgvKWfx9GbO+dvqZRHULZnif+L0BMrxPPNHWdGUOws4sjAkgqsqmHbv3nnnkFpSzZmsFTQpBAsf0iGVERjzHpnVnSFosA1JjbBh2P2fNUMaYdqmsqWd54Y691z2WF+6gqrYBgG7BQRzTM4YhvbozNC2Wob26M7BHjA3H7kcsLIwxh6WpSSko28WKTTudx+adrNhUwc7d9QCEBAn9U6I5Nq07Q9OcEBnUM5bIbtaE1RVZWBhjOoyqUlS+m5VucHzrBklpdR0AItAvOZqhvWLdAOnO4F6xNlBiF2AXuI0xHUZE6J0QSe+ESCYO7Qk4AbKtona/s4+F68v41/J9AzVkJkYyJK07Q3s54ZGdEk3P7uGIWC+srsbCwhhzWESEHt3D6dE9nDMHp+5dX1JZy8rNO1m5uYIVm3byTdEO3vtmy97t0WEh9E+JJjslmuzUaLJTYuifEk1aXIQNYdKJWTOUMcbrduyqY83WStYWV5G/rZK84iryiqsoce9AB4gIDXZCxA2QPWGSHh9p94N4kTVDGWM6jbjIbpzYN5ET+ybut37HrjonOLZVkVdcSX5xFQvyS3l72aa9+4SFBNEvOZoBqdFkp8bsPSvpkxBJiHXrPWosLIwxPhMX2Y2RmQmMzEzYb31FTT1526rIL650g6SKJRvK97se0i0kiL5JUfRNjiIjMYrMxEj3OYqUmDBr0upgFhbGmE4nNjx070yDnqpqG8gvriJvm3MWsnZbJd9tqWTOym00NO1rUg8LCSJjb3jsC5GMxEh6xUVYs9ZhsLAwxnQZ0WEhDOsdx7Decfutb2hsYsvOGjaUVrOhdBcF26spKNtFQWk1n60tobZh38zNocFC7/jI/cMkyQmTtLgIuoVY01ZLLCyMMV1eSHDQ3q6947L339bUpGyrrGHDdic8NpTuYmNZNRu272Lx92VU1zXu3TdIIC0+gszEKNLjI0iPj3SfI0iLiwzo5i0LC2OMXwsKEnp2j6Bn9wjG9Nv/Aruqsr2qbm+IFJRWU+A+z9lcsfemwz26BQfRKy6ctPgI0uPcIElwgiQ9PoLU2HC/beKysDDGBCwRITkmjOSYMHKaXWQH2FXXwOYduyks301R+W42le+mqHwXReW7+WRN8X5df8EZCqVnXPi+IImPdILFffSIDe+yPbgsLIwx5iAiu4XQPyWG/ikxLW6vqW9k0449IeIEyaYdzuvP8koorqzF81a2IIHE6DBSY8NIjQknJTaMlJhwUmPDSd37OozE6LBOd4ZiYWGMMYcpPDSYfsnR9EuObnF7bUMjW3bUOGclO3axqXw3xZW1bKuoYWtFDV8X7aS0ev9AASdUkqLD9oVIbDgpMWH7hUpKbBiJUUcvVLwaFiIyEXgEZw7uZ1X1gWbbw4CXgBFAKXCZqm4QkUxgNbDG3XWhql7vzVqNMaajhYUEk5kURWZS1EH3qW9sYntVLcUVTohsq6yluKLGWa6sYdOOGr7auOOA6yfgTJ+bHB3GyKwE/nrFcG/+KN4LCxEJBh4HJgBFwBIRmaWqqzx2+zFQrqr9ReRy4P8Bl7nb1qnqMG/VZ4wxnUFocNDeC/CtqWtwQmVbRQ3FbqBscwMmJTbM63V688xiFJCvqusBROR14HzAMyzOB/7Pff0m8JjYcJTGGHOAbiFB9IqLoFdc66HiLd68LJ8GFHosF7nrWtxHVRuAncCevm1ZIvKViHwqIuO8WKcxxpg2ePPMoqUzhOZD3B5sny1AH1UtFZERwL9EZIiqVux3sMgMYAZAnz59OqBkY4wxLfHmmUUR0NtjOR3YfLB9RCQE6A6UqWqtqpYCqOpSYB0woPkHqOpMVc1R1Zzk5GQv/AjGGGPAu2GxBMgWkSwR6QZcDsxqts8sYLr7+mLgE1VVEUl2L5AjIn2BbGC9F2s1xhjTCq81Q6lqg4jcCHyI03X2eVVdKSL3ArmqOgt4Dvi7iOQDZTiBAjAeuFdEGoBG4HpVLfNWrcYYY1pnM+UZY0wAa+9MeV1zkBJjjDFHlYWFMcaYNvlNM5SIlAAFR/AWScD2DirH27pSrdC16u1KtULXqrcr1Qpdq94jqTVDVdvsTuo3YXGkRCS3Pe12nUFXqhW6Vr1dqVboWvV2pVqha9V7NGq1ZihjjDFtsrAwxhjTJguLfWb6uoBD0JVqha5Vb1eqFbpWvV2pVuha9Xq9VrtmYYwxpk12ZmGMMaZNFhbGGGPaFPBhISITRWSNiOSLyO2+rqc1ItJbROaJyGoRWSkiN/m6praISLA7L8m7vq6lLSISJyJvish37r/xGF/XdDAi8j/u/4EVIvKaiIT7uiZPIvK8iBSLyAqPdQki8pGI5LnP8b6scY+D1Pon9//BNyLyjojE+bJGTy3V67HtFhFREUnq6M8N6LDwmPp1EjAYuEJEBvu2qlY1AL9S1UHAaOCGTl4vwE0486l3BY8AH6jqMcDxdNK6RSQN+AWQo6pDcQbqvLz1o466F4CJzdbdDnysqtnAx+5yZ/ACB9b6ETBUVY8D1gJ3HO2iWvECB9aLiPTGmcZ6ozc+NKDDAo+pX1W1Dtgz9WunpKpbVHWZ+7oS58us+eyDnYaIpAPnAM/6upa2iEgszmjHzwGoap2q7vBtVa0KASLceWAiOXCuGJ9S1c9wRpL2dD7wovv6ReCCo1rUQbRUq6rOcWfvBFiIMx9Pp3CQf1uAh4D/5cBJ5jpEoIdFe6Z+7ZREJBMYDizybSWtehjnP2+Trwtph75ACfA3t9nsWRGJ8nVRLVHVTcCfcf6C3ALsVNU5vq2qXVJVdQs4f/gAKT6up71+BMz2dRGtEZEpwCZV/dpbnxHoYdGeqV87HRGJBt4Cftl8qtnOQkTOBYrdmQ67ghDgBOBJVR0OVNN5mkn247b1nw9kAb2AKBGZ5tuq/JOI3InT/PuKr2s5GBGJBO4EfuPNzwn0sGjP1K+dioiE4gTFK6r6tq/racVYYIqIbMBp3jtdRF72bUmtKgKKVHXPmdqbOOHRGZ0JfK+qJapaD7wNnOTjmtpjm4j0BHCfi31cT6tEZDpwLnCldu4b0vrh/OHwtfv7lg4sE5EeHfkhgR4W7Zn6tdMQEcFpU1+tqg/6up7WqOodqpquqpk4/66fqGqn/etXVbcChSIy0F11BrDKhyW1ZiMwWkQi3f8TZ9BJL8Y34zmN8nTg3z6spVUiMhG4DZiiqrt8XU9rVPVbVU1R1Uz3960IOMH9P91hAjos3AtYe6Z+XQ28oaorfVtVq8YCV+H8lb7cfUz2dVF+5OfAKyLyDTAM+L2P62mRe/bzJrAM+Bbn97hTDU0hIq8BXwIDRaRIRH4MPABMEJE8nF47D/iyxj0OUutjQAzwkft79pRPi/RwkHq9/7md++zKGGNMZxDQZxbGGGPax8LCGGNMmywsjDHGtMnCwhhjTJssLIwxxrTJwsKYTkBETu0KI/OawGVhYYwxpk0WFsYcAhGZJiKL3Ru1nnbn66gSkb+IyDIR+VhEkt19h4nIQo85EeLd9f1FZK6IfO0e0899+2iP+TRece/ONqZTsLAwpp1EZBBwGTBWVYcBjcCVQBSwTFVPAD4F7nEPeQm4zZ0T4VuP9a8Aj6vq8ThjOm1x1w8Hfokzt0pfnDv2jekUQnxdgDFdyBnACGCJ+0d/BM5geE3AP9x9XgbeFpHuQJyqfuqufxH4p4jEAGmq+g6AqtYAuO+3WFWL3OXlQCbwhfd/LGPaZmFhTPsJ8KKq7jdrmojc3Wy/1sbQaa1pqdbjdSP2+2k6EWuGMqb9PgYuFpEU2DundAbO79HF7j5TgS9UdSdQLiLj3PVXAZ+6848UicgF7nuEufMRGNOp2V8uxrSTqq4SkbuAOSISBNQDN+BMlDRERJYCO3Gua4AzDPdTbhisB37orr8KeFpE7nXf45Kj+GMYc1hs1FljjpCIVKlqtK/rMMabrBnKGGNMm+zMwhhjTJvszMIYY0ybLCyMMca0ycLCGGNMmywsjDHGtMnCwhhjTJv+P9daw63Z/axdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d4afbe14e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize training history\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['top_3_accuracy'])\n",
    "plt.plot(history.history['val_top_3_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Operation 'IsVariableInitialized_25' has been marked as not fetchable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-f5825fc446f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./3xBilstm-09-0.35-0.40.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1159\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[0;32m-> 1161\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m    926\u001b[0m                              ' elements.')\n\u001b[1;32m    927\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2438\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2439\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2440\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 197\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    198\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1085\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_assert_fetchable\u001b[0;34m(self, graph, op)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m       raise ValueError(\n\u001b[0;32m--> 453\u001b[0;31m           'Operation %r has been marked as not fetchable.' % op.name)\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation 'IsVariableInitialized_25' has been marked as not fetchable."
     ]
    }
   ],
   "source": [
    "model.load_weights(\"./3xBilstm-09-0.35-0.40.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8475/8475 [==============================] - 15s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35682671900695756,\n",
       " 0.695457227223039,\n",
       " 0.8662452500267367,\n",
       " 0.3838348082912355]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_anagram 0.27134508811291974\n",
      "is_homophone 0.03939075873617451\n",
      "is_double 0.12846538594596674\n",
      "is_cryptic 0.07140522638860179\n",
      "is_contain 0.3844037081804604\n",
      "is_reverse 0.10374778863039356\n",
      "is_alternate 0.015119418038496854\n",
      "is_init 0.1409753661600937\n",
      "is_delete 0.3709257346433262\n",
      "is_charade 0.423911651140193\n",
      "is_&lit 0.02586975332928806\n",
      "is_hidden 0.07024161006097804\n",
      "is_spoonerism 0.0011445446166587546\n",
      "is_palindrome 0.0011181712882566018\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(cc_val_data)\n",
    "error = cc_val_data_out - pred\n",
    "error = np.absolute(error)\n",
    "error_col_sums = [error[cat].sum() for cat in cc_types]\n",
    "for cat,err in zip(cc_types,error_col_sums):\n",
    "    print(cat,err/len(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt = pad_sequences(tokenizer.texts_to_sequences(['God hurt back']),maxlen=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(inpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_anagram',\n",
       " 'is_homophone',\n",
       " 'is_double',\n",
       " 'is_cryptic',\n",
       " 'is_contain',\n",
       " 'is_reverse',\n",
       " 'is_alternate',\n",
       " 'is_init',\n",
       " 'is_delete',\n",
       " 'is_charade',\n",
       " 'is_&lit',\n",
       " 'is_hidden',\n",
       " 'is_spoonerism',\n",
       " 'is_palindrome']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81713134 is_anagram\n",
      "8.477837e-07 is_homophone\n",
      "0.016211942 is_double\n",
      "0.15162018 is_cryptic\n",
      "0.1603352 is_contain\n",
      "0.5928789 is_reverse\n",
      "0.04534334 is_alternate\n",
      "0.0005872622 is_init\n",
      "0.41834003 is_delete\n",
      "0.2962581 is_charade\n",
      "0.04753652 is_&lit\n",
      "0.0013712196 is_hidden\n",
      "2.8428673e-07 is_spoonerism\n",
      "0.0067614135 is_palindrome\n"
     ]
    }
   ],
   "source": [
    "for a,b in zip(preds[0],cc_types):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
