{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import keras\n",
    "from keras.layers import Dense,Embedding, Flatten, Conv1D, GlobalMaxPooling1D, LSTM, Bidirectional\n",
    "from keras.preprocessing.text import text_to_word_sequence,Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./cryptic_dataset/combined_fifteen_times_final.pickle\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_types = \"is_anagram\tis_homophone\tis_double\tis_cryptic\tis_contain\tis_reverse\tis_alternate\tis_init\tis_delete\tis_charade\tis_&lit\tis_hidden\tis_spoonerism\tis_palindrome\".split('\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.clue = df.clue.apply(text_to_word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_types_dfs = [df[df[cc_type]==True] for cc_type in cc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for cc_type,cc_type_df in zip(cc_types,cc_types_dfs):\n",
    "    cc_type_df['category'] = cc_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.concat(cc_types_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = concatenated_df.groupby('category').count().max()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [concatenated_df]\n",
    "for class_index, group in concatenated_df.groupby('category'):\n",
    "    sample = group.sample(max_size-len(group), replace=True, )\n",
    "    lst.append(sample)\n",
    "upsampled_df = pd.concat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clue</th>\n",
       "      <th>exp</th>\n",
       "      <th>is_anagram</th>\n",
       "      <th>is_homophone</th>\n",
       "      <th>is_double</th>\n",
       "      <th>is_cryptic</th>\n",
       "      <th>is_contain</th>\n",
       "      <th>is_reverse</th>\n",
       "      <th>is_alternate</th>\n",
       "      <th>is_init</th>\n",
       "      <th>is_delete</th>\n",
       "      <th>is_charade</th>\n",
       "      <th>is_&amp;lit</th>\n",
       "      <th>is_hidden</th>\n",
       "      <th>is_spoonerism</th>\n",
       "      <th>is_palindrome</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_&amp;lit</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_alternate</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_anagram</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_charade</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_contain</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_cryptic</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_delete</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_double</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_hidden</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_homophone</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_init</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_palindrome</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_reverse</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_spoonerism</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                clue    exp  is_anagram  is_homophone  is_double  is_cryptic  \\\n",
       "category                                                                       \n",
       "is_&lit        36581  36581       36581         36581      36581       36581   \n",
       "is_alternate   36581  36581       36581         36581      36581       36581   \n",
       "is_anagram     36581  36581       36581         36581      36581       36581   \n",
       "is_charade     36581  36581       36581         36581      36581       36581   \n",
       "is_contain     36581  36581       36581         36581      36581       36581   \n",
       "is_cryptic     36581  36581       36581         36581      36581       36581   \n",
       "is_delete      36581  36581       36581         36581      36581       36581   \n",
       "is_double      36581  36581       36581         36581      36581       36581   \n",
       "is_hidden      36581  36581       36581         36581      36581       36581   \n",
       "is_homophone   36581  36581       36581         36581      36581       36581   \n",
       "is_init        36581  36581       36581         36581      36581       36581   \n",
       "is_palindrome  36581  36581       36581         36581      36581       36581   \n",
       "is_reverse     36581  36581       36581         36581      36581       36581   \n",
       "is_spoonerism  36581  36581       36581         36581      36581       36581   \n",
       "\n",
       "               is_contain  is_reverse  is_alternate  is_init  is_delete  \\\n",
       "category                                                                  \n",
       "is_&lit             36581       36581         36581    36581      36581   \n",
       "is_alternate        36581       36581         36581    36581      36581   \n",
       "is_anagram          36581       36581         36581    36581      36581   \n",
       "is_charade          36581       36581         36581    36581      36581   \n",
       "is_contain          36581       36581         36581    36581      36581   \n",
       "is_cryptic          36581       36581         36581    36581      36581   \n",
       "is_delete           36581       36581         36581    36581      36581   \n",
       "is_double           36581       36581         36581    36581      36581   \n",
       "is_hidden           36581       36581         36581    36581      36581   \n",
       "is_homophone        36581       36581         36581    36581      36581   \n",
       "is_init             36581       36581         36581    36581      36581   \n",
       "is_palindrome       36581       36581         36581    36581      36581   \n",
       "is_reverse          36581       36581         36581    36581      36581   \n",
       "is_spoonerism       36581       36581         36581    36581      36581   \n",
       "\n",
       "               is_charade  is_&lit  is_hidden  is_spoonerism  is_palindrome  \n",
       "category                                                                     \n",
       "is_&lit             36581    36581      36581          36581          36581  \n",
       "is_alternate        36581    36581      36581          36581          36581  \n",
       "is_anagram          36581    36581      36581          36581          36581  \n",
       "is_charade          36581    36581      36581          36581          36581  \n",
       "is_contain          36581    36581      36581          36581          36581  \n",
       "is_cryptic          36581    36581      36581          36581          36581  \n",
       "is_delete           36581    36581      36581          36581          36581  \n",
       "is_double           36581    36581      36581          36581          36581  \n",
       "is_hidden           36581    36581      36581          36581          36581  \n",
       "is_homophone        36581    36581      36581          36581          36581  \n",
       "is_init             36581    36581      36581          36581          36581  \n",
       "is_palindrome       36581    36581      36581          36581          36581  \n",
       "is_reverse          36581    36581      36581          36581          36581  \n",
       "is_spoonerism       36581    36581      36581          36581          36581  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled_df.groupby('category').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaled_cc_dfs = [x[1] for x in upsampled_df.groupby('category')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_val_test(df):\n",
    "    length = len(df)\n",
    "    input_len = math.floor(length*0.7)\n",
    "    val_len  = math.floor(length*0.2)\n",
    "    test_len = math.floor(length*0.1)\n",
    "    input_df = df[:input_len]\n",
    "    val_df = df[input_len:input_len+val_len]\n",
    "    test_df = df[input_len+val_len:]\n",
    "    return input_df,val_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_cc_types_dfs = [x[1] for x in upsampled_df.groupby('category')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dfs = []\n",
    "val_dfs = []\n",
    "test_dfs = []\n",
    "for cc_type_df in upsampled_cc_types_dfs:\n",
    "    input_df,val_df,test_df = get_input_val_test(cc_type_df)\n",
    "    input_dfs.append(input_df)\n",
    "    val_dfs.append(val_df)\n",
    "    test_dfs.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_input_df = pd.concat(input_dfs)\n",
    "cc_val_df = pd.concat(val_dfs).drop('category',axis=1).drop_duplicates()\n",
    "cc_test_df = pd.concat(test_dfs).drop('category',axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df.clue.tolist())\n",
    "cc_input_data = pad_sequences(tokenizer.texts_to_sequences(cc_input_df.clue.tolist()),maxlen=15)\n",
    "cc_val_data = pad_sequences(tokenizer.texts_to_sequences(cc_val_df.clue.tolist()),maxlen=15)\n",
    "cc_test_data = pad_sequences(tokenizer.texts_to_sequences(cc_test_df.clue.tolist()),maxlen=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clue</th>\n",
       "      <th>exp</th>\n",
       "      <th>is_anagram</th>\n",
       "      <th>is_homophone</th>\n",
       "      <th>is_double</th>\n",
       "      <th>is_cryptic</th>\n",
       "      <th>is_contain</th>\n",
       "      <th>is_reverse</th>\n",
       "      <th>is_alternate</th>\n",
       "      <th>is_init</th>\n",
       "      <th>is_delete</th>\n",
       "      <th>is_charade</th>\n",
       "      <th>is_&amp;lit</th>\n",
       "      <th>is_hidden</th>\n",
       "      <th>is_spoonerism</th>\n",
       "      <th>is_palindrome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9139</th>\n",
       "      <td>Undefined number carried by rail, coming in to...</td>\n",
       "      <td>TRAINLOAD (A nice &amp;lit!) N = “Undefined numbe...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69231</th>\n",
       "      <td>For instance, spread either side of level path?</td>\n",
       "      <td>ASPHALT AS (for instance) + [L (either side ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29228</th>\n",
       "      <td>English literary doctrine favouring the Establ...</td>\n",
       "      <td>ELITISM – E (English) LIT (literary) ISM (doc...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71545</th>\n",
       "      <td>Confusing note with others?</td>\n",
       "      <td>&amp;lit; NOTE* D E A F (notes in the musical oct...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52947</th>\n",
       "      <td>Gloss cast light on standard operating procedu...</td>\n",
       "      <td>Reverse of LIT S.O.P.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13649</th>\n",
       "      <td>______ is lead free with energy for accelerati...</td>\n",
       "      <td>(IS LEAD)* with E(energy) replacing A (acceler...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56775</th>\n",
       "      <td>One ignited in company of friend to fight for ...</td>\n",
       "      <td>I (one) LIT (ignited) inside (in company of) ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>Stick — —- on billboard?</td>\n",
       "      <td>ADHERE AD HERE. Wonderful &amp;lit-ish clue! Down...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26233</th>\n",
       "      <td>Pair Maced horrifically might require one</td>\n",
       "      <td>(Pair Maced)*, &amp;lit. — Ithink it’s the chemic...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>Monster turning on a child with ruler? Not the...</td>\n",
       "      <td>TE (rev of ET,extraterrestrial) A CH (child) ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74152</th>\n",
       "      <td>18AAs for heading off into country, is it to s...</td>\n",
       "      <td>&amp;lit / PANAMA (country) around OR (fOR with h...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52164</th>\n",
       "      <td>What’s displaying form of rut with age?</td>\n",
       "      <td>*(RUT AGE). Another &amp; lit clue, where the def...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50774</th>\n",
       "      <td>25AMobile business processor?</td>\n",
       "      <td>&amp;lit-ish/CD? / A PORTALOO could be described ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70060</th>\n",
       "      <td>Steps made in a chaotic way</td>\n",
       "      <td>STAMPEDES An &amp;lit – an anagram of STEPS MADE ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50429</th>\n",
       "      <td>Person snaring new skin of tigress?</td>\n",
       "      <td>N + T[igres]S in HUMAN, &amp;lit</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21638</th>\n",
       "      <td>6Ddeveloper in another’s pocket becomes such a...</td>\n",
       "      <td>&amp;lit-ish/double defn.? / a baby (kanga)roo, t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45293</th>\n",
       "      <td>7DCraved by petrol-head dieters?</td>\n",
       "      <td>&amp;lit-ish/CD – or self-introspective double de...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92015</th>\n",
       "      <td>Flipping brilliant hiding data sheets in the k...</td>\n",
       "      <td>TINFOIL LIT = “brilliant” (seems a bit of a s...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92683</th>\n",
       "      <td>Start to sense by smell</td>\n",
       "      <td>S (start to Sense) + NIFF (smell); &amp;lit.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93943</th>\n",
       "      <td>Reason for strong medical preparation?</td>\n",
       "      <td>(STRONG MEDICAL)* AInd: Preparation. &amp;Lit</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65347</th>\n",
       "      <td>Matter involving educating appalling children,...</td>\n",
       "      <td>TEACHING THING [matter] round initial letters...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63668</th>\n",
       "      <td>Quantity of dirt suddenly swirling?</td>\n",
       "      <td>Hidden reversed in dirT SUDdenly, &amp;lit.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34144</th>\n",
       "      <td>Are they scattered around, brought in by hunts...</td>\n",
       "      <td>Not sure about “are they scattered around?” u...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7328</th>\n",
       "      <td>Stars who may become despicable if not paid</td>\n",
       "      <td>CELEBS isan anagram (may become) ofDISPICABLE...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>35AWhat follows sex to make it attract one’s i...</td>\n",
       "      <td>/ &amp;lit-ish – APPEAL = attract one’s interest,...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96800</th>\n",
       "      <td>Deploying this initially, police range in it?</td>\n",
       "      <td>RANGE in D(eploying) T(his); another &amp; lit cl...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6920</th>\n",
       "      <td>One with no heart in novel form?</td>\n",
       "      <td>ANTIHERO – an anagram (in novel form) of I (o...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>In which Gandhi’s lower half’s also wrapped up?</td>\n",
       "      <td>ganDHI (lower half of) includes (wraps) TOO (...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31905</th>\n",
       "      <td>Insect maturing and going off at first?</td>\n",
       "      <td>IMAGO The first letters of I[nsect] M[aturing...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23883</th>\n",
       "      <td>She’ll give a mother a bit of help</td>\n",
       "      <td>A MA H(elp). Another &amp; lit clue for this Asia...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70332</th>\n",
       "      <td>Pub to which Spooner’s working girl retired</td>\n",
       "      <td>BOARS HEAD : Spoonerism of “whore’s bed”(the ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41349</th>\n",
       "      <td>For Spooner to attend to small cut is clever p...</td>\n",
       "      <td>Spoonerization of TREAT NICK (to attend to sm...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11642</th>\n",
       "      <td>Spooner’s horse does this for a bunch of flowers</td>\n",
       "      <td>NOSEGAY Spooner’s horse ‘GOES NEIGH’: unlike ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81558</th>\n",
       "      <td>“Dress will detract from the man” says Spooner</td>\n",
       "      <td>The Rev.William Archibald Spooner has a lot t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39267</th>\n",
       "      <td>Spooner acclaims Mia’s role in “Zulu Dawn”</td>\n",
       "      <td>SPARROWFART This was a new word for us – it’s...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71985</th>\n",
       "      <td>Novel storage unit in Spooner’s kitchen?</td>\n",
       "      <td>BOOKCASE – the Spoonerism being ‘cook base’ (...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Self-proclaimed birdwatcher?</td>\n",
       "      <td>SPOONER This one made me laugh: a Spoonerism ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95008</th>\n",
       "      <td>Lively movement in Spooner’s beer glass</td>\n",
       "      <td>a BITTER JUG for the Reverend Spooner</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43570</th>\n",
       "      <td>Spooner’s to tear apart boss – one can see wha...</td>\n",
       "      <td>spoonerism of RIP (tear apart) LEADER (boss)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48547</th>\n",
       "      <td>Device that makes chick peas choose Cheddar, p...</td>\n",
       "      <td>Spoonerism of “pick cheese”</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17141</th>\n",
       "      <td>Spooner’s got rhythm and will rock with Laurel</td>\n",
       "      <td>A spoonerism of Beet (sounding like beat – rh...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291</th>\n",
       "      <td>Spooner’s empty room a problem for cat</td>\n",
       "      <td>Spooner’s BARE HALL (empty room) for aconcret...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28083</th>\n",
       "      <td>Source of protein Spooner’s son spotted</td>\n",
       "      <td>SOYBEAN A Spoonerism of BOY SEEN (‘son spotte...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25896</th>\n",
       "      <td>Salad ingredient or Spooner’s green nightmare?</td>\n",
       "      <td>Spoonerism of ‘nine putts’, which might be a ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18211</th>\n",
       "      <td>According to Spooner, Rooney’s scandal is to p...</td>\n",
       "      <td>GAIN WEIGHT Hurrah! – a Spoonerism that made ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32645</th>\n",
       "      <td>Good feed making Spooner’s horse kick up a fuss</td>\n",
       "      <td>SQUARE MEAL ‘Mare squeal’ – I’m not over-fond...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22510</th>\n",
       "      <td>Spooner’s gin more damaging for baby-minder?</td>\n",
       "      <td>Spoonerism of NET (gin?) WORSE (more damaging...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30073</th>\n",
       "      <td>They cook Spooner’s inquisitive supporters</td>\n",
       "      <td>Spoonerism of prying fans</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43217</th>\n",
       "      <td>They grow on trees in Spooner’s brown flatlands</td>\n",
       "      <td>spoonerism of TAN (brown) PLAINS (flatlands)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90169</th>\n",
       "      <td>Stealthily avoid Spooner’s spot of light breat...</td>\n",
       "      <td>SLIP BY : Spoonerism of “blip”(a spot of ligh...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67017</th>\n",
       "      <td>Spooner urinated toys in legal documents</td>\n",
       "      <td>DEED POLLS A Spoonerism of: PEED (urinated) +...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36963</th>\n",
       "      <td>Adverse reaction caused by Spooner’s need to s...</td>\n",
       "      <td>spoonerism of LACK (need) BASH (strike)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22992</th>\n",
       "      <td>3AInsect in bottle out of water, according to ...</td>\n",
       "      <td>Insect / The Rev Spooner might have said FLAG...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17108</th>\n",
       "      <td>They obey their bosses and fix currency, accor...</td>\n",
       "      <td>YES-MEN – Spoonerism of MESS YEN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38283</th>\n",
       "      <td>Bug in locks of Spooner’s radiation-proof dwel...</td>\n",
       "      <td>HEAD LOUSE A spoonerism for LEAD HOUSE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36067</th>\n",
       "      <td>Spooner’s chief murder weapons</td>\n",
       "      <td>Spoonerism of BOSS CROWS (murder of..)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36197</th>\n",
       "      <td>Particular person, one that lifts depression,...</td>\n",
       "      <td>NITPICKER A Spoonerism of PIT (depression) NI...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>Uncertain if fluids be suitable for pouring</td>\n",
       "      <td>(IF FLUIDS BE)*  17 LIE IN WAIT Be ready to ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32026</th>\n",
       "      <td>Spooner’s communications device in a warren? T...</td>\n",
       "      <td>Spoonerization of “bunny phone”</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43116</th>\n",
       "      <td>Beam over window for Spooner?</td>\n",
       "      <td>A vocalic spoonerism of LINTEL; we wasted a l...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27368 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    clue  \\\n",
       "9139   Undefined number carried by rail, coming in to...   \n",
       "69231   For instance, spread either side of level path?    \n",
       "29228  English literary doctrine favouring the Establ...   \n",
       "71545                       Confusing note with others?    \n",
       "52947  Gloss cast light on standard operating procedu...   \n",
       "13649  ______ is lead free with energy for accelerati...   \n",
       "56775  One ignited in company of friend to fight for ...   \n",
       "4126                           Stick — —- on billboard?    \n",
       "26233         Pair Maced horrifically might require one    \n",
       "2673   Monster turning on a child with ruler? Not the...   \n",
       "74152  18AAs for heading off into country, is it to s...   \n",
       "52164           What’s displaying form of rut with age?    \n",
       "50774                     25AMobile business processor?    \n",
       "70060                       Steps made in a chaotic way    \n",
       "50429               Person snaring new skin of tigress?    \n",
       "21638  6Ddeveloper in another’s pocket becomes such a...   \n",
       "45293                  7DCraved by petrol-head dieters?    \n",
       "92015  Flipping brilliant hiding data sheets in the k...   \n",
       "92683                           Start to sense by smell    \n",
       "93943            Reason for strong medical preparation?    \n",
       "65347  Matter involving educating appalling children,...   \n",
       "63668               Quantity of dirt suddenly swirling?    \n",
       "34144  Are they scattered around, brought in by hunts...   \n",
       "7328        Stars who may become despicable if not paid    \n",
       "1204   35AWhat follows sex to make it attract one’s i...   \n",
       "96800     Deploying this initially, police range in it?    \n",
       "6920                   One with no heart in novel form?    \n",
       "2618    In which Gandhi’s lower half’s also wrapped up?    \n",
       "31905           Insect maturing and going off at first?    \n",
       "23883                She’ll give a mother a bit of help    \n",
       "...                                                  ...   \n",
       "70332       Pub to which Spooner’s working girl retired    \n",
       "41349  For Spooner to attend to small cut is clever p...   \n",
       "11642  Spooner’s horse does this for a bunch of flowers    \n",
       "81558    “Dress will detract from the man” says Spooner    \n",
       "39267        Spooner acclaims Mia’s role in “Zulu Dawn”    \n",
       "71985          Novel storage unit in Spooner’s kitchen?    \n",
       "309                        Self-proclaimed birdwatcher?    \n",
       "95008           Lively movement in Spooner’s beer glass    \n",
       "43570  Spooner’s to tear apart boss – one can see wha...   \n",
       "48547  Device that makes chick peas choose Cheddar, p...   \n",
       "17141    Spooner’s got rhythm and will rock with Laurel    \n",
       "5291             Spooner’s empty room a problem for cat    \n",
       "28083           Source of protein Spooner’s son spotted    \n",
       "25896    Salad ingredient or Spooner’s green nightmare?    \n",
       "18211  According to Spooner, Rooney’s scandal is to p...   \n",
       "32645   Good feed making Spooner’s horse kick up a fuss    \n",
       "22510      Spooner’s gin more damaging for baby-minder?    \n",
       "30073        They cook Spooner’s inquisitive supporters    \n",
       "43217   They grow on trees in Spooner’s brown flatlands    \n",
       "90169  Stealthily avoid Spooner’s spot of light breat...   \n",
       "67017          Spooner urinated toys in legal documents    \n",
       "36963  Adverse reaction caused by Spooner’s need to s...   \n",
       "22992  3AInsect in bottle out of water, according to ...   \n",
       "17108  They obey their bosses and fix currency, accor...   \n",
       "38283  Bug in locks of Spooner’s radiation-proof dwel...   \n",
       "36067                    Spooner’s chief murder weapons    \n",
       "36197   Particular person, one that lifts depression,...   \n",
       "1943        Uncertain if fluids be suitable for pouring    \n",
       "32026  Spooner’s communications device in a warren? T...   \n",
       "43116                     Beam over window for Spooner?    \n",
       "\n",
       "                                                     exp  is_anagram  \\\n",
       "9139    TRAINLOAD (A nice &lit!) N = “Undefined numbe...        True   \n",
       "69231    ASPHALT AS (for instance) + [L (either side ...       False   \n",
       "29228   ELITISM – E (English) LIT (literary) ISM (doc...       False   \n",
       "71545   &lit; NOTE* D E A F (notes in the musical oct...       False   \n",
       "52947                             Reverse of LIT S.O.P.        False   \n",
       "13649  (IS LEAD)* with E(energy) replacing A (acceler...        True   \n",
       "56775   I (one) LIT (ignited) inside (in company of) ...       False   \n",
       "4126    ADHERE AD HERE. Wonderful &lit-ish clue! Down...       False   \n",
       "26233   (Pair Maced)*, &lit. — Ithink it’s the chemic...        True   \n",
       "2673    TE (rev of ET,extraterrestrial) A CH (child) ...       False   \n",
       "74152   &lit / PANAMA (country) around OR (fOR with h...       False   \n",
       "52164   *(RUT AGE). Another & lit clue, where the def...        True   \n",
       "50774   &lit-ish/CD? / A PORTALOO could be described ...       False   \n",
       "70060   STAMPEDES An &lit – an anagram of STEPS MADE ...        True   \n",
       "50429                      N + T[igres]S in HUMAN, &lit        False   \n",
       "21638   &lit-ish/double defn.? / a baby (kanga)roo, t...       False   \n",
       "45293   &lit-ish/CD – or self-introspective double de...       False   \n",
       "92015   TINFOIL LIT = “brilliant” (seems a bit of a s...       False   \n",
       "92683          S (start to Sense) + NIFF (smell); &lit.        False   \n",
       "93943         (STRONG MEDICAL)* AInd: Preparation. &Lit         True   \n",
       "65347   TEACHING THING [matter] round initial letters...        True   \n",
       "63668           Hidden reversed in dirT SUDdenly, &lit.        False   \n",
       "34144   Not sure about “are they scattered around?” u...       False   \n",
       "7328    CELEBS isan anagram (may become) ofDISPICABLE...        True   \n",
       "1204    / &lit-ish – APPEAL = attract one’s interest,...       False   \n",
       "96800   RANGE in D(eploying) T(his); another & lit cl...       False   \n",
       "6920    ANTIHERO – an anagram (in novel form) of I (o...        True   \n",
       "2618    ganDHI (lower half of) includes (wraps) TOO (...       False   \n",
       "31905   IMAGO The first letters of I[nsect] M[aturing...       False   \n",
       "23883   A MA H(elp). Another & lit clue for this Asia...       False   \n",
       "...                                                  ...         ...   \n",
       "70332   BOARS HEAD : Spoonerism of “whore’s bed”(the ...       False   \n",
       "41349   Spoonerization of TREAT NICK (to attend to sm...       False   \n",
       "11642   NOSEGAY Spooner’s horse ‘GOES NEIGH’: unlike ...       False   \n",
       "81558   The Rev.William Archibald Spooner has a lot t...       False   \n",
       "39267   SPARROWFART This was a new word for us – it’s...       False   \n",
       "71985   BOOKCASE – the Spoonerism being ‘cook base’ (...       False   \n",
       "309     SPOONER This one made me laugh: a Spoonerism ...       False   \n",
       "95008             a BITTER JUG for the Reverend Spooner        False   \n",
       "43570      spoonerism of RIP (tear apart) LEADER (boss)        False   \n",
       "48547                       Spoonerism of “pick cheese”        False   \n",
       "17141   A spoonerism of Beet (sounding like beat – rh...       False   \n",
       "5291    Spooner’s BARE HALL (empty room) for aconcret...       False   \n",
       "28083   SOYBEAN A Spoonerism of BOY SEEN (‘son spotte...       False   \n",
       "25896   Spoonerism of ‘nine putts’, which might be a ...       False   \n",
       "18211   GAIN WEIGHT Hurrah! – a Spoonerism that made ...       False   \n",
       "32645   SQUARE MEAL ‘Mare squeal’ – I’m not over-fond...       False   \n",
       "22510   Spoonerism of NET (gin?) WORSE (more damaging...       False   \n",
       "30073                         Spoonerism of prying fans        False   \n",
       "43217      spoonerism of TAN (brown) PLAINS (flatlands)        False   \n",
       "90169   SLIP BY : Spoonerism of “blip”(a spot of ligh...       False   \n",
       "67017   DEED POLLS A Spoonerism of: PEED (urinated) +...       False   \n",
       "36963           spoonerism of LACK (need) BASH (strike)        False   \n",
       "22992   Insect / The Rev Spooner might have said FLAG...       False   \n",
       "17108                  YES-MEN – Spoonerism of MESS YEN        False   \n",
       "38283            HEAD LOUSE A spoonerism for LEAD HOUSE        False   \n",
       "36067            Spoonerism of BOSS CROWS (murder of..)        False   \n",
       "36197   NITPICKER A Spoonerism of PIT (depression) NI...       False   \n",
       "1943     (IF FLUIDS BE)*  17 LIE IN WAIT Be ready to ...        True   \n",
       "32026                   Spoonerization of “bunny phone”        False   \n",
       "43116   A vocalic spoonerism of LINTEL; we wasted a l...       False   \n",
       "\n",
       "       is_homophone  is_double  is_cryptic  is_contain  is_reverse  \\\n",
       "9139          False      False       False        True       False   \n",
       "69231         False      False       False       False       False   \n",
       "29228         False      False       False       False       False   \n",
       "71545         False      False       False        True       False   \n",
       "52947         False      False       False       False        True   \n",
       "13649         False      False       False       False       False   \n",
       "56775         False      False       False        True       False   \n",
       "4126          False      False       False       False       False   \n",
       "26233         False      False       False       False       False   \n",
       "2673          False      False       False       False       False   \n",
       "74152         False      False       False        True       False   \n",
       "52164         False      False       False       False       False   \n",
       "50774         False      False       False       False       False   \n",
       "70060         False      False       False       False       False   \n",
       "50429         False      False       False        True       False   \n",
       "21638         False       True       False        True       False   \n",
       "45293         False       True       False       False       False   \n",
       "92015         False      False       False        True        True   \n",
       "92683         False      False       False       False       False   \n",
       "93943         False      False       False       False       False   \n",
       "65347         False       True       False        True       False   \n",
       "63668         False      False       False        True        True   \n",
       "34144         False      False       False        True       False   \n",
       "7328          False      False       False       False       False   \n",
       "1204          False      False       False       False       False   \n",
       "96800         False      False       False        True       False   \n",
       "6920          False      False       False       False       False   \n",
       "2618          False      False       False       False        True   \n",
       "31905         False      False       False       False       False   \n",
       "23883         False      False       False       False       False   \n",
       "...             ...        ...         ...         ...         ...   \n",
       "70332         False      False       False        True       False   \n",
       "41349         False      False       False       False       False   \n",
       "11642         False      False       False       False       False   \n",
       "81558         False      False       False       False       False   \n",
       "39267         False      False       False        True       False   \n",
       "71985         False      False       False       False       False   \n",
       "309           False      False       False       False       False   \n",
       "95008         False      False       False       False       False   \n",
       "43570         False      False       False       False       False   \n",
       "48547         False      False       False       False       False   \n",
       "17141          True      False       False        True       False   \n",
       "5291          False      False       False        True       False   \n",
       "28083         False      False       False       False       False   \n",
       "25896         False      False       False       False       False   \n",
       "18211         False      False       False       False       False   \n",
       "32645         False      False       False       False       False   \n",
       "22510         False      False       False       False       False   \n",
       "30073         False      False       False       False       False   \n",
       "43217         False      False       False       False       False   \n",
       "90169         False      False       False       False       False   \n",
       "67017         False      False       False       False       False   \n",
       "36963         False      False       False       False       False   \n",
       "22992         False      False       False       False       False   \n",
       "17108         False      False       False       False       False   \n",
       "38283         False      False       False       False       False   \n",
       "36067         False      False       False       False       False   \n",
       "36197         False      False       False       False       False   \n",
       "1943          False      False       False        True       False   \n",
       "32026         False      False       False       False       False   \n",
       "43116         False      False       False       False       False   \n",
       "\n",
       "       is_alternate  is_init  is_delete  is_charade  is_&lit  is_hidden  \\\n",
       "9139          False    False       True       False     True      False   \n",
       "69231         False    False      False        True     True      False   \n",
       "29228         False    False      False       False     True      False   \n",
       "71545         False    False      False       False     True      False   \n",
       "52947         False    False      False       False     True      False   \n",
       "13649         False     True      False       False     True      False   \n",
       "56775         False    False      False       False     True      False   \n",
       "4126          False    False      False       False     True      False   \n",
       "26233         False    False      False       False     True      False   \n",
       "2673          False    False      False       False     True      False   \n",
       "74152         False    False      False       False     True      False   \n",
       "52164         False    False      False       False     True      False   \n",
       "50774         False    False      False       False     True      False   \n",
       "70060         False    False      False       False     True      False   \n",
       "50429         False    False       True        True     True      False   \n",
       "21638         False    False      False       False     True      False   \n",
       "45293         False    False      False       False     True      False   \n",
       "92015         False    False      False       False     True      False   \n",
       "92683         False    False      False        True     True      False   \n",
       "93943         False    False      False       False     True      False   \n",
       "65347         False     True       True       False     True      False   \n",
       "63668         False    False      False       False     True       True   \n",
       "34144         False    False      False       False     True      False   \n",
       "7328          False    False       True       False     True      False   \n",
       "1204          False    False      False       False     True      False   \n",
       "96800         False     True      False       False     True      False   \n",
       "6920          False    False      False       False     True      False   \n",
       "2618          False    False      False       False     True      False   \n",
       "31905         False     True       True       False     True      False   \n",
       "23883         False     True      False       False     True      False   \n",
       "...             ...      ...        ...         ...      ...        ...   \n",
       "70332         False    False      False       False    False      False   \n",
       "41349         False    False      False       False    False      False   \n",
       "11642         False    False      False       False    False      False   \n",
       "81558         False    False      False       False    False      False   \n",
       "39267         False    False      False       False    False      False   \n",
       "71985         False    False      False       False    False      False   \n",
       "309           False    False      False       False    False      False   \n",
       "95008         False    False      False       False    False      False   \n",
       "43570         False    False      False       False    False      False   \n",
       "48547         False    False      False       False    False      False   \n",
       "17141         False    False      False       False    False      False   \n",
       "5291          False    False      False       False    False      False   \n",
       "28083         False    False      False       False    False      False   \n",
       "25896         False    False      False       False    False      False   \n",
       "18211         False    False      False       False    False      False   \n",
       "32645         False    False      False       False    False      False   \n",
       "22510         False    False      False       False    False      False   \n",
       "30073         False    False      False       False    False      False   \n",
       "43217         False    False      False       False    False      False   \n",
       "90169         False    False      False        True    False      False   \n",
       "67017         False    False      False        True    False      False   \n",
       "36963         False    False      False       False    False      False   \n",
       "22992         False    False      False       False    False      False   \n",
       "17108         False    False      False       False    False      False   \n",
       "38283         False    False      False       False    False      False   \n",
       "36067         False    False      False       False    False      False   \n",
       "36197         False    False      False       False    False      False   \n",
       "1943          False    False      False       False    False      False   \n",
       "32026         False    False      False       False    False      False   \n",
       "43116         False    False      False       False    False      False   \n",
       "\n",
       "       is_spoonerism  is_palindrome  \n",
       "9139           False          False  \n",
       "69231          False          False  \n",
       "29228          False          False  \n",
       "71545          False          False  \n",
       "52947          False          False  \n",
       "13649          False          False  \n",
       "56775          False          False  \n",
       "4126           False          False  \n",
       "26233          False          False  \n",
       "2673           False          False  \n",
       "74152          False          False  \n",
       "52164          False          False  \n",
       "50774          False          False  \n",
       "70060          False          False  \n",
       "50429          False          False  \n",
       "21638          False          False  \n",
       "45293          False          False  \n",
       "92015          False          False  \n",
       "92683          False          False  \n",
       "93943          False          False  \n",
       "65347          False          False  \n",
       "63668          False          False  \n",
       "34144          False          False  \n",
       "7328           False          False  \n",
       "1204           False          False  \n",
       "96800          False          False  \n",
       "6920           False          False  \n",
       "2618           False          False  \n",
       "31905          False          False  \n",
       "23883          False          False  \n",
       "...              ...            ...  \n",
       "70332           True          False  \n",
       "41349           True          False  \n",
       "11642           True          False  \n",
       "81558           True          False  \n",
       "39267           True          False  \n",
       "71985           True          False  \n",
       "309             True          False  \n",
       "95008           True          False  \n",
       "43570           True          False  \n",
       "48547           True          False  \n",
       "17141           True          False  \n",
       "5291            True          False  \n",
       "28083           True          False  \n",
       "25896           True          False  \n",
       "18211           True          False  \n",
       "32645           True          False  \n",
       "22510           True          False  \n",
       "30073           True          False  \n",
       "43217           True          False  \n",
       "90169           True          False  \n",
       "67017           True          False  \n",
       "36963           True          False  \n",
       "22992           True          False  \n",
       "17108           True          False  \n",
       "38283           True          False  \n",
       "36067           True          False  \n",
       "36197           True          False  \n",
       "1943            True          False  \n",
       "32026           True          False  \n",
       "43116           True          False  \n",
       "\n",
       "[27368 rows x 16 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc_test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_input_data_out = cc_input_df[cc_input_df.columns[2:]] * 1\n",
    "cc_val_data_out = cc_val_df[cc_val_df.columns[2:]] * 1\n",
    "cc_test_data_out = cc_test_df[cc_test_df.columns[2:]] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300))\n",
    "model.add(Dense(14, activation='relu', input_dim=15))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358484 samples, validate on 49180 samples\n",
      "Epoch 1/6\n",
      "358484/358484 [==============================] - 6s 16us/step - loss: 3.3946 - categorical_accuracy: 0.0455 - val_loss: 2.6466 - val_categorical_accuracy: 0.0478\n",
      "Epoch 2/6\n",
      "358484/358484 [==============================] - 4s 12us/step - loss: 2.4441 - categorical_accuracy: 0.1367 - val_loss: 2.3147 - val_categorical_accuracy: 0.2202\n",
      "Epoch 3/6\n",
      "358484/358484 [==============================] - 4s 12us/step - loss: 2.2802 - categorical_accuracy: 0.1833 - val_loss: 2.3002 - val_categorical_accuracy: 0.2362\n",
      "Epoch 4/6\n",
      "358484/358484 [==============================] - 4s 12us/step - loss: 2.2584 - categorical_accuracy: 0.1734 - val_loss: 2.2246 - val_categorical_accuracy: 0.1864\n",
      "Epoch 5/6\n",
      "358484/358484 [==============================] - 4s 12us/step - loss: 1.7173 - categorical_accuracy: 0.1494 - val_loss: 0.5385 - val_categorical_accuracy: 0.2949\n",
      "Epoch 6/6\n",
      "358484/358484 [==============================] - 4s 12us/step - loss: 0.4070 - categorical_accuracy: 0.2597 - val_loss: 0.3639 - val_categorical_accuracy: 0.3100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30302/30302 [==============================] - 0s 16us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3701306075559938, 0.2917629199441955]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300,input_length=15))\n",
    "model.add(Dense(300, activation='relu', input_dim=15))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 711924 samples, validate on 42542 samples\n",
      "Epoch 1/4\n",
      "711924/711924 [==============================] - 11s 16us/step - loss: 2.7505 - categorical_accuracy: 0.3063 - val_loss: 2.6746 - val_categorical_accuracy: 0.2312\n",
      "Epoch 2/4\n",
      "711924/711924 [==============================] - 10s 15us/step - loss: 2.7355 - categorical_accuracy: 0.3131 - val_loss: 2.6953 - val_categorical_accuracy: 0.2227\n",
      "Epoch 3/4\n",
      "711924/711924 [==============================] - 10s 15us/step - loss: 2.7349 - categorical_accuracy: 0.3134 - val_loss: 2.6953 - val_categorical_accuracy: 0.2227\n",
      "Epoch 4/4\n",
      "711924/711924 [==============================] - 10s 15us/step - loss: 2.7349 - categorical_accuracy: 0.3134 - val_loss: 2.6953 - val_categorical_accuracy: 0.2227\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16968/16968 [==============================] - 0s 17us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.777652508467225, 0.31347241867043846]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300,input_length=15))\n",
    "model.add(Dense(300, activation='sigmoid', input_dim=15))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 12s 26us/step - loss: 0.3623 - categorical_accuracy: 0.2733 - val_loss: 0.3074 - val_categorical_accuracy: 0.2127\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 12s 25us/step - loss: 0.3528 - categorical_accuracy: 0.2822 - val_loss: 0.3024 - val_categorical_accuracy: 0.3311\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 12s 25us/step - loss: 0.3464 - categorical_accuracy: 0.2847 - val_loss: 0.3041 - val_categorical_accuracy: 0.3002\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 12s 25us/step - loss: 0.3408 - categorical_accuracy: 0.2881 - val_loss: 0.3029 - val_categorical_accuracy: 0.2917\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300,input_length=15))\n",
    "model.add(Dense(300, activation='sigmoid', input_dim=15))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 17s 35us/step - loss: 0.3612 - categorical_accuracy: 0.2776 - val_loss: 0.3047 - val_categorical_accuracy: 0.3257\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 16s 33us/step - loss: 0.3472 - categorical_accuracy: 0.2888 - val_loss: 0.3023 - val_categorical_accuracy: 0.2896\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 16s 33us/step - loss: 0.3392 - categorical_accuracy: 0.2916 - val_loss: 0.3045 - val_categorical_accuracy: 0.3026\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 16s 33us/step - loss: 0.3315 - categorical_accuracy: 0.2933 - val_loss: 0.3047 - val_categorical_accuracy: 0.3212\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 9s 18us/step - loss: 0.3121 - categorical_accuracy: 0.3606 - val_loss: 0.2770 - val_categorical_accuracy: 0.3414\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 8s 16us/step - loss: 0.1623 - categorical_accuracy: 0.5833 - val_loss: 0.3133 - val_categorical_accuracy: 0.3344\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 8s 16us/step - loss: 0.1039 - categorical_accuracy: 0.6364 - val_loss: 0.3685 - val_categorical_accuracy: 0.3245\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 8s 16us/step - loss: 0.0760 - categorical_accuracy: 0.6496 - val_loss: 0.4256 - val_categorical_accuracy: 0.3246\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(Conv1D(filters=15,kernel_size=2))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 13s 28us/step - loss: 0.3132 - categorical_accuracy: 0.3622 - val_loss: 0.2806 - val_categorical_accuracy: 0.3209\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 12s 25us/step - loss: 0.1933 - categorical_accuracy: 0.4961 - val_loss: 0.3093 - val_categorical_accuracy: 0.3052\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 12s 24us/step - loss: 0.1522 - categorical_accuracy: 0.5294 - val_loss: 0.3411 - val_categorical_accuracy: 0.3040\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 12s 24us/step - loss: 0.1292 - categorical_accuracy: 0.5360 - val_loss: 0.3725 - val_categorical_accuracy: 0.2919\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=15))\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/10\n",
      "480706/480706 [==============================] - 22s 45us/step - loss: 0.3965 - categorical_accuracy: 0.2432 - val_loss: 0.3013 - val_categorical_accuracy: 0.3406\n",
      "Epoch 2/10\n",
      "480706/480706 [==============================] - 20s 41us/step - loss: 0.3287 - categorical_accuracy: 0.3195 - val_loss: 0.2875 - val_categorical_accuracy: 0.3196\n",
      "Epoch 3/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.2611 - categorical_accuracy: 0.4215 - val_loss: 0.2971 - val_categorical_accuracy: 0.3073\n",
      "Epoch 4/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.2048 - categorical_accuracy: 0.5103 - val_loss: 0.3144 - val_categorical_accuracy: 0.3185\n",
      "Epoch 5/10\n",
      "480706/480706 [==============================] - 20s 41us/step - loss: 0.1678 - categorical_accuracy: 0.5882 - val_loss: 0.3387 - val_categorical_accuracy: 0.3311\n",
      "Epoch 6/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.1401 - categorical_accuracy: 0.6242 - val_loss: 0.3645 - val_categorical_accuracy: 0.3281\n",
      "Epoch 7/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.1198 - categorical_accuracy: 0.6423 - val_loss: 0.3948 - val_categorical_accuracy: 0.3228\n",
      "Epoch 8/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.1046 - categorical_accuracy: 0.6477 - val_loss: 0.4164 - val_categorical_accuracy: 0.3355\n",
      "Epoch 9/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.0925 - categorical_accuracy: 0.6491 - val_loss: 0.4457 - val_categorical_accuracy: 0.3339\n",
      "Epoch 10/10\n",
      "480706/480706 [==============================] - 21s 43us/step - loss: 0.0828 - categorical_accuracy: 0.6541 - val_loss: 0.4727 - val_categorical_accuracy: 0.3281\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=15,dropout=0.5))\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/10\n",
      "480706/480706 [==============================] - 24s 51us/step - loss: 0.3896 - categorical_accuracy: 0.2492 - val_loss: 0.2951 - val_categorical_accuracy: 0.2055\n",
      "Epoch 2/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.3106 - categorical_accuracy: 0.2419 - val_loss: 0.2923 - val_categorical_accuracy: 0.2200\n",
      "Epoch 3/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2638 - categorical_accuracy: 0.3352 - val_loss: 0.2947 - val_categorical_accuracy: 0.2900\n",
      "Epoch 4/10\n",
      "480706/480706 [==============================] - 22s 45us/step - loss: 0.2280 - categorical_accuracy: 0.4346 - val_loss: 0.2994 - val_categorical_accuracy: 0.2927\n",
      "Epoch 5/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1998 - categorical_accuracy: 0.4691 - val_loss: 0.3095 - val_categorical_accuracy: 0.2929\n",
      "Epoch 6/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1833 - categorical_accuracy: 0.4925 - val_loss: 0.3201 - val_categorical_accuracy: 0.2955\n",
      "Epoch 7/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1719 - categorical_accuracy: 0.5095 - val_loss: 0.3377 - val_categorical_accuracy: 0.2941\n",
      "Epoch 8/10\n",
      "480706/480706 [==============================] - 23s 47us/step - loss: 0.1629 - categorical_accuracy: 0.5205 - val_loss: 0.3440 - val_categorical_accuracy: 0.3012\n",
      "Epoch 9/10\n",
      "480706/480706 [==============================] - 22s 47us/step - loss: 0.1558 - categorical_accuracy: 0.5286 - val_loss: 0.3580 - val_categorical_accuracy: 0.2966\n",
      "Epoch 10/10\n",
      "480706/480706 [==============================] - 23s 47us/step - loss: 0.1498 - categorical_accuracy: 0.5339 - val_loss: 0.3669 - val_categorical_accuracy: 0.2963\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=15,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/10\n",
      "480706/480706 [==============================] - 24s 50us/step - loss: 0.3729 - categorical_accuracy: 0.2750 - val_loss: 0.2868 - val_categorical_accuracy: 0.3534\n",
      "Epoch 2/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2979 - categorical_accuracy: 0.3678 - val_loss: 0.2798 - val_categorical_accuracy: 0.3122\n",
      "Epoch 3/10\n",
      "480706/480706 [==============================] - 22s 45us/step - loss: 0.2621 - categorical_accuracy: 0.3925 - val_loss: 0.2765 - val_categorical_accuracy: 0.2912\n",
      "Epoch 4/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2378 - categorical_accuracy: 0.3910 - val_loss: 0.2806 - val_categorical_accuracy: 0.2862\n",
      "Epoch 5/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2195 - categorical_accuracy: 0.3993 - val_loss: 0.2868 - val_categorical_accuracy: 0.2821\n",
      "Epoch 6/10\n",
      "480706/480706 [==============================] - 21s 45us/step - loss: 0.2054 - categorical_accuracy: 0.4168 - val_loss: 0.2885 - val_categorical_accuracy: 0.2942\n",
      "Epoch 7/10\n",
      "480706/480706 [==============================] - 21s 45us/step - loss: 0.1938 - categorical_accuracy: 0.4396 - val_loss: 0.2931 - val_categorical_accuracy: 0.2959\n",
      "Epoch 8/10\n",
      "480706/480706 [==============================] - 21s 45us/step - loss: 0.1837 - categorical_accuracy: 0.4620 - val_loss: 0.2958 - val_categorical_accuracy: 0.3023\n",
      "Epoch 9/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1755 - categorical_accuracy: 0.4806 - val_loss: 0.3047 - val_categorical_accuracy: 0.3062\n",
      "Epoch 10/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1686 - categorical_accuracy: 0.4963 - val_loss: 0.3069 - val_categorical_accuracy: 0.3098\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 63s 130us/step - loss: 0.3368 - categorical_accuracy: 0.3093 - val_loss: 0.2784 - val_categorical_accuracy: 0.3377\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 60s 125us/step - loss: 0.2544 - categorical_accuracy: 0.3886 - val_loss: 0.2754 - val_categorical_accuracy: 0.3392\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 59s 124us/step - loss: 0.2061 - categorical_accuracy: 0.4286 - val_loss: 0.2780 - val_categorical_accuracy: 0.3276\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 61s 127us/step - loss: 0.1781 - categorical_accuracy: 0.4674 - val_loss: 0.2845 - val_categorical_accuracy: 0.3838\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 131s 273us/step - loss: 0.2407 - categorical_accuracy: 0.4084 - val_loss: 0.2657 - val_categorical_accuracy: 0.3660\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 134s 278us/step - loss: 0.1200 - categorical_accuracy: 0.5198 - val_loss: 0.3120 - val_categorical_accuracy: 0.3779\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 129s 269us/step - loss: 0.0849 - categorical_accuracy: 0.5433 - val_loss: 0.3533 - val_categorical_accuracy: 0.3933\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 123s 256us/step - loss: 0.0670 - categorical_accuracy: 0.5531 - val_loss: 0.3648 - val_categorical_accuracy: 0.3614\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 144s 299us/step - loss: 0.2603 - categorical_accuracy: 0.3927 - val_loss: 0.2619 - val_categorical_accuracy: 0.3735\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 144s 300us/step - loss: 0.1281 - categorical_accuracy: 0.5149 - val_loss: 0.2991 - val_categorical_accuracy: 0.3854\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 141s 293us/step - loss: 0.0891 - categorical_accuracy: 0.5421 - val_loss: 0.3305 - val_categorical_accuracy: 0.3654\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 142s 294us/step - loss: 0.0699 - categorical_accuracy: 0.5525 - val_loss: 0.3636 - val_categorical_accuracy: 0.3623\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[top_3_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 155s 323us/step - loss: 0.2645 - top_3_accuracy: 0.6709 - val_loss: 0.2829 - val_top_3_accuracy: 0.6989\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 151s 315us/step - loss: 0.0995 - top_3_accuracy: 0.9275 - val_loss: 0.3524 - val_top_3_accuracy: 0.7083\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 156s 324us/step - loss: 0.0604 - top_3_accuracy: 0.9550 - val_loss: 0.4098 - val_top_3_accuracy: 0.6998\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 151s 314us/step - loss: 0.0439 - top_3_accuracy: 0.9633 - val_loss: 0.4590 - val_top_3_accuracy: 0.7104\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 144s 300us/step - loss: 0.2591 - top_3_accuracy: 0.6832 - val_loss: 0.2614 - val_top_3_accuracy: 0.7131\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 140s 292us/step - loss: 0.1269 - top_3_accuracy: 0.8907 - val_loss: 0.3014 - val_top_3_accuracy: 0.7368\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 139s 290us/step - loss: 0.0876 - top_3_accuracy: 0.9269 - val_loss: 0.3333 - val_top_3_accuracy: 0.7359\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 140s 292us/step - loss: 0.0685 - top_3_accuracy: 0.9408 - val_loss: 0.3611 - val_top_3_accuracy: 0.7363\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8475/8475 [==============================] - 2s 203us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3741736157664859, 0.7189380530903121]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cc_test_data,cc_test_data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy,'accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 135s 280us/step - loss: 0.2571 - top_3_accuracy: 0.6866 - acc: 0.8944 - categorical_accuracy: 0.3799 - val_loss: 0.2664 - val_top_3_accuracy: 0.7184 - val_acc: 0.8875 - val_categorical_accuracy: 0.3795\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 135s 280us/step - loss: 0.1281 - top_3_accuracy: 0.8894 - acc: 0.9481 - categorical_accuracy: 0.5082 - val_loss: 0.2937 - val_top_3_accuracy: 0.7343 - val_acc: 0.8843 - val_categorical_accuracy: 0.3934\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 131s 272us/step - loss: 0.0888 - top_3_accuracy: 0.9259 - acc: 0.9658 - categorical_accuracy: 0.5418 - val_loss: 0.3326 - val_top_3_accuracy: 0.7342 - val_acc: 0.8792 - val_categorical_accuracy: 0.3857\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 130s 271us/step - loss: 0.0696 - top_3_accuracy: 0.9397 - acc: 0.9741 - categorical_accuracy: 0.5522 - val_loss: 0.3629 - val_top_3_accuracy: 0.7288 - val_acc: 0.8783 - val_categorical_accuracy: 0.3844\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5)))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy,'accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"2xBilstm-{epoch:02d}-{val_loss:.2f}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358484 samples, validate on 49290 samples\n",
      "Epoch 1/4\n",
      "358484/358484 [==============================] - 96s 268us/step - loss: 0.1395 - top_3_accuracy: 0.8842 - acc: 0.9412 - categorical_accuracy: 0.5579 - val_loss: 0.1762 - val_top_3_accuracy: 0.8603 - val_acc: 0.9229 - val_categorical_accuracy: 0.5487\n",
      "\n",
      "Epoch 00001: saving model to 2xBilstm-01-0.18-0.55.hdf5\n",
      "Epoch 2/4\n",
      "358484/358484 [==============================] - 96s 268us/step - loss: 0.1228 - top_3_accuracy: 0.9015 - acc: 0.9493 - categorical_accuracy: 0.5747 - val_loss: 0.1603 - val_top_3_accuracy: 0.8911 - val_acc: 0.9318 - val_categorical_accuracy: 0.5681\n",
      "\n",
      "Epoch 00002: saving model to 2xBilstm-02-0.16-0.57.hdf5\n",
      "Epoch 3/4\n",
      "358484/358484 [==============================] - 96s 268us/step - loss: 0.1092 - top_3_accuracy: 0.9138 - acc: 0.9556 - categorical_accuracy: 0.5832 - val_loss: 0.1500 - val_top_3_accuracy: 0.8924 - val_acc: 0.9373 - val_categorical_accuracy: 0.5851\n",
      "\n",
      "Epoch 00003: saving model to 2xBilstm-03-0.15-0.59.hdf5\n",
      "Epoch 4/4\n",
      "358484/358484 [==============================] - 97s 270us/step - loss: 0.0982 - top_3_accuracy: 0.9230 - acc: 0.9607 - categorical_accuracy: 0.5861 - val_loss: 0.1362 - val_top_3_accuracy: 0.8644 - val_acc: 0.9440 - val_categorical_accuracy: 0.4795\n",
      "\n",
      "Epoch 00004: saving model to 2xBilstm-04-0.14-0.48.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=1024, epochs=4,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30237/30237 [==============================] - 35s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18163946719529575,\n",
       " 0.8345404636703376,\n",
       " 0.9197624472866543,\n",
       " 0.5073585342579497]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('50%_categorical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./2xBilstm-03-0.15-0.59.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27368/27368 [==============================] - 31s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14074560044130624,\n",
       " 0.8990061385559778,\n",
       " 0.9414096788787173,\n",
       " 0.6011400175387314]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(cc_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = cc_val_data_out - pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.absolute(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "error.to_csv('bilstm_error.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "!explorer ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2969.5"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc_val_df)/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5089.301023368861,\n",
       " 762.4743669615234,\n",
       " 2454.0194316451343,\n",
       " 1656.4140921296591,\n",
       " 10343.44581935413,\n",
       " 2204.0897995197242,\n",
       " 499.975531778603,\n",
       " 4319.007700273058,\n",
       " 9885.208288726579,\n",
       " 11999.036386445297,\n",
       " 406.4953425794674,\n",
       " 1292.0463068031086,\n",
       " 15.940705289792575,\n",
       " 26.371238619690075]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[error[cat].sum() for cat in cc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_anagram 0.5518053803934577\n",
      "is_homophone 0.30609167682116556\n",
      "is_double 0.6011806544941535\n",
      "is_cryptic 0.6089757691653158\n",
      "is_contain 0.5840784809618912\n",
      "is_reverse 0.3757398226252513\n",
      "is_alternate 0.6820948591795403\n",
      "is_init 0.7701511591071786\n",
      "is_delete 0.8669714338472706\n",
      "is_charade 0.8708205520317365\n",
      "is_&lit 0.47654788110136853\n",
      "is_hidden 0.4530316643769665\n",
      "is_spoonerism 0.09839941536908997\n",
      "is_palindrome 0.3995642215104557\n"
     ]
    }
   ],
   "source": [
    "error_col_sums = [error[cat].sum() for cat in cc_types]\n",
    "length_per_cat = [len(cc_val_df[cc_val_df[cat]==True]) for cat in cc_types]\n",
    "for cat,err,leng in zip(cc_types,error_col_sums,length_per_cat):\n",
    "    print(cat,err/leng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9223,\n",
       " 2491,\n",
       " 4082,\n",
       " 2720,\n",
       " 17709,\n",
       " 5866,\n",
       " 733,\n",
       " 5608,\n",
       " 11402,\n",
       " 13779,\n",
       " 853,\n",
       " 2852,\n",
       " 162,\n",
       " 66]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(cc_val_df[cc_val_df[cat]==True]) for cat in cc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['is_anagram', 'is_homophone', 'is_double', 'is_cryptic', 'is_contain',\n",
       "       'is_reverse', 'is_alternate', 'is_init', 'is_delete', 'is_charade',\n",
       "       'is_&lit', 'is_hidden', 'is_spoonerism', 'is_palindrome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_anagram',\n",
       " 'is_homophone',\n",
       " 'is_double',\n",
       " 'is_cryptic',\n",
       " 'is_contain',\n",
       " 'is_reverse',\n",
       " 'is_alternate',\n",
       " 'is_init',\n",
       " 'is_delete',\n",
       " 'is_charade',\n",
       " 'is_&lit',\n",
       " 'is_hidden',\n",
       " 'is_spoonerism',\n",
       " 'is_palindrome']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
