{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import keras\n",
    "from keras.layers import Dense,Embedding, Flatten, Conv1D, GlobalMaxPooling1D, LSTM, Bidirectional\n",
    "from keras.preprocessing.text import text_to_word_sequence,Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./cryptic_dataset/combined_fifteen_times_final.pickle\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_types = \"is_anagram\tis_homophone\tis_double\tis_cryptic\tis_contain\tis_reverse\tis_alternate\tis_init\tis_delete\tis_charade\tis_&lit\tis_hidden\tis_spoonerism\tis_palindrome\".split('\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.clue = df.clue.apply(text_to_word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_types_dfs = [df[df[cc_type]==True] for cc_type in cc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for cc_type,cc_type_df in zip(cc_types,cc_types_dfs):\n",
    "    cc_type_df['category'] = cc_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.concat(cc_types_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = concatenated_df.groupby('category').count().max()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [concatenated_df]\n",
    "for class_index, group in concatenated_df.groupby('category'):\n",
    "    sample = group.sample(max_size-len(group), replace=True, )\n",
    "    lst.append(sample)\n",
    "upsampled_df = pd.concat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clue</th>\n",
       "      <th>exp</th>\n",
       "      <th>is_anagram</th>\n",
       "      <th>is_homophone</th>\n",
       "      <th>is_double</th>\n",
       "      <th>is_cryptic</th>\n",
       "      <th>is_contain</th>\n",
       "      <th>is_reverse</th>\n",
       "      <th>is_alternate</th>\n",
       "      <th>is_init</th>\n",
       "      <th>is_delete</th>\n",
       "      <th>is_charade</th>\n",
       "      <th>is_&amp;lit</th>\n",
       "      <th>is_hidden</th>\n",
       "      <th>is_spoonerism</th>\n",
       "      <th>is_palindrome</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_&amp;lit</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_alternate</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_anagram</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_charade</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_contain</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_cryptic</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_delete</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_double</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_hidden</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_homophone</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_init</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_palindrome</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_reverse</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_spoonerism</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                clue    exp  is_anagram  is_homophone  is_double  is_cryptic  \\\n",
       "category                                                                       \n",
       "is_&lit        36581  36581       36581         36581      36581       36581   \n",
       "is_alternate   36581  36581       36581         36581      36581       36581   \n",
       "is_anagram     36581  36581       36581         36581      36581       36581   \n",
       "is_charade     36581  36581       36581         36581      36581       36581   \n",
       "is_contain     36581  36581       36581         36581      36581       36581   \n",
       "is_cryptic     36581  36581       36581         36581      36581       36581   \n",
       "is_delete      36581  36581       36581         36581      36581       36581   \n",
       "is_double      36581  36581       36581         36581      36581       36581   \n",
       "is_hidden      36581  36581       36581         36581      36581       36581   \n",
       "is_homophone   36581  36581       36581         36581      36581       36581   \n",
       "is_init        36581  36581       36581         36581      36581       36581   \n",
       "is_palindrome  36581  36581       36581         36581      36581       36581   \n",
       "is_reverse     36581  36581       36581         36581      36581       36581   \n",
       "is_spoonerism  36581  36581       36581         36581      36581       36581   \n",
       "\n",
       "               is_contain  is_reverse  is_alternate  is_init  is_delete  \\\n",
       "category                                                                  \n",
       "is_&lit             36581       36581         36581    36581      36581   \n",
       "is_alternate        36581       36581         36581    36581      36581   \n",
       "is_anagram          36581       36581         36581    36581      36581   \n",
       "is_charade          36581       36581         36581    36581      36581   \n",
       "is_contain          36581       36581         36581    36581      36581   \n",
       "is_cryptic          36581       36581         36581    36581      36581   \n",
       "is_delete           36581       36581         36581    36581      36581   \n",
       "is_double           36581       36581         36581    36581      36581   \n",
       "is_hidden           36581       36581         36581    36581      36581   \n",
       "is_homophone        36581       36581         36581    36581      36581   \n",
       "is_init             36581       36581         36581    36581      36581   \n",
       "is_palindrome       36581       36581         36581    36581      36581   \n",
       "is_reverse          36581       36581         36581    36581      36581   \n",
       "is_spoonerism       36581       36581         36581    36581      36581   \n",
       "\n",
       "               is_charade  is_&lit  is_hidden  is_spoonerism  is_palindrome  \n",
       "category                                                                     \n",
       "is_&lit             36581    36581      36581          36581          36581  \n",
       "is_alternate        36581    36581      36581          36581          36581  \n",
       "is_anagram          36581    36581      36581          36581          36581  \n",
       "is_charade          36581    36581      36581          36581          36581  \n",
       "is_contain          36581    36581      36581          36581          36581  \n",
       "is_cryptic          36581    36581      36581          36581          36581  \n",
       "is_delete           36581    36581      36581          36581          36581  \n",
       "is_double           36581    36581      36581          36581          36581  \n",
       "is_hidden           36581    36581      36581          36581          36581  \n",
       "is_homophone        36581    36581      36581          36581          36581  \n",
       "is_init             36581    36581      36581          36581          36581  \n",
       "is_palindrome       36581    36581      36581          36581          36581  \n",
       "is_reverse          36581    36581      36581          36581          36581  \n",
       "is_spoonerism       36581    36581      36581          36581          36581  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled_df.groupby('category').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaled_cc_dfs = [x[1] for x in upsampled_df.groupby('category')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_val_test(df):\n",
    "    length = len(df)\n",
    "    input_len = math.floor(length*0.7)\n",
    "    val_len  = math.floor(length*0.2)\n",
    "    test_len = math.floor(length*0.1)\n",
    "    input_df = df[:input_len]\n",
    "    val_df = df[input_len:input_len+val_len]\n",
    "    test_df = df[input_len+val_len:]\n",
    "    return input_df,val_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_cc_types_dfs = [x[1] for x in upsampled_df.groupby('category')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dfs = []\n",
    "val_dfs = []\n",
    "test_dfs = []\n",
    "for cc_type_df in upsampled_cc_types_dfs:\n",
    "    input_df,val_df,test_df = get_input_val_test(cc_type_df)\n",
    "    input_dfs.append(input_df)\n",
    "    val_dfs.append(val_df)\n",
    "    test_dfs.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_input_df = pd.concat(input_dfs).drop('category',axis=1)\n",
    "cc_val_df = pd.concat(val_dfs).drop('category',axis=1).drop_duplicates()\n",
    "cc_test_df = pd.concat(test_dfs).drop('category',axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df.clue.tolist())\n",
    "cc_input_data = pad_sequences(tokenizer.texts_to_sequences(cc_input_df.clue.tolist()),maxlen=15)\n",
    "cc_val_data = pad_sequences(tokenizer.texts_to_sequences(cc_val_df.clue.tolist()),maxlen=15)\n",
    "cc_test_data = pad_sequences(tokenizer.texts_to_sequences(cc_test_df.clue.tolist()),maxlen=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_input_data_out = cc_input_df[cc_input_df.columns[2:]] * 1\n",
    "cc_val_data_out = cc_val_df[cc_val_df.columns[2:]] * 1\n",
    "cc_test_data_out = cc_test_df[cc_test_df.columns[2:]] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300))\n",
    "model.add(Dense(14, activation='relu', input_dim=15))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358484 samples, validate on 41573 samples\n",
      "Epoch 1/6\n",
      "358484/358484 [==============================] - 10s 27us/step - loss: 2.9708 - categorical_accuracy: 0.1521 - val_loss: 2.1487 - val_categorical_accuracy: 0.2142\n",
      "Epoch 2/6\n",
      "358484/358484 [==============================] - 9s 25us/step - loss: 2.2879 - categorical_accuracy: 0.1800 - val_loss: 2.1582 - val_categorical_accuracy: 0.2312\n",
      "Epoch 3/6\n",
      "358484/358484 [==============================] - 9s 26us/step - loss: 2.2866 - categorical_accuracy: 0.1823 - val_loss: 2.1418 - val_categorical_accuracy: 0.2313\n",
      "Epoch 4/6\n",
      "358484/358484 [==============================] - 10s 27us/step - loss: 2.2837 - categorical_accuracy: 0.1857 - val_loss: 2.1385 - val_categorical_accuracy: 0.2394\n",
      "Epoch 5/6\n",
      "358484/358484 [==============================] - 10s 27us/step - loss: 2.2817 - categorical_accuracy: 0.1891 - val_loss: 2.1392 - val_categorical_accuracy: 0.2395\n",
      "Epoch 6/6\n",
      "358484/358484 [==============================] - 9s 26us/step - loss: 2.2802 - categorical_accuracy: 0.1880 - val_loss: 2.1300 - val_categorical_accuracy: 0.2289\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30302/30302 [==============================] - 0s 16us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3701306075559938, 0.2917629199441955]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300,input_length=15))\n",
    "model.add(Dense(300, activation='relu', input_dim=15))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 711924 samples, validate on 42542 samples\n",
      "Epoch 1/4\n",
      "711924/711924 [==============================] - 11s 16us/step - loss: 2.7505 - categorical_accuracy: 0.3063 - val_loss: 2.6746 - val_categorical_accuracy: 0.2312\n",
      "Epoch 2/4\n",
      "711924/711924 [==============================] - 10s 15us/step - loss: 2.7355 - categorical_accuracy: 0.3131 - val_loss: 2.6953 - val_categorical_accuracy: 0.2227\n",
      "Epoch 3/4\n",
      "711924/711924 [==============================] - 10s 15us/step - loss: 2.7349 - categorical_accuracy: 0.3134 - val_loss: 2.6953 - val_categorical_accuracy: 0.2227\n",
      "Epoch 4/4\n",
      "711924/711924 [==============================] - 10s 15us/step - loss: 2.7349 - categorical_accuracy: 0.3134 - val_loss: 2.6953 - val_categorical_accuracy: 0.2227\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16968/16968 [==============================] - 0s 17us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.777652508467225, 0.31347241867043846]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300,input_length=15))\n",
    "model.add(Dense(300, activation='sigmoid', input_dim=15))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 12s 26us/step - loss: 0.3623 - categorical_accuracy: 0.2733 - val_loss: 0.3074 - val_categorical_accuracy: 0.2127\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 12s 25us/step - loss: 0.3528 - categorical_accuracy: 0.2822 - val_loss: 0.3024 - val_categorical_accuracy: 0.3311\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 12s 25us/step - loss: 0.3464 - categorical_accuracy: 0.2847 - val_loss: 0.3041 - val_categorical_accuracy: 0.3002\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 12s 25us/step - loss: 0.3408 - categorical_accuracy: 0.2881 - val_loss: 0.3029 - val_categorical_accuracy: 0.2917\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300,input_length=15))\n",
    "model.add(Dense(300, activation='sigmoid', input_dim=15))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 17s 35us/step - loss: 0.3612 - categorical_accuracy: 0.2776 - val_loss: 0.3047 - val_categorical_accuracy: 0.3257\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 16s 33us/step - loss: 0.3472 - categorical_accuracy: 0.2888 - val_loss: 0.3023 - val_categorical_accuracy: 0.2896\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 16s 33us/step - loss: 0.3392 - categorical_accuracy: 0.2916 - val_loss: 0.3045 - val_categorical_accuracy: 0.3026\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 16s 33us/step - loss: 0.3315 - categorical_accuracy: 0.2933 - val_loss: 0.3047 - val_categorical_accuracy: 0.3212\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 9s 18us/step - loss: 0.3121 - categorical_accuracy: 0.3606 - val_loss: 0.2770 - val_categorical_accuracy: 0.3414\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 8s 16us/step - loss: 0.1623 - categorical_accuracy: 0.5833 - val_loss: 0.3133 - val_categorical_accuracy: 0.3344\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 8s 16us/step - loss: 0.1039 - categorical_accuracy: 0.6364 - val_loss: 0.3685 - val_categorical_accuracy: 0.3245\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 8s 16us/step - loss: 0.0760 - categorical_accuracy: 0.6496 - val_loss: 0.4256 - val_categorical_accuracy: 0.3246\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(Conv1D(filters=15,kernel_size=2))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 13s 28us/step - loss: 0.3132 - categorical_accuracy: 0.3622 - val_loss: 0.2806 - val_categorical_accuracy: 0.3209\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 12s 25us/step - loss: 0.1933 - categorical_accuracy: 0.4961 - val_loss: 0.3093 - val_categorical_accuracy: 0.3052\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 12s 24us/step - loss: 0.1522 - categorical_accuracy: 0.5294 - val_loss: 0.3411 - val_categorical_accuracy: 0.3040\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 12s 24us/step - loss: 0.1292 - categorical_accuracy: 0.5360 - val_loss: 0.3725 - val_categorical_accuracy: 0.2919\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=15))\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/10\n",
      "480706/480706 [==============================] - 22s 45us/step - loss: 0.3965 - categorical_accuracy: 0.2432 - val_loss: 0.3013 - val_categorical_accuracy: 0.3406\n",
      "Epoch 2/10\n",
      "480706/480706 [==============================] - 20s 41us/step - loss: 0.3287 - categorical_accuracy: 0.3195 - val_loss: 0.2875 - val_categorical_accuracy: 0.3196\n",
      "Epoch 3/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.2611 - categorical_accuracy: 0.4215 - val_loss: 0.2971 - val_categorical_accuracy: 0.3073\n",
      "Epoch 4/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.2048 - categorical_accuracy: 0.5103 - val_loss: 0.3144 - val_categorical_accuracy: 0.3185\n",
      "Epoch 5/10\n",
      "480706/480706 [==============================] - 20s 41us/step - loss: 0.1678 - categorical_accuracy: 0.5882 - val_loss: 0.3387 - val_categorical_accuracy: 0.3311\n",
      "Epoch 6/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.1401 - categorical_accuracy: 0.6242 - val_loss: 0.3645 - val_categorical_accuracy: 0.3281\n",
      "Epoch 7/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.1198 - categorical_accuracy: 0.6423 - val_loss: 0.3948 - val_categorical_accuracy: 0.3228\n",
      "Epoch 8/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.1046 - categorical_accuracy: 0.6477 - val_loss: 0.4164 - val_categorical_accuracy: 0.3355\n",
      "Epoch 9/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.0925 - categorical_accuracy: 0.6491 - val_loss: 0.4457 - val_categorical_accuracy: 0.3339\n",
      "Epoch 10/10\n",
      "480706/480706 [==============================] - 21s 43us/step - loss: 0.0828 - categorical_accuracy: 0.6541 - val_loss: 0.4727 - val_categorical_accuracy: 0.3281\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=15,dropout=0.5))\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/10\n",
      "480706/480706 [==============================] - 24s 51us/step - loss: 0.3896 - categorical_accuracy: 0.2492 - val_loss: 0.2951 - val_categorical_accuracy: 0.2055\n",
      "Epoch 2/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.3106 - categorical_accuracy: 0.2419 - val_loss: 0.2923 - val_categorical_accuracy: 0.2200\n",
      "Epoch 3/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2638 - categorical_accuracy: 0.3352 - val_loss: 0.2947 - val_categorical_accuracy: 0.2900\n",
      "Epoch 4/10\n",
      "480706/480706 [==============================] - 22s 45us/step - loss: 0.2280 - categorical_accuracy: 0.4346 - val_loss: 0.2994 - val_categorical_accuracy: 0.2927\n",
      "Epoch 5/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1998 - categorical_accuracy: 0.4691 - val_loss: 0.3095 - val_categorical_accuracy: 0.2929\n",
      "Epoch 6/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1833 - categorical_accuracy: 0.4925 - val_loss: 0.3201 - val_categorical_accuracy: 0.2955\n",
      "Epoch 7/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1719 - categorical_accuracy: 0.5095 - val_loss: 0.3377 - val_categorical_accuracy: 0.2941\n",
      "Epoch 8/10\n",
      "480706/480706 [==============================] - 23s 47us/step - loss: 0.1629 - categorical_accuracy: 0.5205 - val_loss: 0.3440 - val_categorical_accuracy: 0.3012\n",
      "Epoch 9/10\n",
      "480706/480706 [==============================] - 22s 47us/step - loss: 0.1558 - categorical_accuracy: 0.5286 - val_loss: 0.3580 - val_categorical_accuracy: 0.2966\n",
      "Epoch 10/10\n",
      "480706/480706 [==============================] - 23s 47us/step - loss: 0.1498 - categorical_accuracy: 0.5339 - val_loss: 0.3669 - val_categorical_accuracy: 0.2963\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=15,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/10\n",
      "480706/480706 [==============================] - 24s 50us/step - loss: 0.3729 - categorical_accuracy: 0.2750 - val_loss: 0.2868 - val_categorical_accuracy: 0.3534\n",
      "Epoch 2/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2979 - categorical_accuracy: 0.3678 - val_loss: 0.2798 - val_categorical_accuracy: 0.3122\n",
      "Epoch 3/10\n",
      "480706/480706 [==============================] - 22s 45us/step - loss: 0.2621 - categorical_accuracy: 0.3925 - val_loss: 0.2765 - val_categorical_accuracy: 0.2912\n",
      "Epoch 4/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2378 - categorical_accuracy: 0.3910 - val_loss: 0.2806 - val_categorical_accuracy: 0.2862\n",
      "Epoch 5/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2195 - categorical_accuracy: 0.3993 - val_loss: 0.2868 - val_categorical_accuracy: 0.2821\n",
      "Epoch 6/10\n",
      "480706/480706 [==============================] - 21s 45us/step - loss: 0.2054 - categorical_accuracy: 0.4168 - val_loss: 0.2885 - val_categorical_accuracy: 0.2942\n",
      "Epoch 7/10\n",
      "480706/480706 [==============================] - 21s 45us/step - loss: 0.1938 - categorical_accuracy: 0.4396 - val_loss: 0.2931 - val_categorical_accuracy: 0.2959\n",
      "Epoch 8/10\n",
      "480706/480706 [==============================] - 21s 45us/step - loss: 0.1837 - categorical_accuracy: 0.4620 - val_loss: 0.2958 - val_categorical_accuracy: 0.3023\n",
      "Epoch 9/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1755 - categorical_accuracy: 0.4806 - val_loss: 0.3047 - val_categorical_accuracy: 0.3062\n",
      "Epoch 10/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1686 - categorical_accuracy: 0.4963 - val_loss: 0.3069 - val_categorical_accuracy: 0.3098\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 63s 130us/step - loss: 0.3368 - categorical_accuracy: 0.3093 - val_loss: 0.2784 - val_categorical_accuracy: 0.3377\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 60s 125us/step - loss: 0.2544 - categorical_accuracy: 0.3886 - val_loss: 0.2754 - val_categorical_accuracy: 0.3392\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 59s 124us/step - loss: 0.2061 - categorical_accuracy: 0.4286 - val_loss: 0.2780 - val_categorical_accuracy: 0.3276\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 61s 127us/step - loss: 0.1781 - categorical_accuracy: 0.4674 - val_loss: 0.2845 - val_categorical_accuracy: 0.3838\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 131s 273us/step - loss: 0.2407 - categorical_accuracy: 0.4084 - val_loss: 0.2657 - val_categorical_accuracy: 0.3660\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 134s 278us/step - loss: 0.1200 - categorical_accuracy: 0.5198 - val_loss: 0.3120 - val_categorical_accuracy: 0.3779\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 129s 269us/step - loss: 0.0849 - categorical_accuracy: 0.5433 - val_loss: 0.3533 - val_categorical_accuracy: 0.3933\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 123s 256us/step - loss: 0.0670 - categorical_accuracy: 0.5531 - val_loss: 0.3648 - val_categorical_accuracy: 0.3614\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 144s 299us/step - loss: 0.2603 - categorical_accuracy: 0.3927 - val_loss: 0.2619 - val_categorical_accuracy: 0.3735\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 144s 300us/step - loss: 0.1281 - categorical_accuracy: 0.5149 - val_loss: 0.2991 - val_categorical_accuracy: 0.3854\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 141s 293us/step - loss: 0.0891 - categorical_accuracy: 0.5421 - val_loss: 0.3305 - val_categorical_accuracy: 0.3654\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 142s 294us/step - loss: 0.0699 - categorical_accuracy: 0.5525 - val_loss: 0.3636 - val_categorical_accuracy: 0.3623\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[top_3_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 155s 323us/step - loss: 0.2645 - top_3_accuracy: 0.6709 - val_loss: 0.2829 - val_top_3_accuracy: 0.6989\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 151s 315us/step - loss: 0.0995 - top_3_accuracy: 0.9275 - val_loss: 0.3524 - val_top_3_accuracy: 0.7083\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 156s 324us/step - loss: 0.0604 - top_3_accuracy: 0.9550 - val_loss: 0.4098 - val_top_3_accuracy: 0.6998\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 151s 314us/step - loss: 0.0439 - top_3_accuracy: 0.9633 - val_loss: 0.4590 - val_top_3_accuracy: 0.7104\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 144s 300us/step - loss: 0.2591 - top_3_accuracy: 0.6832 - val_loss: 0.2614 - val_top_3_accuracy: 0.7131\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 140s 292us/step - loss: 0.1269 - top_3_accuracy: 0.8907 - val_loss: 0.3014 - val_top_3_accuracy: 0.7368\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 139s 290us/step - loss: 0.0876 - top_3_accuracy: 0.9269 - val_loss: 0.3333 - val_top_3_accuracy: 0.7359\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 140s 292us/step - loss: 0.0685 - top_3_accuracy: 0.9408 - val_loss: 0.3611 - val_top_3_accuracy: 0.7363\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8475/8475 [==============================] - 2s 203us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3741736157664859, 0.7189380530903121]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cc_test_data,cc_test_data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy,'accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 135s 280us/step - loss: 0.2571 - top_3_accuracy: 0.6866 - acc: 0.8944 - categorical_accuracy: 0.3799 - val_loss: 0.2664 - val_top_3_accuracy: 0.7184 - val_acc: 0.8875 - val_categorical_accuracy: 0.3795\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 135s 280us/step - loss: 0.1281 - top_3_accuracy: 0.8894 - acc: 0.9481 - categorical_accuracy: 0.5082 - val_loss: 0.2937 - val_top_3_accuracy: 0.7343 - val_acc: 0.8843 - val_categorical_accuracy: 0.3934\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 131s 272us/step - loss: 0.0888 - top_3_accuracy: 0.9259 - acc: 0.9658 - categorical_accuracy: 0.5418 - val_loss: 0.3326 - val_top_3_accuracy: 0.7342 - val_acc: 0.8792 - val_categorical_accuracy: 0.3857\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 130s 271us/step - loss: 0.0696 - top_3_accuracy: 0.9397 - acc: 0.9741 - categorical_accuracy: 0.5522 - val_loss: 0.3629 - val_top_3_accuracy: 0.7288 - val_acc: 0.8783 - val_categorical_accuracy: 0.3844\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5)))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy,'accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"2xBilstm-{epoch:02d}-{val_loss:.2f}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358484 samples, validate on 49290 samples\n",
      "Epoch 1/4\n",
      "358484/358484 [==============================] - 96s 268us/step - loss: 0.1395 - top_3_accuracy: 0.8842 - acc: 0.9412 - categorical_accuracy: 0.5579 - val_loss: 0.1762 - val_top_3_accuracy: 0.8603 - val_acc: 0.9229 - val_categorical_accuracy: 0.5487\n",
      "\n",
      "Epoch 00001: saving model to 2xBilstm-01-0.18-0.55.hdf5\n",
      "Epoch 2/4\n",
      "358484/358484 [==============================] - 96s 268us/step - loss: 0.1228 - top_3_accuracy: 0.9015 - acc: 0.9493 - categorical_accuracy: 0.5747 - val_loss: 0.1603 - val_top_3_accuracy: 0.8911 - val_acc: 0.9318 - val_categorical_accuracy: 0.5681\n",
      "\n",
      "Epoch 00002: saving model to 2xBilstm-02-0.16-0.57.hdf5\n",
      "Epoch 3/4\n",
      "358484/358484 [==============================] - 96s 268us/step - loss: 0.1092 - top_3_accuracy: 0.9138 - acc: 0.9556 - categorical_accuracy: 0.5832 - val_loss: 0.1500 - val_top_3_accuracy: 0.8924 - val_acc: 0.9373 - val_categorical_accuracy: 0.5851\n",
      "\n",
      "Epoch 00003: saving model to 2xBilstm-03-0.15-0.59.hdf5\n",
      "Epoch 4/4\n",
      "358484/358484 [==============================] - 97s 270us/step - loss: 0.0982 - top_3_accuracy: 0.9230 - acc: 0.9607 - categorical_accuracy: 0.5861 - val_loss: 0.1362 - val_top_3_accuracy: 0.8644 - val_acc: 0.9440 - val_categorical_accuracy: 0.4795\n",
      "\n",
      "Epoch 00004: saving model to 2xBilstm-04-0.14-0.48.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=1024, epochs=4,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30237/30237 [==============================] - 35s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18163946719529575,\n",
       " 0.8345404636703376,\n",
       " 0.9197624472866543,\n",
       " 0.5073585342579497]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('50%_categorical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./2xBilstm-03-0.15-0.59.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27368/27368 [==============================] - 31s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14074560044130624,\n",
       " 0.8990061385559778,\n",
       " 0.9414096788787173,\n",
       " 0.6011400175387314]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(cc_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = cc_val_data_out - pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.absolute(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "error.to_csv('bilstm_error.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "!explorer ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2969.5"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc_val_df)/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5089.301023368861,\n",
       " 762.4743669615234,\n",
       " 2454.0194316451343,\n",
       " 1656.4140921296591,\n",
       " 10343.44581935413,\n",
       " 2204.0897995197242,\n",
       " 499.975531778603,\n",
       " 4319.007700273058,\n",
       " 9885.208288726579,\n",
       " 11999.036386445297,\n",
       " 406.4953425794674,\n",
       " 1292.0463068031086,\n",
       " 15.940705289792575,\n",
       " 26.371238619690075]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[error[cat].sum() for cat in cc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_anagram 0.5518053803934577\n",
      "is_homophone 0.30609167682116556\n",
      "is_double 0.6011806544941535\n",
      "is_cryptic 0.6089757691653158\n",
      "is_contain 0.5840784809618912\n",
      "is_reverse 0.3757398226252513\n",
      "is_alternate 0.6820948591795403\n",
      "is_init 0.7701511591071786\n",
      "is_delete 0.8669714338472706\n",
      "is_charade 0.8708205520317365\n",
      "is_&lit 0.47654788110136853\n",
      "is_hidden 0.4530316643769665\n",
      "is_spoonerism 0.09839941536908997\n",
      "is_palindrome 0.3995642215104557\n"
     ]
    }
   ],
   "source": [
    "error_col_sums = [error[cat].sum() for cat in cc_types]\n",
    "length_per_cat = [len(cc_val_df[cc_val_df[cat]==True]) for cat in cc_types]\n",
    "for cat,err,leng in zip(cc_types,error_col_sums,length_per_cat):\n",
    "    print(cat,err/leng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9223,\n",
       " 2491,\n",
       " 4082,\n",
       " 2720,\n",
       " 17709,\n",
       " 5866,\n",
       " 733,\n",
       " 5608,\n",
       " 11402,\n",
       " 13779,\n",
       " 853,\n",
       " 2852,\n",
       " 162,\n",
       " 66]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(cc_val_df[cc_val_df[cat]==True]) for cat in cc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['is_anagram', 'is_homophone', 'is_double', 'is_cryptic', 'is_contain',\n",
       "       'is_reverse', 'is_alternate', 'is_init', 'is_delete', 'is_charade',\n",
       "       'is_&lit', 'is_hidden', 'is_spoonerism', 'is_palindrome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_anagram',\n",
       " 'is_homophone',\n",
       " 'is_double',\n",
       " 'is_cryptic',\n",
       " 'is_contain',\n",
       " 'is_reverse',\n",
       " 'is_alternate',\n",
       " 'is_init',\n",
       " 'is_delete',\n",
       " 'is_charade',\n",
       " 'is_&lit',\n",
       " 'is_hidden',\n",
       " 'is_spoonerism',\n",
       " 'is_palindrome']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Proceeding smoothly and evenly, judge back observing cases'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt = pad_sequences(tokenizer.texts_to_sequences([query]),maxlen=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(inpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is_anagram',\n",
       " 'is_homophone',\n",
       " 'is_double',\n",
       " 'is_cryptic',\n",
       " 'is_contain',\n",
       " 'is_reverse',\n",
       " 'is_alternate',\n",
       " 'is_init',\n",
       " 'is_delete',\n",
       " 'is_charade',\n",
       " 'is_&lit',\n",
       " 'is_hidden',\n",
       " 'is_spoonerism',\n",
       " 'is_palindrome']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_anagram 0.00080093107\n",
      "is_homophone 0.001205507\n",
      "is_double 0.00011718823\n",
      "is_cryptic 3.4680426e-05\n",
      "is_contain 0.9938917\n",
      "is_reverse 0.0020614178\n",
      "is_alternate 0.9986004\n",
      "is_init 2.895232e-06\n",
      "is_delete 0.01853707\n",
      "is_charade 0.0053280066\n",
      "is_&lit 3.5364006e-05\n",
      "is_hidden 0.00079043105\n",
      "is_spoonerism 1.4816669e-06\n",
      "is_palindrome 1.3082043e-05\n"
     ]
    }
   ],
   "source": [
    "for a,b in zip(cc_types,preds[0]):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5)))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy,'accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
