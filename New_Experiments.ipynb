{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import keras\n",
    "from keras.layers import Dense,Embedding, Flatten, Conv1D, GlobalMaxPooling1D, LSTM, Bidirectional\n",
    "from keras.preprocessing.text import text_to_word_sequence,Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../fifteen_dataset/combined_fifteen_times_final.pickle\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_types = \"is_anagram\tis_homophone\tis_double\tis_cryptic\tis_contain\tis_reverse\tis_alternate\tis_init\tis_delete\tis_charade\tis_&lit\tis_hidden\tis_spoonerism\tis_palindrome\".split('\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.clue = df.clue.apply(text_to_word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_types_dfs = [df[df[cc_type]==True] for cc_type in cc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for cc_type,cc_type_df in zip(cc_types,cc_types_dfs):\n",
    "    cc_type_df['category'] = cc_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.concat(cc_types_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = concatenated_df.groupby('category').count().max()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [concatenated_df]\n",
    "for class_index, group in concatenated_df.groupby('category'):\n",
    "    sample = group.sample(max_size-len(group), replace=True, )\n",
    "    lst.append(sample)\n",
    "upsampled_df = pd.concat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clue</th>\n",
       "      <th>exp</th>\n",
       "      <th>is_anagram</th>\n",
       "      <th>is_homophone</th>\n",
       "      <th>is_double</th>\n",
       "      <th>is_cryptic</th>\n",
       "      <th>is_contain</th>\n",
       "      <th>is_reverse</th>\n",
       "      <th>is_alternate</th>\n",
       "      <th>is_init</th>\n",
       "      <th>is_delete</th>\n",
       "      <th>is_charade</th>\n",
       "      <th>is_&amp;lit</th>\n",
       "      <th>is_hidden</th>\n",
       "      <th>is_spoonerism</th>\n",
       "      <th>is_palindrome</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_&amp;lit</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_alternate</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_anagram</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_charade</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_contain</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_cryptic</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_delete</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_double</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_hidden</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_homophone</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_init</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_palindrome</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_reverse</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_spoonerism</th>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "      <td>36581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                clue    exp  is_anagram  is_homophone  is_double  is_cryptic  \\\n",
       "category                                                                       \n",
       "is_&lit        36581  36581       36581         36581      36581       36581   \n",
       "is_alternate   36581  36581       36581         36581      36581       36581   \n",
       "is_anagram     36581  36581       36581         36581      36581       36581   \n",
       "is_charade     36581  36581       36581         36581      36581       36581   \n",
       "is_contain     36581  36581       36581         36581      36581       36581   \n",
       "is_cryptic     36581  36581       36581         36581      36581       36581   \n",
       "is_delete      36581  36581       36581         36581      36581       36581   \n",
       "is_double      36581  36581       36581         36581      36581       36581   \n",
       "is_hidden      36581  36581       36581         36581      36581       36581   \n",
       "is_homophone   36581  36581       36581         36581      36581       36581   \n",
       "is_init        36581  36581       36581         36581      36581       36581   \n",
       "is_palindrome  36581  36581       36581         36581      36581       36581   \n",
       "is_reverse     36581  36581       36581         36581      36581       36581   \n",
       "is_spoonerism  36581  36581       36581         36581      36581       36581   \n",
       "\n",
       "               is_contain  is_reverse  is_alternate  is_init  is_delete  \\\n",
       "category                                                                  \n",
       "is_&lit             36581       36581         36581    36581      36581   \n",
       "is_alternate        36581       36581         36581    36581      36581   \n",
       "is_anagram          36581       36581         36581    36581      36581   \n",
       "is_charade          36581       36581         36581    36581      36581   \n",
       "is_contain          36581       36581         36581    36581      36581   \n",
       "is_cryptic          36581       36581         36581    36581      36581   \n",
       "is_delete           36581       36581         36581    36581      36581   \n",
       "is_double           36581       36581         36581    36581      36581   \n",
       "is_hidden           36581       36581         36581    36581      36581   \n",
       "is_homophone        36581       36581         36581    36581      36581   \n",
       "is_init             36581       36581         36581    36581      36581   \n",
       "is_palindrome       36581       36581         36581    36581      36581   \n",
       "is_reverse          36581       36581         36581    36581      36581   \n",
       "is_spoonerism       36581       36581         36581    36581      36581   \n",
       "\n",
       "               is_charade  is_&lit  is_hidden  is_spoonerism  is_palindrome  \n",
       "category                                                                     \n",
       "is_&lit             36581    36581      36581          36581          36581  \n",
       "is_alternate        36581    36581      36581          36581          36581  \n",
       "is_anagram          36581    36581      36581          36581          36581  \n",
       "is_charade          36581    36581      36581          36581          36581  \n",
       "is_contain          36581    36581      36581          36581          36581  \n",
       "is_cryptic          36581    36581      36581          36581          36581  \n",
       "is_delete           36581    36581      36581          36581          36581  \n",
       "is_double           36581    36581      36581          36581          36581  \n",
       "is_hidden           36581    36581      36581          36581          36581  \n",
       "is_homophone        36581    36581      36581          36581          36581  \n",
       "is_init             36581    36581      36581          36581          36581  \n",
       "is_palindrome       36581    36581      36581          36581          36581  \n",
       "is_reverse          36581    36581      36581          36581          36581  \n",
       "is_spoonerism       36581    36581      36581          36581          36581  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled_df.groupby('category').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaled_cc_dfs = [x[1] for x in upsampled_df.groupby('category')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_val_test(df):\n",
    "    length = len(df)\n",
    "    input_len = math.floor(length*0.7)\n",
    "    val_len  = math.floor(length*0.2)\n",
    "    test_len = math.floor(length*0.1)\n",
    "    input_df = df[:input_len]\n",
    "    val_df = df[input_len:input_len+val_len]\n",
    "    test_df = df[input_len+val_len:]\n",
    "    return input_df,val_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_cc_types_dfs = [x[1] for x in upsampled_df.groupby('category')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dfs = []\n",
    "val_dfs = []\n",
    "test_dfs = []\n",
    "for cc_type_df in upsampled_cc_types_dfs:\n",
    "    input_df,val_df,test_df = get_input_val_test(cc_type_df)\n",
    "    input_dfs.append(input_df)\n",
    "    val_dfs.append(val_df)\n",
    "    test_dfs.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_input_df = pd.concat(input_dfs)\n",
    "cc_val_df = pd.concat(val_dfs).drop_duplicates()\n",
    "cc_test_df = pd.concat(test_dfs).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df.clue.tolist())\n",
    "cc_input_data = pad_sequences(tokenizer.texts_to_sequences(cc_input_df.clue.tolist()),maxlen=15)\n",
    "cc_val_data = pad_sequences(tokenizer.texts_to_sequences(cc_val_df.clue.tolist()),maxlen=15)\n",
    "cc_test_data = pad_sequences(tokenizer.texts_to_sequences(cc_test_df.clue.tolist()),maxlen=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358484"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_input_data_out = cc_input_df[cc_input_df.columns[2:-1]] * 1\n",
    "cc_val_data_out = cc_val_df[cc_val_df.columns[2:-1]] * 1\n",
    "cc_test_data_out = cc_test_df[cc_test_df.columns[2:-1]] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300))\n",
    "model.add(Dense(14, activation='relu', input_dim=15))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358484 samples, validate on 49180 samples\n",
      "Epoch 1/6\n",
      "358484/358484 [==============================] - 6s 16us/step - loss: 3.3946 - categorical_accuracy: 0.0455 - val_loss: 2.6466 - val_categorical_accuracy: 0.0478\n",
      "Epoch 2/6\n",
      "358484/358484 [==============================] - 4s 12us/step - loss: 2.4441 - categorical_accuracy: 0.1367 - val_loss: 2.3147 - val_categorical_accuracy: 0.2202\n",
      "Epoch 3/6\n",
      "358484/358484 [==============================] - 4s 12us/step - loss: 2.2802 - categorical_accuracy: 0.1833 - val_loss: 2.3002 - val_categorical_accuracy: 0.2362\n",
      "Epoch 4/6\n",
      "358484/358484 [==============================] - 4s 12us/step - loss: 2.2584 - categorical_accuracy: 0.1734 - val_loss: 2.2246 - val_categorical_accuracy: 0.1864\n",
      "Epoch 5/6\n",
      "358484/358484 [==============================] - 4s 12us/step - loss: 1.7173 - categorical_accuracy: 0.1494 - val_loss: 0.5385 - val_categorical_accuracy: 0.2949\n",
      "Epoch 6/6\n",
      "358484/358484 [==============================] - 4s 12us/step - loss: 0.4070 - categorical_accuracy: 0.2597 - val_loss: 0.3639 - val_categorical_accuracy: 0.3100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30302/30302 [==============================] - 0s 16us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3701306075559938, 0.2917629199441955]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300,input_length=15))\n",
    "model.add(Dense(300, activation='relu', input_dim=15))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 711924 samples, validate on 42542 samples\n",
      "Epoch 1/4\n",
      "711924/711924 [==============================] - 11s 16us/step - loss: 2.7505 - categorical_accuracy: 0.3063 - val_loss: 2.6746 - val_categorical_accuracy: 0.2312\n",
      "Epoch 2/4\n",
      "711924/711924 [==============================] - 10s 15us/step - loss: 2.7355 - categorical_accuracy: 0.3131 - val_loss: 2.6953 - val_categorical_accuracy: 0.2227\n",
      "Epoch 3/4\n",
      "711924/711924 [==============================] - 10s 15us/step - loss: 2.7349 - categorical_accuracy: 0.3134 - val_loss: 2.6953 - val_categorical_accuracy: 0.2227\n",
      "Epoch 4/4\n",
      "711924/711924 [==============================] - 10s 15us/step - loss: 2.7349 - categorical_accuracy: 0.3134 - val_loss: 2.6953 - val_categorical_accuracy: 0.2227\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16968/16968 [==============================] - 0s 17us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.777652508467225, 0.31347241867043846]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300,input_length=15))\n",
    "model.add(Dense(300, activation='sigmoid', input_dim=15))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 12s 26us/step - loss: 0.3623 - categorical_accuracy: 0.2733 - val_loss: 0.3074 - val_categorical_accuracy: 0.2127\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 12s 25us/step - loss: 0.3528 - categorical_accuracy: 0.2822 - val_loss: 0.3024 - val_categorical_accuracy: 0.3311\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 12s 25us/step - loss: 0.3464 - categorical_accuracy: 0.2847 - val_loss: 0.3041 - val_categorical_accuracy: 0.3002\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 12s 25us/step - loss: 0.3408 - categorical_accuracy: 0.2881 - val_loss: 0.3029 - val_categorical_accuracy: 0.2917\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(Embedding(vocab_size, 300,input_length=15))\n",
    "model.add(Dense(300, activation='sigmoid', input_dim=15))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(300, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 17s 35us/step - loss: 0.3612 - categorical_accuracy: 0.2776 - val_loss: 0.3047 - val_categorical_accuracy: 0.3257\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 16s 33us/step - loss: 0.3472 - categorical_accuracy: 0.2888 - val_loss: 0.3023 - val_categorical_accuracy: 0.2896\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 16s 33us/step - loss: 0.3392 - categorical_accuracy: 0.2916 - val_loss: 0.3045 - val_categorical_accuracy: 0.3026\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 16s 33us/step - loss: 0.3315 - categorical_accuracy: 0.2933 - val_loss: 0.3047 - val_categorical_accuracy: 0.3212\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=128, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 9s 18us/step - loss: 0.3121 - categorical_accuracy: 0.3606 - val_loss: 0.2770 - val_categorical_accuracy: 0.3414\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 8s 16us/step - loss: 0.1623 - categorical_accuracy: 0.5833 - val_loss: 0.3133 - val_categorical_accuracy: 0.3344\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 8s 16us/step - loss: 0.1039 - categorical_accuracy: 0.6364 - val_loss: 0.3685 - val_categorical_accuracy: 0.3245\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 8s 16us/step - loss: 0.0760 - categorical_accuracy: 0.6496 - val_loss: 0.4256 - val_categorical_accuracy: 0.3246\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(Conv1D(filters=15,kernel_size=2))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 13s 28us/step - loss: 0.3132 - categorical_accuracy: 0.3622 - val_loss: 0.2806 - val_categorical_accuracy: 0.3209\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 12s 25us/step - loss: 0.1933 - categorical_accuracy: 0.4961 - val_loss: 0.3093 - val_categorical_accuracy: 0.3052\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 12s 24us/step - loss: 0.1522 - categorical_accuracy: 0.5294 - val_loss: 0.3411 - val_categorical_accuracy: 0.3040\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 12s 24us/step - loss: 0.1292 - categorical_accuracy: 0.5360 - val_loss: 0.3725 - val_categorical_accuracy: 0.2919\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=15))\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/10\n",
      "480706/480706 [==============================] - 22s 45us/step - loss: 0.3965 - categorical_accuracy: 0.2432 - val_loss: 0.3013 - val_categorical_accuracy: 0.3406\n",
      "Epoch 2/10\n",
      "480706/480706 [==============================] - 20s 41us/step - loss: 0.3287 - categorical_accuracy: 0.3195 - val_loss: 0.2875 - val_categorical_accuracy: 0.3196\n",
      "Epoch 3/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.2611 - categorical_accuracy: 0.4215 - val_loss: 0.2971 - val_categorical_accuracy: 0.3073\n",
      "Epoch 4/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.2048 - categorical_accuracy: 0.5103 - val_loss: 0.3144 - val_categorical_accuracy: 0.3185\n",
      "Epoch 5/10\n",
      "480706/480706 [==============================] - 20s 41us/step - loss: 0.1678 - categorical_accuracy: 0.5882 - val_loss: 0.3387 - val_categorical_accuracy: 0.3311\n",
      "Epoch 6/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.1401 - categorical_accuracy: 0.6242 - val_loss: 0.3645 - val_categorical_accuracy: 0.3281\n",
      "Epoch 7/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.1198 - categorical_accuracy: 0.6423 - val_loss: 0.3948 - val_categorical_accuracy: 0.3228\n",
      "Epoch 8/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.1046 - categorical_accuracy: 0.6477 - val_loss: 0.4164 - val_categorical_accuracy: 0.3355\n",
      "Epoch 9/10\n",
      "480706/480706 [==============================] - 20s 42us/step - loss: 0.0925 - categorical_accuracy: 0.6491 - val_loss: 0.4457 - val_categorical_accuracy: 0.3339\n",
      "Epoch 10/10\n",
      "480706/480706 [==============================] - 21s 43us/step - loss: 0.0828 - categorical_accuracy: 0.6541 - val_loss: 0.4727 - val_categorical_accuracy: 0.3281\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=15,dropout=0.5))\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/10\n",
      "480706/480706 [==============================] - 24s 51us/step - loss: 0.3896 - categorical_accuracy: 0.2492 - val_loss: 0.2951 - val_categorical_accuracy: 0.2055\n",
      "Epoch 2/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.3106 - categorical_accuracy: 0.2419 - val_loss: 0.2923 - val_categorical_accuracy: 0.2200\n",
      "Epoch 3/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2638 - categorical_accuracy: 0.3352 - val_loss: 0.2947 - val_categorical_accuracy: 0.2900\n",
      "Epoch 4/10\n",
      "480706/480706 [==============================] - 22s 45us/step - loss: 0.2280 - categorical_accuracy: 0.4346 - val_loss: 0.2994 - val_categorical_accuracy: 0.2927\n",
      "Epoch 5/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1998 - categorical_accuracy: 0.4691 - val_loss: 0.3095 - val_categorical_accuracy: 0.2929\n",
      "Epoch 6/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1833 - categorical_accuracy: 0.4925 - val_loss: 0.3201 - val_categorical_accuracy: 0.2955\n",
      "Epoch 7/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1719 - categorical_accuracy: 0.5095 - val_loss: 0.3377 - val_categorical_accuracy: 0.2941\n",
      "Epoch 8/10\n",
      "480706/480706 [==============================] - 23s 47us/step - loss: 0.1629 - categorical_accuracy: 0.5205 - val_loss: 0.3440 - val_categorical_accuracy: 0.3012\n",
      "Epoch 9/10\n",
      "480706/480706 [==============================] - 22s 47us/step - loss: 0.1558 - categorical_accuracy: 0.5286 - val_loss: 0.3580 - val_categorical_accuracy: 0.2966\n",
      "Epoch 10/10\n",
      "480706/480706 [==============================] - 23s 47us/step - loss: 0.1498 - categorical_accuracy: 0.5339 - val_loss: 0.3669 - val_categorical_accuracy: 0.2963\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=15,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/10\n",
      "480706/480706 [==============================] - 24s 50us/step - loss: 0.3729 - categorical_accuracy: 0.2750 - val_loss: 0.2868 - val_categorical_accuracy: 0.3534\n",
      "Epoch 2/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2979 - categorical_accuracy: 0.3678 - val_loss: 0.2798 - val_categorical_accuracy: 0.3122\n",
      "Epoch 3/10\n",
      "480706/480706 [==============================] - 22s 45us/step - loss: 0.2621 - categorical_accuracy: 0.3925 - val_loss: 0.2765 - val_categorical_accuracy: 0.2912\n",
      "Epoch 4/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2378 - categorical_accuracy: 0.3910 - val_loss: 0.2806 - val_categorical_accuracy: 0.2862\n",
      "Epoch 5/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.2195 - categorical_accuracy: 0.3993 - val_loss: 0.2868 - val_categorical_accuracy: 0.2821\n",
      "Epoch 6/10\n",
      "480706/480706 [==============================] - 21s 45us/step - loss: 0.2054 - categorical_accuracy: 0.4168 - val_loss: 0.2885 - val_categorical_accuracy: 0.2942\n",
      "Epoch 7/10\n",
      "480706/480706 [==============================] - 21s 45us/step - loss: 0.1938 - categorical_accuracy: 0.4396 - val_loss: 0.2931 - val_categorical_accuracy: 0.2959\n",
      "Epoch 8/10\n",
      "480706/480706 [==============================] - 21s 45us/step - loss: 0.1837 - categorical_accuracy: 0.4620 - val_loss: 0.2958 - val_categorical_accuracy: 0.3023\n",
      "Epoch 9/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1755 - categorical_accuracy: 0.4806 - val_loss: 0.3047 - val_categorical_accuracy: 0.3062\n",
      "Epoch 10/10\n",
      "480706/480706 [==============================] - 22s 46us/step - loss: 0.1686 - categorical_accuracy: 0.4963 - val_loss: 0.3069 - val_categorical_accuracy: 0.3098\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 10,input_length=15))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 63s 130us/step - loss: 0.3368 - categorical_accuracy: 0.3093 - val_loss: 0.2784 - val_categorical_accuracy: 0.3377\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 60s 125us/step - loss: 0.2544 - categorical_accuracy: 0.3886 - val_loss: 0.2754 - val_categorical_accuracy: 0.3392\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 59s 124us/step - loss: 0.2061 - categorical_accuracy: 0.4286 - val_loss: 0.2780 - val_categorical_accuracy: 0.3276\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 61s 127us/step - loss: 0.1781 - categorical_accuracy: 0.4674 - val_loss: 0.2845 - val_categorical_accuracy: 0.3838\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 131s 273us/step - loss: 0.2407 - categorical_accuracy: 0.4084 - val_loss: 0.2657 - val_categorical_accuracy: 0.3660\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 134s 278us/step - loss: 0.1200 - categorical_accuracy: 0.5198 - val_loss: 0.3120 - val_categorical_accuracy: 0.3779\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 129s 269us/step - loss: 0.0849 - categorical_accuracy: 0.5433 - val_loss: 0.3533 - val_categorical_accuracy: 0.3933\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 123s 256us/step - loss: 0.0670 - categorical_accuracy: 0.5531 - val_loss: 0.3648 - val_categorical_accuracy: 0.3614\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 144s 299us/step - loss: 0.2603 - categorical_accuracy: 0.3927 - val_loss: 0.2619 - val_categorical_accuracy: 0.3735\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 144s 300us/step - loss: 0.1281 - categorical_accuracy: 0.5149 - val_loss: 0.2991 - val_categorical_accuracy: 0.3854\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 141s 293us/step - loss: 0.0891 - categorical_accuracy: 0.5421 - val_loss: 0.3305 - val_categorical_accuracy: 0.3654\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 142s 294us/step - loss: 0.0699 - categorical_accuracy: 0.5525 - val_loss: 0.3636 - val_categorical_accuracy: 0.3623\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[top_3_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 155s 323us/step - loss: 0.2645 - top_3_accuracy: 0.6709 - val_loss: 0.2829 - val_top_3_accuracy: 0.6989\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 151s 315us/step - loss: 0.0995 - top_3_accuracy: 0.9275 - val_loss: 0.3524 - val_top_3_accuracy: 0.7083\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 156s 324us/step - loss: 0.0604 - top_3_accuracy: 0.9550 - val_loss: 0.4098 - val_top_3_accuracy: 0.6998\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 151s 314us/step - loss: 0.0439 - top_3_accuracy: 0.9633 - val_loss: 0.4590 - val_top_3_accuracy: 0.7104\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 144s 300us/step - loss: 0.2591 - top_3_accuracy: 0.6832 - val_loss: 0.2614 - val_top_3_accuracy: 0.7131\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 140s 292us/step - loss: 0.1269 - top_3_accuracy: 0.8907 - val_loss: 0.3014 - val_top_3_accuracy: 0.7368\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 139s 290us/step - loss: 0.0876 - top_3_accuracy: 0.9269 - val_loss: 0.3333 - val_top_3_accuracy: 0.7359\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 140s 292us/step - loss: 0.0685 - top_3_accuracy: 0.9408 - val_loss: 0.3611 - val_top_3_accuracy: 0.7363\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8475/8475 [==============================] - 2s 203us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3741736157664859, 0.7189380530903121]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cc_test_data,cc_test_data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(LSTM(units=100,dropout=0.5))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy,'accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480706 samples, validate on 16926 samples\n",
      "Epoch 1/4\n",
      "480706/480706 [==============================] - 135s 280us/step - loss: 0.2571 - top_3_accuracy: 0.6866 - acc: 0.8944 - categorical_accuracy: 0.3799 - val_loss: 0.2664 - val_top_3_accuracy: 0.7184 - val_acc: 0.8875 - val_categorical_accuracy: 0.3795\n",
      "Epoch 2/4\n",
      "480706/480706 [==============================] - 135s 280us/step - loss: 0.1281 - top_3_accuracy: 0.8894 - acc: 0.9481 - categorical_accuracy: 0.5082 - val_loss: 0.2937 - val_top_3_accuracy: 0.7343 - val_acc: 0.8843 - val_categorical_accuracy: 0.3934\n",
      "Epoch 3/4\n",
      "480706/480706 [==============================] - 131s 272us/step - loss: 0.0888 - top_3_accuracy: 0.9259 - acc: 0.9658 - categorical_accuracy: 0.5418 - val_loss: 0.3326 - val_top_3_accuracy: 0.7342 - val_acc: 0.8792 - val_categorical_accuracy: 0.3857\n",
      "Epoch 4/4\n",
      "480706/480706 [==============================] - 130s 271us/step - loss: 0.0696 - top_3_accuracy: 0.9397 - acc: 0.9741 - categorical_accuracy: 0.5522 - val_loss: 0.3629 - val_top_3_accuracy: 0.7288 - val_acc: 0.8783 - val_categorical_accuracy: 0.3844\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=512, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 100,input_length=15,mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(units=100,dropout=0.5)))\n",
    "model.add(Dense(14, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=[top_3_accuracy,'accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358484 samples, validate on 49180 samples\n",
      "Epoch 1/4\n",
      " 60416/358484 [====>.........................] - ETA: 4:31 - loss: 0.3414 - top_3_accuracy: 0.4886 - acc: 0.8616 - categorical_accuracy: 0.3169"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-318-180c51b68d8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc_input_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcc_input_data_out\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc_val_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcc_val_data_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(cc_input_data,cc_input_data_out ,validation_data=(cc_val_data,cc_val_data_out), batch_size=1024, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16968/16968 [==============================] - 4s 224us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09238049671071889,\n",
       " 0.8882013201320133,\n",
       " 0.9660284985691127,\n",
       " 0.45627062706270627]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=cc_test_data, y=cc_test_data_out, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16968"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(cc_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = cc_val_data_out - pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.absolute(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "error.to_csv('bilstm_error.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16154.535136588065,\n",
       " 6662.582197049524,\n",
       " 8583.062200032553,\n",
       " 7453.934503478135,\n",
       " 24068.791266601515,\n",
       " 12378.339939907646,\n",
       " 4638.738405879772,\n",
       " 11482.486753391886,\n",
       " 19216.01940386737,\n",
       " 21175.516342392424,\n",
       " 5113.395972896646,\n",
       " 7602.213598822878,\n",
       " 3761.032203883525,\n",
       " 3557.2851888880355]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[error[cat].sum() for cat in cc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_anagram 16154.535136588065\n",
      "is_homophone 6662.582197049524\n",
      "is_double 8583.062200032553\n",
      "is_cryptic 7453.934503478135\n",
      "is_contain 24068.791266601515\n",
      "is_reverse 12378.339939907646\n",
      "is_alternate 4638.738405879772\n",
      "is_init 11482.486753391886\n",
      "is_delete 19216.01940386737\n",
      "is_charade 21175.516342392424\n",
      "is_&lit 5113.395972896646\n",
      "is_hidden 7602.213598822878\n",
      "is_spoonerism 3761.032203883525\n",
      "is_palindrome 3557.2851888880355\n"
     ]
    }
   ],
   "source": [
    "for cat,err in zip(cc_types,[error[cat].sum() for cat in cc_types]):\n",
    "    print(cat,err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
